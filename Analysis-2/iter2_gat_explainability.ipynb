{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "\n",
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GATv2Conv\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "torch.set_printoptions(sci_mode=False)\n",
    "print('torch:', torch.__version__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paths (relative to Test-2/)\n",
    "PROCESSED_DIR = Path('../Test-2/data/processed/9f751fe859f07b5c')\n",
    "CKPT_PATH = Path('../Test-2/data/models/iter2_gat.pth')\n",
    "\n",
    "assert PROCESSED_DIR.exists(), f'Missing processed dir: {PROCESSED_DIR.resolve()}'\n",
    "print('processed dir:', PROCESSED_DIR.resolve())\n",
    "print('checkpoint exists:', CKPT_PATH.exists(), '|', CKPT_PATH.resolve())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load processed tensors/loaders\n",
    "edge_index = torch.load(PROCESSED_DIR / 'edge_index.pt', weights_only=False)\n",
    "edge_attr = torch.load(PROCESSED_DIR / 'edge_attr.pt', weights_only=False)\n",
    "static_features = torch.load(PROCESSED_DIR / 'static_features.pt', weights_only=False)\n",
    "sensor_mask = torch.load(PROCESSED_DIR / 'sensor_mask.pt', weights_only=False)\n",
    "train_loader = torch.load(PROCESSED_DIR / 'train_loader.pt', weights_only=False)\n",
    "val_loader = torch.load(PROCESSED_DIR / 'val_loader.pt', weights_only=False)\n",
    "test_loader = torch.load(PROCESSED_DIR / 'test_loader.pt', weights_only=False)\n",
    "\n",
    "with open(PROCESSED_DIR / 'sensor_name_to_id_map.json', 'r') as f:\n",
    "    name_to_id = json.load(f)\n",
    "id_to_name = {int(v): k for k, v in name_to_id.items()}\n",
    "\n",
    "print('edge_index:', tuple(edge_index.shape))\n",
    "print('edge_attr :', tuple(edge_attr.shape))\n",
    "print('static_features:', tuple(static_features.shape))\n",
    "print('sensor_mask:', tuple(sensor_mask.shape), '| dtype:', sensor_mask.dtype)\n",
    "print('train batches:', len(train_loader), 'val:', len(val_loader), 'test:', len(test_loader))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The training notebook uses these scalers for unnormalizing targets before ZINB loss.\n",
    "# Keep them here so forward() can be called the same way if you want loss values.\n",
    "SCALER_MU = 5.887820243835449\n",
    "SCALER_SIGMA = 7.024876594543457"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Same helper as in iter2_gat.ipynb (needed to match checkpoint state_dict structure)\n",
    "def prepare_hybrid_loader(loader, batch_size: int):\n",
    "    all_batches = [(X, y) for X, y in loader]\n",
    "\n",
    "    # Temporal component (unused by this Iter2 model, but kept for dataset structure)\n",
    "    X_temporal_list = [(X[:, :, :, -1:]) for X, _ in all_batches]\n",
    "    X_temporal = torch.cat(X_temporal_list, dim=0)\n",
    "\n",
    "    # Spatial component for GAT\n",
    "    X_agg_list = [(X[:, 0:1, :, :-1]) for X, _ in all_batches]  # 9 aggregated stats\n",
    "    X_raw_list = [(X[:, :, :, -1:].permute(0, 3, 2, 1)) for X, _ in all_batches]  # 12 raw timesteps\n",
    "    X_agg = torch.cat(X_agg_list, dim=0)\n",
    "    X_raw = torch.cat(X_raw_list, dim=0)\n",
    "    X_spatial = torch.cat([X_agg, X_raw], dim=3)  # 9 + 12 = 21\n",
    "\n",
    "    y_list = [y[:, 0:1, :, :] for _, y in all_batches]\n",
    "    y_target = torch.cat(y_list, dim=0)\n",
    "\n",
    "    dataset = torch.utils.data.TensorDataset(X_spatial, X_temporal, y_target)\n",
    "    hybrid_loader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, shuffle=False, drop_last=True)\n",
    "    return hybrid_loader\n",
    "\n",
    "train_h = prepare_hybrid_loader(train_loader, batch_size=16)\n",
    "val_h = prepare_hybrid_loader(val_loader, batch_size=16)\n",
    "test_h = prepare_hybrid_loader(test_loader, batch_size=16)\n",
    "\n",
    "X_spatial, X_temporal, y = next(iter(test_h))\n",
    "print('X_spatial:', tuple(X_spatial.shape), 'X_temporal:', tuple(X_temporal.shape), 'y:', tuple(y.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model (state_dict-compatible with Test-2/iter2_gat.ipynb)\n",
    "def _finite_stats(name, t: torch.Tensor | None) -> bool:\n",
    "    if t is None:\n",
    "        print(f'[DEBUG] {name}: None')\n",
    "        return False\n",
    "    is_finite = torch.isfinite(t)\n",
    "    if not is_finite.all():\n",
    "        n_nan = torch.isnan(t).sum().item()\n",
    "        n_inf = torch.isinf(t).sum().item()\n",
    "        print(f'[NON-FINITE] {name}: nan={n_nan}, inf={n_inf}, shape={tuple(t.shape)}')\n",
    "        return False\n",
    "    return True\n",
    "\n",
    "def _check(name, t: torch.Tensor | None):\n",
    "    _finite_stats(name, t)\n",
    "\n",
    "class SimpleNodeGATZINB(nn.Module):\n",
    "    def __init__(self, dynamic_node_dim, static_node_dim, edge_dim, n_embd, n_heads, edge_index, edge_attr, static_node_features, dropout_rate):\n",
    "        super().__init__()\n",
    "\n",
    "        dynamic_input_dim = dynamic_node_dim * 2  # Original feature + missing mask\n",
    "        gat1_input_channels = dynamic_input_dim + static_node_dim\n",
    "\n",
    "        self.gat1 = GATv2Conv(\n",
    "            in_channels=gat1_input_channels,\n",
    "            out_channels=n_embd,\n",
    "            edge_dim=edge_dim,\n",
    "            heads=n_heads,\n",
    "            concat=False,\n",
    "            dropout=dropout_rate,\n",
    "        )\n",
    "        self.gat2 = GATv2Conv(\n",
    "            in_channels=n_embd,\n",
    "            out_channels=n_embd,\n",
    "            edge_dim=edge_dim,\n",
    "            heads=n_heads,\n",
    "            concat=False,\n",
    "            dropout=dropout_rate,\n",
    "        )\n",
    "        self.norm = nn.LayerNorm(n_embd)\n",
    "\n",
    "        self.mu_head = nn.Linear(n_embd, 1)\n",
    "        self.theta_head = nn.Linear(n_embd, 1)\n",
    "        self.pi_head = nn.Linear(n_embd, 1)\n",
    "\n",
    "        self.elu = nn.ELU()\n",
    "        self.dropout = nn.Dropout(dropout_rate)\n",
    "\n",
    "        self.register_buffer('edge_index', edge_index)\n",
    "        self.register_buffer('edge_attr', edge_attr)\n",
    "        self.register_buffer('static_node_features', static_node_features)\n",
    "\n",
    "    def forward(self, X_batch, targets, node_mask=None, return_attention: bool = False):\n",
    "        mu_list, theta_list, pi_list = [], [], []\n",
    "        attn = {}\n",
    "\n",
    "        missing_mask = torch.isnan(X_batch)\n",
    "        imputed_X = torch.nan_to_num(X_batch, nan=0.0)\n",
    "        mask_features = missing_mask.float()\n",
    "        combined_input = torch.cat([imputed_X, mask_features], dim=-1)\n",
    "\n",
    "        B = combined_input.shape[0]\n",
    "        Xb = combined_input[:, 0, :, :]\n",
    "\n",
    "        for b in range(B):\n",
    "            combined_features = torch.cat([Xb[b], self.static_node_features], dim=-1)\n",
    "            xb = self.dropout(combined_features)\n",
    "\n",
    "            if return_attention:\n",
    "                xb, (ei1, alpha1) = self.gat1(xb, self.edge_index, self.edge_attr, return_attention_weights=True)\n",
    "                attn.setdefault('layer1', []).append((ei1, alpha1))\n",
    "            else:\n",
    "                xb = self.gat1(xb, self.edge_index, self.edge_attr)\n",
    "\n",
    "            xb = self.norm(xb)\n",
    "            xb = self.elu(xb)\n",
    "            xb = self.dropout(xb)\n",
    "\n",
    "            if return_attention:\n",
    "                xb, (ei2, alpha2) = self.gat2(xb, self.edge_index, self.edge_attr, return_attention_weights=True)\n",
    "                attn.setdefault('layer2', []).append((ei2, alpha2))\n",
    "            else:\n",
    "                xb = self.gat2(xb, self.edge_index, self.edge_attr)\n",
    "\n",
    "            xb = self.norm(xb)\n",
    "            xb = self.elu(xb)\n",
    "            xb = self.dropout(xb)\n",
    "\n",
    "            mu_b = F.softplus(self.mu_head(xb)) + 1e-6\n",
    "            theta_b = F.softplus(self.theta_head(xb)) + 1e-6\n",
    "            pi_b = torch.sigmoid(self.pi_head(xb))\n",
    "            pi_b = torch.clamp(pi_b, min=1e-6, max=1 - 1e-6)\n",
    "\n",
    "            mu_list.append(mu_b)\n",
    "            theta_list.append(theta_b)\n",
    "            pi_list.append(pi_b)\n",
    "\n",
    "        mu = torch.stack(mu_list, dim=0).unsqueeze(1)\n",
    "        theta = torch.stack(theta_list, dim=0).unsqueeze(1)\n",
    "        pi = torch.stack(pi_list, dim=0).unsqueeze(1)\n",
    "\n",
    "        preds = mu * (1 - pi)\n",
    "\n",
    "        if targets is None:\n",
    "            zinb_nll_loss = None\n",
    "            mse_loss = None\n",
    "            huber_loss = None\n",
    "            valid_sum = torch.tensor(0.0, device=preds.device)\n",
    "        else:\n",
    "            zinb_nll_loss, valid_sum = self.zinb_nll_loss(mu, theta, pi, targets, node_mask)\n",
    "            mse_loss, _ = self.mse_loss(preds, targets, node_mask)\n",
    "            huber_loss, _ = self.huber_loss(preds, targets, node_mask)\n",
    "\n",
    "        extra = {'mu': mu, 'theta': theta, 'pi': pi, 'valid_sum': valid_sum}\n",
    "        if return_attention:\n",
    "            extra['attn'] = attn\n",
    "\n",
    "        return preds, zinb_nll_loss, mse_loss, huber_loss,extra\n",
    "\n",
    "    def zinb_nll_loss(self, mu, theta, pi, targets, node_mask):\n",
    "        eps = 1e-8\n",
    "        nan_mask = ~torch.isnan(targets)\n",
    "        valid_mask = nan_mask & node_mask if node_mask is not None else nan_mask\n",
    "        if valid_mask.sum() == 0:\n",
    "            return torch.tensor(0.0, device=mu.device, requires_grad=True), torch.tensor(0.0, device=mu.device)\n",
    "\n",
    "        mu_valid = mu[valid_mask]\n",
    "        theta_valid = theta[valid_mask]\n",
    "        pi_valid = pi[valid_mask]\n",
    "        targets_valid = targets[valid_mask]\n",
    "\n",
    "        theta_mu = theta_valid + mu_valid\n",
    "        nb_log_prob = (\n",
    "            torch.lgamma(theta_valid + targets_valid + eps)\n",
    "            - torch.lgamma(theta_valid + eps)\n",
    "            - torch.lgamma(targets_valid + 1)\n",
    "            + theta_valid * torch.log(theta_valid + eps)\n",
    "            - theta_valid * torch.log(theta_mu + eps)\n",
    "            + targets_valid * torch.log(mu_valid + eps)\n",
    "            - targets_valid * torch.log(theta_mu + eps)\n",
    "        )\n",
    "\n",
    "        zero_mask = (targets_valid < eps).float()\n",
    "        nb_zero_prob = theta_valid * torch.log(theta_valid / (theta_mu + eps))\n",
    "        zero_log_prob = torch.log(pi_valid + (1 - pi_valid) * torch.exp(nb_zero_prob) + eps)\n",
    "        non_zero_log_prob = torch.log(1 - pi_valid + eps) + nb_log_prob\n",
    "        log_prob = zero_mask * zero_log_prob + (1 - zero_mask) * non_zero_log_prob\n",
    "        nll = -log_prob.mean()\n",
    "        return nll, valid_mask.sum()\n",
    "\n",
    "    def mse_loss(self, predictions, targets, node_mask):\n",
    "        nan_mask = ~torch.isnan(targets)\n",
    "        valid_mask = nan_mask & node_mask if node_mask is not None else nan_mask\n",
    "        if valid_mask.sum() == 0:\n",
    "            return torch.tensor(0.0, device=predictions.device, requires_grad=True), 0\n",
    "        preds_valid = predictions[valid_mask]\n",
    "        targets_valid = targets[valid_mask]\n",
    "        mse_loss = ((targets_valid - preds_valid) ** 2).mean()\n",
    "        return mse_loss, valid_mask.sum()\n",
    "\n",
    "    def huber_loss(self, predictions, targets, node_mask, delta=1.0):\n",
    "        \"\"\"\n",
    "        Huber loss (smooth L1 loss) - less sensitive to outliers than MSE.\n",
    "\n",
    "        Args:\n",
    "            predictions: Model predictions\n",
    "            targets: Ground truth values\n",
    "            node_mask: Mask for valid nodes\n",
    "            delta: Threshold at which to switch from quadratic to linear loss\n",
    "        \"\"\"\n",
    "        nan_mask = ~torch.isnan(targets)\n",
    "        valid_mask = nan_mask & node_mask if node_mask is not None else nan_mask\n",
    "        if valid_mask.sum() == 0:\n",
    "            return torch.tensor(0.0, device=predictions.device, requires_grad=True), 0\n",
    "\n",
    "        preds_valid = predictions[valid_mask]\n",
    "        targets_valid = targets[valid_mask]\n",
    "\n",
    "        # Huber loss formula\n",
    "        diff = torch.abs(targets_valid - preds_valid)\n",
    "        huber = torch.where(\n",
    "            diff < delta,\n",
    "            0.5 * diff ** 2,\n",
    "            delta * (diff - 0.5 * delta)\n",
    "        )\n",
    "        huber_loss = huber.mean()\n",
    "\n",
    "        return huber_loss, valid_mask.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Training expectations:\")\n",
    "print(\"  Dynamic features: 21\")\n",
    "print(\"  Static features: Should be 13\")\n",
    "print(f\"\\nValidation data:\")\n",
    "print(f\"  Dynamics features shape: {X_spatial.shape}\")\n",
    "print(f\"  Static features shape: {static_features.shape}\")\n",
    "print(f\"  Expected input to GAT1: {21*2 + static_features.shape[1]}\")\n",
    "print(f\"  Model GAT1 expects: 55\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate + load checkpoint\n",
    "device = torch.device('cpu')\n",
    "\n",
    "n_embd = 32\n",
    "n_heads = 4\n",
    "dropout = 0.1\n",
    "\n",
    "model = SimpleNodeGATZINB(\n",
    "    dynamic_node_dim=21,\n",
    "    static_node_dim=static_features.shape[1],\n",
    "    edge_dim=edge_attr.shape[1],\n",
    "    n_embd=n_embd,\n",
    "    n_heads=n_heads,\n",
    "    edge_index=edge_index,\n",
    "    edge_attr=edge_attr,\n",
    "    static_node_features=static_features,\n",
    "    dropout_rate=dropout,\n",
    ").to(device)\n",
    "\n",
    "if CKPT_PATH.exists():\n",
    "    state = torch.load(CKPT_PATH, map_location=device, weights_only=False)\n",
    "    missing, unexpected = model.load_state_dict(state, strict=False)\n",
    "    print('Loaded checkpoint:', CKPT_PATH)\n",
    "    print('missing keys:', len(missing))\n",
    "    print('unexpected keys:', len(unexpected))\n",
    "else:\n",
    "    print('Checkpoint missing:', CKPT_PATH)\n",
    "    print('Create it by running the save cell in Test-2/iter2_gat.ipynb:')\n",
    "    print(\"  torch.save(model.state_dict(), 'data/models/iter2_gat.pth')\")\n",
    "\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Attention aggregation utilities\n",
    "from collections import defaultdict\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def _alpha_mean_per_edge(alpha: torch.Tensor) -> torch.Tensor:\n",
    "    \"\"\"Return per-edge attention scalar by averaging over heads.\"\"\"\n",
    "    # Expected shapes: [E, heads] or [E] (rare)\n",
    "    if alpha.dim() == 2:\n",
    "        return alpha.mean(dim=1)\n",
    "    return alpha.view(alpha.shape[0], -1).mean(dim=1)\n",
    "\n",
    "@torch.no_grad()\n",
    "def collect_attention_stats(\n",
    "    loader,\n",
    "    max_batches: int = 10,\n",
    "    layer: str = 'layer2',\n",
    "    device: torch.device | str = 'cpu',\n",
    "    ) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Runs the trained model and aggregates mean attention per directed edge.\n",
    "\n",
    "    Returns a DataFrame with columns: src, dst, attn_mean, count, src_name, dst_name\n",
    "    where attn_mean is averaged across (batches x samples x heads).\n",
    "    \"\"\"\n",
    "    device = torch.device(device)\n",
    "    model.eval()\n",
    "    sums = defaultdict(float)\n",
    "    counts = defaultdict(int)\n",
    "\n",
    "    n_batches = 0\n",
    "    for X_spatial, _, y_batch in loader:\n",
    "        X_batch = X_spatial.to(device)\n",
    "        y_batch = y_batch.to(device)\n",
    "        y_raw = (y_batch * SCALER_SIGMA) + SCALER_MU\n",
    "        y_raw_int = torch.round(y_raw).long()\n",
    "        _, _, _, _, extra = model(X_batch=X_batch, targets=y_raw_int, node_mask=None, return_attention=True)\n",
    "        attn_dict = extra.get('attn', {})\n",
    "        pairs = attn_dict.get(layer, [])\n",
    "        # pairs is a list over samples in the batch (because model loops over B)\n",
    "        for ei, alpha in pairs:\n",
    "            ei = ei.detach().cpu()\n",
    "            alpha = alpha.detach().cpu()\n",
    "            w = _alpha_mean_per_edge(alpha)\n",
    "            src = ei[0].to(torch.long)\n",
    "            dst = ei[1].to(torch.long)\n",
    "            for s, d, ww in zip(src.tolist(), dst.tolist(), w.tolist()):\n",
    "                key = (int(s), int(d))\n",
    "                sums[key] += float(ww)\n",
    "                counts[key] += 1\n",
    "        n_batches += 1\n",
    "        if n_batches >= max_batches:\n",
    "            break\n",
    "    rows = []\n",
    "    for (s, d), total in sums.items():\n",
    "        c = counts[(s, d)]\n",
    "        rows.append({\n",
    "            'src': s,\n",
    "            'dst': d,\n",
    "            'attn_mean': total / max(c, 1),\n",
    "            'count': c,\n",
    "            'src_name': id_to_name.get(s, str(s)),\n",
    "            'dst_name': id_to_name.get(d, str(d)),\n",
    "        })\n",
    "    df = pd.DataFrame(rows)\n",
    "    if len(df) == 0:\n",
    "        return df\n",
    "    df = df.sort_values(['attn_mean', 'count'], ascending=[False, False]).reset_index(drop=True)\n",
    "    return df\n",
    "\n",
    "def top_incoming(df: pd.DataFrame, node_idx: int, k: int = 15) -> pd.DataFrame:\n",
    "    \"\"\"Top-k incoming edges by attention into node_idx.\"\"\"\n",
    "    out = df[df['dst'] == int(node_idx)].copy()\n",
    "    return out.sort_values('attn_mean', ascending=False).head(k).reset_index(drop=True)\n",
    "\n",
    "def top_outgoing(df: pd.DataFrame, node_idx: int, k: int = 15) -> pd.DataFrame:\n",
    "    \"\"\"Top-k outgoing edges by attention from node_idx.\"\"\"\n",
    "    out = df[df['src'] == int(node_idx)].copy()\n",
    "    return out.sort_values('attn_mean', ascending=False).head(k).reset_index(drop=True)\n",
    "\n",
    "print('Ready to collect attention statistics.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collect + summarize learned attention (change max_batches for more stability)\n",
    "MAX_BATCHES = 25\n",
    "\n",
    "attn_l1 = collect_attention_stats(test_h, max_batches=MAX_BATCHES, layer='layer1', device=device)\n",
    "attn_l2 = collect_attention_stats(test_h, max_batches=MAX_BATCHES, layer='layer2', device=device)\n",
    "\n",
    "print('layer1 edges:', len(attn_l1), '| layer2 edges:', len(attn_l2))\n",
    "\n",
    "# Top edges globally\n",
    "display(attn_l1.head(20))\n",
    "display(attn_l2.head(20))\n",
    "\n",
    "# Pick a node to inspect (0 is fine, or change to any sensor id)\n",
    "node_idx = 0\n",
    "print('Node:', node_idx, id_to_name.get(int(node_idx), str(node_idx)))\n",
    "\n",
    "print('\\nTop incoming (layer2):')\n",
    "display(top_incoming(attn_l2, node_idx=node_idx, k=20))\n",
    "\n",
    "print('\\nTop outgoing (layer2):')\n",
    "display(top_outgoing(attn_l2, node_idx=node_idx, k=20))\n",
    "\n",
    "# Optional: save to CSV for further analysis\n",
    "# attn_l2.to_csv('attn_layer2_test.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate model with all metrics (ZINB NLL, MSE, and Huber Loss)\n",
    "@torch.no_grad()\n",
    "def evaluate_all_metrics(loader, split_name='Test', device='cpu'):\n",
    "    \"\"\"Evaluate model with ZINB NLL, MSE, and Huber Loss.\"\"\"\n",
    "    device = torch.device(device)\n",
    "    model.eval()\n",
    "\n",
    "    total_zinb_nll = 0.0\n",
    "    total_mse = 0.0\n",
    "    total_huber = 0.0\n",
    "    num_batches = 0\n",
    "\n",
    "    for X_spatial, _, y_batch in loader:\n",
    "        X_batch = X_spatial.to(device)\n",
    "        y_batch = y_batch.to(device)\n",
    "        y_raw = (y_batch * SCALER_SIGMA) + SCALER_MU\n",
    "        y_raw_int = torch.round(y_raw).long()\n",
    "\n",
    "        _, zinb_nll, mse, huber, _ = model(\n",
    "            X_batch=X_batch,\n",
    "            targets=y_raw_int,\n",
    "            node_mask=None,\n",
    "            return_attention=False\n",
    "        )\n",
    "\n",
    "        if zinb_nll is not None:\n",
    "            total_zinb_nll += zinb_nll.item()\n",
    "            total_mse += mse.item()\n",
    "            total_huber += huber.item()\n",
    "            num_batches += 1\n",
    "\n",
    "    if num_batches > 0:\n",
    "        avg_zinb_nll = total_zinb_nll / num_batches\n",
    "        avg_mse = total_mse / num_batches\n",
    "        avg_huber = total_huber / num_batches\n",
    "\n",
    "        print(f'\\n{split_name} Set Metrics:')\n",
    "        print(f'  ZINB NLL:   {avg_zinb_nll:.4f}')\n",
    "        print(f'  MSE:        {avg_mse:.4f}')\n",
    "        print(f'  Huber Loss: {avg_huber:.4f}')\n",
    "        print(f'  Batches:    {num_batches}')\n",
    "\n",
    "        return {\n",
    "            'zinb_nll': avg_zinb_nll,\n",
    "            'mse': avg_mse,\n",
    "            'huber': avg_huber,\n",
    "            'num_batches': num_batches\n",
    "        }\n",
    "\n",
    "    return None\n",
    "\n",
    "# Run evaluation on all splits\n",
    "train_metrics = evaluate_all_metrics(train_h, split_name='Train', device=device)\n",
    "val_metrics = evaluate_all_metrics(val_h, split_name='Validation', device=device)\n",
    "test_metrics = evaluate_all_metrics(test_h, split_name='Test', device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save attention scores to JSON for visualization\n",
    "output_data = {\n",
    "    'layer1': {},\n",
    "    'layer2': {},\n",
    "    'nodes': id_to_name\n",
    "}\n",
    "\n",
    "# Convert layer1 attention to JSON format\n",
    "for _, row in attn_l1.iterrows():\n",
    "    edge_key = f\"{row['src']}_{row['dst']}\"\n",
    "    output_data['layer1'][edge_key] = {\n",
    "        'source': int(row['src']),\n",
    "        'target': int(row['dst']),\n",
    "        'source_name': row['src_name'],\n",
    "        'target_name': row['dst_name'],\n",
    "        'score': float(row['attn_mean'])\n",
    "    }\n",
    "\n",
    "# Convert layer2 attention to JSON format\n",
    "for _, row in attn_l2.iterrows():\n",
    "    edge_key = f\"{row['src']}_{row['dst']}\"\n",
    "    output_data['layer2'][edge_key] = {\n",
    "        'source': int(row['src']),\n",
    "        'target': int(row['dst']),\n",
    "        'source_name': row['src_name'],\n",
    "        'target_name': row['dst_name'],\n",
    "        'score': float(row['attn_mean'])\n",
    "    }\n",
    "\n",
    "# Save to JSON file\n",
    "with open('attention_scores.json', 'w') as f:\n",
    "    json.dump(output_data, f, indent=2)\n",
    "\n",
    "print(f'Attention scores saved to: attention_scores.json')\n",
    "print(f'Layer 1 edges: {len(output_data[\"layer1\"])}')\n",
    "print(f'Layer 2 edges: {len(output_data[\"layer2\"])}')\n",
    "print(f'Nodes: {len(output_data[\"nodes\"])}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize attention scores on graph\n",
    "import matplotlib.pyplot as plt\n",
    "import networkx as nx\n",
    "from matplotlib.colors import Normalize\n",
    "from matplotlib.cm import ScalarMappable\n",
    "\n",
    "def plot_attention_graph(attn_df, layer_name='Layer 2', top_k=100, figsize=(20, 16)):\n",
    "    \"\"\"\n",
    "    Plot a graph visualization with edges colored by attention scores.\n",
    "\n",
    "    Parameters:\n",
    "    - attn_df: DataFrame with columns src, dst, attn_mean, src_name, dst_name\n",
    "    - layer_name: Name for the plot title\n",
    "    - top_k: Number of top edges to display (to avoid clutter)\n",
    "    - figsize: Figure size tuple\n",
    "    \"\"\"\n",
    "    # Take top_k edges by attention score\n",
    "    df_plot = attn_df.head(top_k).copy()\n",
    "\n",
    "    # Create directed graph\n",
    "    G = nx.DiGraph()\n",
    "\n",
    "    # Add nodes with names\n",
    "    all_nodes = set(df_plot['src'].tolist() + df_plot['dst'].tolist())\n",
    "    for node_id in all_nodes:\n",
    "        node_name = id_to_name.get(int(node_id), str(node_id))\n",
    "        G.add_node(node_id, label=node_name)\n",
    "\n",
    "    # Add edges with attention weights\n",
    "    edge_weights = []\n",
    "    for _, row in df_plot.iterrows():\n",
    "        G.add_edge(row['src'], row['dst'], weight=row['attn_mean'])\n",
    "        edge_weights.append(row['attn_mean'])\n",
    "\n",
    "    # Setup figure\n",
    "    fig, ax = plt.subplots(figsize=figsize)\n",
    "\n",
    "    # Layout - using spring layout for better visualization\n",
    "    # You can try: spring_layout, kamada_kawai_layout, circular_layout\n",
    "    pos = nx.spring_layout(G, k=2, iterations=50, seed=42)\n",
    "\n",
    "    # Normalize edge weights for coloring\n",
    "    norm = Normalize(vmin=min(edge_weights), vmax=max(edge_weights))\n",
    "    cmap = plt.cm.YlOrRd  # Yellow to Red colormap\n",
    "\n",
    "    # Draw nodes\n",
    "    nx.draw_networkx_nodes(\n",
    "        G, pos,\n",
    "        node_color='lightblue',\n",
    "        node_size=800,\n",
    "        alpha=0.9,\n",
    "        ax=ax\n",
    "    )\n",
    "\n",
    "    # Draw edges with colors based on attention scores\n",
    "    edges = G.edges()\n",
    "    colors = [G[u][v]['weight'] for u, v in edges]\n",
    "\n",
    "    nx.draw_networkx_edges(\n",
    "        G, pos,\n",
    "        edgelist=edges,\n",
    "        edge_color=colors,\n",
    "        edge_cmap=cmap,\n",
    "        edge_vmin=min(edge_weights),\n",
    "        edge_vmax=max(edge_weights),\n",
    "        width=2,\n",
    "        alpha=0.6,\n",
    "        arrows=True,\n",
    "        arrowsize=15,\n",
    "        arrowstyle='->',\n",
    "        connectionstyle='arc3,rad=0.1',\n",
    "        ax=ax\n",
    "    )\n",
    "\n",
    "    # Draw labels\n",
    "    labels = nx.get_node_attributes(G, 'label')\n",
    "    nx.draw_networkx_labels(\n",
    "        G, pos,\n",
    "        labels=labels,\n",
    "        font_size=8,\n",
    "        font_weight='bold',\n",
    "        ax=ax\n",
    "    )\n",
    "\n",
    "    # Add colorbar\n",
    "    sm = ScalarMappable(cmap=cmap, norm=norm)\n",
    "    sm.set_array([])\n",
    "    cbar = plt.colorbar(sm, ax=ax, fraction=0.046, pad=0.04)\n",
    "    cbar.set_label('Attention Score', rotation=270, labelpad=20, fontsize=12)\n",
    "\n",
    "    ax.set_title(f'{layer_name} Attention Scores (Top {top_k} Edges)',\n",
    "                 fontsize=16, fontweight='bold', pad=20)\n",
    "    ax.axis('off')\n",
    "    plt.tight_layout()\n",
    "\n",
    "    return fig, ax, G\n",
    "\n",
    "# Plot both layers\n",
    "print('Plotting Layer 1 attention...')\n",
    "fig1, ax1, G1 = plot_attention_graph(attn_l1, layer_name='Layer 1', top_k=100)\n",
    "plt.savefig('attention_layer1_graph.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print('\\nPlotting Layer 2 attention...')\n",
    "fig2, ax2, G2 = plot_attention_graph(attn_l2, layer_name='Layer 2', top_k=100)\n",
    "plt.savefig('attention_layer2_graph.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(f'\\nGraphs saved as attention_layer1_graph.png and attention_layer2_graph.png')\n",
    "print(f'Layer 1: {G1.number_of_nodes()} nodes, {G1.number_of_edges()} edges')\n",
    "print(f'Layer 2: {G2.number_of_nodes()} nodes, {G2.number_of_edges()} edges')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
