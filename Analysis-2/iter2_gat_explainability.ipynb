{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "\n",
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GATv2Conv\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "torch.set_printoptions(sci_mode=False)\n",
    "print('torch:', torch.__version__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paths (relative to Test-2/)\n",
    "PROCESSED_DIR = Path('../Test-2/data/processed/9f751fe859f07b5c')\n",
    "CKPT_PATH = Path('../Test-2/data/models/iter4_gat.pth')\n",
    "\n",
    "assert PROCESSED_DIR.exists(), f'Missing processed dir: {PROCESSED_DIR.resolve()}'\n",
    "print('processed dir:', PROCESSED_DIR.resolve())\n",
    "print('checkpoint exists:', CKPT_PATH.exists(), '|', CKPT_PATH.resolve())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load processed tensors/loaders\n",
    "edge_index = torch.load(PROCESSED_DIR / 'edge_index.pt', weights_only=False)\n",
    "edge_attr = torch.load(PROCESSED_DIR / 'edge_attr.pt', weights_only=False)\n",
    "static_features = torch.load(PROCESSED_DIR / 'static_features.pt', weights_only=False)\n",
    "sensor_mask = torch.load(PROCESSED_DIR / 'sensor_mask.pt', weights_only=False)\n",
    "train_loader = torch.load(PROCESSED_DIR / 'train_loader.pt', weights_only=False)\n",
    "val_loader = torch.load(PROCESSED_DIR / 'val_loader.pt', weights_only=False)\n",
    "test_loader = torch.load(PROCESSED_DIR / 'test_loader.pt', weights_only=False)\n",
    "\n",
    "with open(PROCESSED_DIR / 'sensor_name_to_id_map.json', 'r') as f:\n",
    "    name_to_id = json.load(f)\n",
    "id_to_name = {int(v): k for k, v in name_to_id.items()}\n",
    "\n",
    "print('edge_index:', tuple(edge_index.shape))\n",
    "print('edge_attr :', tuple(edge_attr.shape))\n",
    "print('static_features:', tuple(static_features.shape))\n",
    "print('sensor_mask:', tuple(sensor_mask.shape), '| dtype:', sensor_mask.dtype)\n",
    "print('train batches:', len(train_loader), 'val:', len(val_loader), 'test:', len(test_loader))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The training notebook uses these scalers for unnormalizing targets before ZINB loss.\n",
    "# Keep them here so forward() can be called the same way if you want loss values.\n",
    "SCALER_MU = 14.323774337768555\n",
    "SCALER_SIGMA = 34.9963493347168\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select 3 random days from test set for temporal analysis\n",
    "# Assuming data is sampled at 15-minute intervals, 96 samples per day\n",
    "SAMPLES_PER_DAY = 96\n",
    "NUM_DAYS = 3\n",
    "BATCH_SIZE = 16\n",
    "\n",
    "# Get total samples in test set\n",
    "total_test_samples = len(test_loader) * BATCH_SIZE\n",
    "total_days = total_test_samples // SAMPLES_PER_DAY\n",
    "\n",
    "print(f\"Total test samples: {total_test_samples}\")\n",
    "print(f\"Total days in test set: {total_days}\")\n",
    "print(f\"Samples per day: {SAMPLES_PER_DAY}\")\n",
    "\n",
    "# Randomly select 3 days\n",
    "import random\n",
    "random.seed(42)  # For reproducibility\n",
    "selected_days = sorted(random.sample(range(total_days), min(NUM_DAYS, total_days)))\n",
    "selected_day_ranges = [(day * SAMPLES_PER_DAY, (day + 1) * SAMPLES_PER_DAY) for day in selected_days]\n",
    "\n",
    "print(f\"\\nSelected days: {selected_days}\")\n",
    "print(f\"Sample ranges: {selected_day_ranges}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5",
   "metadata": {},
   "source": [
    "## Sample Selection for Temporal Analysis\n",
    "\n",
    "Select a random subset of days from the test set for temporal attention analysis.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Same helper as in iter2_gat.ipynb (needed to match checkpoint state_dict structure)\n",
    "def prepare_hybrid_loader(loader, batch_size: int):\n",
    "    all_batches = [(X, y) for X, y in loader]\n",
    "\n",
    "    # Temporal component (unused by this Iter2 model, but kept for dataset structure)\n",
    "    X_temporal_list = [(X[:, :, :, -1:]) for X, _ in all_batches]\n",
    "    X_temporal = torch.cat(X_temporal_list, dim=0)\n",
    "\n",
    "    # Spatial component for GAT\n",
    "    X_agg_list = [(X[:, 0:1, :, :-1]) for X, _ in all_batches]  # 9 aggregated stats\n",
    "    X_raw_list = [(X[:, :, :, -1:].permute(0, 3, 2, 1)) for X, _ in all_batches]  # 12 raw timesteps\n",
    "    X_agg = torch.cat(X_agg_list, dim=0)\n",
    "    X_raw = torch.cat(X_raw_list, dim=0)\n",
    "    X_spatial = torch.cat([X_agg, X_raw], dim=3)  # 9 + 12 = 21\n",
    "\n",
    "    y_list = [y[:, 0:1, :, :] for _, y in all_batches]\n",
    "    y_target = torch.cat(y_list, dim=0)\n",
    "\n",
    "    dataset = torch.utils.data.TensorDataset(X_spatial, X_temporal, y_target)\n",
    "    hybrid_loader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, shuffle=False, drop_last=True)\n",
    "    return hybrid_loader\n",
    "\n",
    "train_h = prepare_hybrid_loader(train_loader, batch_size=16)\n",
    "val_h = prepare_hybrid_loader(val_loader, batch_size=16)\n",
    "test_h = prepare_hybrid_loader(test_loader, batch_size=16)\n",
    "\n",
    "X_spatial, X_temporal, y = next(iter(test_h))\n",
    "print('X_spatial:', tuple(X_spatial.shape), 'X_temporal:', tuple(X_temporal.shape), 'y:', tuple(y.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model (state_dict-compatible with Test-2/iter2_gat.ipynb)\n",
    "def _finite_stats(name, t: torch.Tensor | None) -> bool:\n",
    "    if t is None:\n",
    "        print(f'[DEBUG] {name}: None')\n",
    "        return False\n",
    "    is_finite = torch.isfinite(t)\n",
    "    if not is_finite.all():\n",
    "        n_nan = torch.isnan(t).sum().item()\n",
    "        n_inf = torch.isinf(t).sum().item()\n",
    "        print(f'[NON-FINITE] {name}: nan={n_nan}, inf={n_inf}, shape={tuple(t.shape)}')\n",
    "        return False\n",
    "    return True\n",
    "\n",
    "def _check(name, t: torch.Tensor | None):\n",
    "    _finite_stats(name, t)\n",
    "\n",
    "class DynamicNodeGATZINB(nn.Module):\n",
    "    def __init__(self, dynamic_node_dim, static_node_dim, edge_dim, n_embd, n_heads, dropout_rate):\n",
    "        super().__init__()\n",
    "\n",
    "        dynamic_input_dim = dynamic_node_dim * 2\n",
    "        gat1_input_channels = dynamic_input_dim + static_node_dim\n",
    "\n",
    "        self.gat1 = GATv2Conv(\n",
    "            in_channels=gat1_input_channels,\n",
    "            out_channels=n_embd,\n",
    "            edge_dim=edge_dim,\n",
    "            heads=n_heads,\n",
    "            concat=False,\n",
    "            dropout=dropout_rate,\n",
    "        )\n",
    "        self.gat2 = GATv2Conv(\n",
    "            in_channels=n_embd,\n",
    "            out_channels=n_embd,\n",
    "            edge_dim=edge_dim,\n",
    "            heads=n_heads,\n",
    "            concat=False,\n",
    "            dropout=dropout_rate,\n",
    "        )\n",
    "        self.norm = nn.LayerNorm(n_embd)\n",
    "\n",
    "        self.mu_head = nn.Linear(n_embd, 1)\n",
    "        self.theta_head = nn.Linear(n_embd, 1)\n",
    "        self.pi_head = nn.Linear(n_embd, 1)\n",
    "\n",
    "        self.elu = nn.ELU()\n",
    "        self.dropout = nn.Dropout(dropout_rate)\n",
    "\n",
    "        # NO register_buffer calls!\n",
    "\n",
    "    def forward(self, X_batch, targets, node_mask, edge_index, edge_attr, static_node_features, return_attention=False):\n",
    "        mu_list, theta_list, pi_list = [], [], []\n",
    "        attn = {}\n",
    "\n",
    "        missing_mask = torch.isnan(X_batch)\n",
    "        imputed_X = torch.nan_to_num(X_batch, nan=0.0)\n",
    "        mask_features = missing_mask.float()\n",
    "        combined_input = torch.cat([imputed_X, mask_features], dim=-1)\n",
    "\n",
    "        B = combined_input.shape[0]\n",
    "        Xb = combined_input[:, 0, :, :]\n",
    "\n",
    "        for b in range(B):\n",
    "            combined_features = torch.cat([Xb[b], static_node_features], dim=-1)\n",
    "            xb = self.dropout(combined_features)\n",
    "\n",
    "            if return_attention:\n",
    "                xb, (ei1, alpha1) = self.gat1(xb, edge_index, edge_attr, return_attention_weights=True)\n",
    "                attn.setdefault('layer1', []).append((ei1, alpha1))\n",
    "            else:\n",
    "                xb = self.gat1(xb, self.edge_index, self.edge_attr)\n",
    "\n",
    "            xb = self.norm(xb)\n",
    "            xb = self.elu(xb)\n",
    "            xb = self.dropout(xb)\n",
    "\n",
    "            if return_attention:\n",
    "                xb, (ei2, alpha2) = self.gat2(xb, edge_index,\n",
    "                edge_attr, return_attention_weights=True)\n",
    "                attn.setdefault('layer2', []).append((ei2, alpha2))\n",
    "            else:\n",
    "                xb = self.gat2(xb, self.edge_index, self.edge_attr)\n",
    "\n",
    "            xb = self.norm(xb)\n",
    "            xb = self.elu(xb)\n",
    "            xb = self.dropout(xb)\n",
    "\n",
    "            mu_b = F.softplus(self.mu_head(xb)) + 1e-6\n",
    "            theta_b = F.softplus(self.theta_head(xb)) + 1e-6\n",
    "            pi_b = torch.sigmoid(self.pi_head(xb))\n",
    "            pi_b = torch.clamp(pi_b, min=1e-6, max=1 - 1e-6)\n",
    "\n",
    "            mu_list.append(mu_b)\n",
    "            theta_list.append(theta_b)\n",
    "            pi_list.append(pi_b)\n",
    "\n",
    "        mu = torch.stack(mu_list, dim=0).unsqueeze(1)\n",
    "        theta = torch.stack(theta_list, dim=0).unsqueeze(1)\n",
    "        pi = torch.stack(pi_list, dim=0).unsqueeze(1)\n",
    "\n",
    "        preds = mu * (1 - pi)\n",
    "\n",
    "        if targets is None:\n",
    "            zinb_nll_loss = None\n",
    "            mse_loss = None\n",
    "            huber_loss = None\n",
    "            valid_sum = torch.tensor(0.0, device=preds.device)\n",
    "        else:\n",
    "            zinb_nll_loss, valid_sum = self.zinb_nll_loss(mu, theta, pi, targets, node_mask)\n",
    "            mse_loss, _ = self.mse_loss(preds, targets, node_mask)\n",
    "            huber_loss, _ = self.mse_loss(preds, targets, node_mask)\n",
    "\n",
    "        extra = {'mu': mu, 'theta': theta, 'pi': pi, 'valid_sum': valid_sum}\n",
    "        if return_attention:\n",
    "            extra['attn'] = attn\n",
    "\n",
    "        return preds, zinb_nll_loss, mse_loss, huber_loss, extra\n",
    "\n",
    "    def zinb_nll_loss(self, mu, theta, pi, targets, node_mask):\n",
    "        eps = 1e-8\n",
    "        nan_mask = ~torch.isnan(targets)\n",
    "        valid_mask = nan_mask & node_mask if node_mask is not None else nan_mask\n",
    "        if valid_mask.sum() == 0:\n",
    "            return torch.tensor(0.0, device=mu.device, requires_grad=True), torch.tensor(0.0, device=mu.device)\n",
    "\n",
    "        mu_valid = mu[valid_mask]\n",
    "        theta_valid = theta[valid_mask]\n",
    "        pi_valid = pi[valid_mask]\n",
    "        targets_valid = targets[valid_mask]\n",
    "\n",
    "        theta_mu = theta_valid + mu_valid\n",
    "        nb_log_prob = (\n",
    "            torch.lgamma(theta_valid + targets_valid + eps)\n",
    "            - torch.lgamma(theta_valid + eps)\n",
    "            - torch.lgamma(targets_valid + 1)\n",
    "            + theta_valid * torch.log(theta_valid + eps)\n",
    "            - theta_valid * torch.log(theta_mu + eps)\n",
    "            + targets_valid * torch.log(mu_valid + eps)\n",
    "            - targets_valid * torch.log(theta_mu + eps)\n",
    "        )\n",
    "\n",
    "        zero_mask = (targets_valid < eps).float()\n",
    "        nb_zero_prob = theta_valid * torch.log(theta_valid / (theta_mu + eps))\n",
    "        zero_log_prob = torch.log(pi_valid + (1 - pi_valid) * torch.exp(nb_zero_prob) + eps)\n",
    "        non_zero_log_prob = torch.log(1 - pi_valid + eps) + nb_log_prob\n",
    "        log_prob = zero_mask * zero_log_prob + (1 - zero_mask) * non_zero_log_prob\n",
    "        nll = -log_prob.mean()\n",
    "        return nll, valid_mask.sum()\n",
    "\n",
    "    def mse_loss(self, predictions, targets, node_mask):\n",
    "        nan_mask = ~torch.isnan(targets)\n",
    "        valid_mask = nan_mask & node_mask if node_mask is not None else nan_mask\n",
    "        if valid_mask.sum() == 0:\n",
    "            return torch.tensor(0.0, device=predictions.device, requires_grad=True), 0\n",
    "        preds_valid = predictions[valid_mask]\n",
    "        targets_valid = targets[valid_mask]\n",
    "        mse_loss = ((targets_valid - preds_valid) ** 2).mean()\n",
    "        return mse_loss, valid_mask.sum()\n",
    "\n",
    "    def huber_loss(self, predictions, targets, node_mask, delta=1.0):\n",
    "        \"\"\"\n",
    "        Huber loss (smooth L1 loss) - less sensitive to outliers than MSE.\n",
    "\n",
    "        Args:\n",
    "            predictions: Model predictions\n",
    "            targets: Ground truth values\n",
    "            node_mask: Mask for valid nodes\n",
    "            delta: Threshold at which to switch from quadratic to linear loss\n",
    "        \"\"\"\n",
    "        nan_mask = ~torch.isnan(targets)\n",
    "        valid_mask = nan_mask & node_mask if node_mask is not None else nan_mask\n",
    "        if valid_mask.sum() == 0:\n",
    "            return torch.tensor(0.0, device=predictions.device, requires_grad=True), 0\n",
    "\n",
    "        preds_valid = predictions[valid_mask]\n",
    "        targets_valid = targets[valid_mask]\n",
    "\n",
    "        # Huber loss formula\n",
    "        diff = torch.abs(targets_valid - preds_valid)\n",
    "        huber = torch.where(\n",
    "            diff < delta,\n",
    "            0.5 * diff ** 2,\n",
    "            delta * (diff - 0.5 * delta)\n",
    "        )\n",
    "        huber_loss = huber.mean()\n",
    "\n",
    "        return huber_loss, valid_mask.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Training expectations:\")\n",
    "print(\"  Dynamic features: 21\")\n",
    "print(\"  Static features: Should be 13\")\n",
    "print(f\"\\nValidation data:\")\n",
    "print(f\"  Dynamics features shape: {X_spatial.shape}\")\n",
    "print(f\"  Static features shape: {static_features.shape}\")\n",
    "print(f\"  Expected input to GAT1: {21*2 + static_features.shape[1]}\")\n",
    "print(f\"  Model GAT1 expects: 55\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate + load checkpoint\n",
    "device = torch.device('cpu')\n",
    "\n",
    "n_embd = 32\n",
    "n_heads = 4\n",
    "dropout = 0.1\n",
    "\n",
    "# Update model instantiation (remove graph data from constructor):\n",
    "model = DynamicNodeGATZINB(\n",
    "    dynamic_node_dim=21,\n",
    "    static_node_dim=static_features.shape[1],\n",
    "    edge_dim=edge_attr.shape[1],\n",
    "    n_embd=n_embd,\n",
    "    n_heads=n_heads,\n",
    "    dropout_rate=dropout,\n",
    ").to(device)\n",
    "\n",
    "# Load checkpoint - this will work if layer dimensions match\n",
    "if CKPT_PATH.exists():\n",
    "    state = torch.load(CKPT_PATH, map_location=device, weights_only=False)\n",
    "    missing, unexpected = model.load_state_dict(state, strict=False)\n",
    "    print('Loaded checkpoint:', CKPT_PATH)\n",
    "\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Attention aggregation utilities\n",
    "from collections import defaultdict\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def _alpha_mean_per_edge(alpha: torch.Tensor) -> torch.Tensor:\n",
    "    \"\"\"Return per-edge attention scalar by averaging over heads.\"\"\"\n",
    "    # Expected shapes: [E, heads] or [E] (rare)\n",
    "    if alpha.dim() == 2:\n",
    "        return alpha.mean(dim=1)\n",
    "    return alpha.view(alpha.shape[0], -1).mean(dim=1)\n",
    "\n",
    "@torch.no_grad()\n",
    "def collect_attention_stats(loader, max_batches=10, layer='layer2', device='cpu'):\n",
    "    \"\"\"Collect averaged attention statistics across batches.\"\"\"\n",
    "    device = torch.device(device)\n",
    "    model.eval()\n",
    "    sums = defaultdict(float)\n",
    "    counts = defaultdict(int)\n",
    "\n",
    "    n_batches = 0\n",
    "    for X_spatial, _, y_batch in loader:\n",
    "        X_batch = X_spatial.to(device)\n",
    "        y_batch = y_batch.to(device)\n",
    "        y_raw = (y_batch * SCALER_SIGMA) + SCALER_MU\n",
    "        y_raw_int = torch.round(y_raw).long()\n",
    "\n",
    "        # Pass graph data explicitly:\n",
    "        _, _, _, _, extra = model(\n",
    "            X_batch=X_batch,\n",
    "            targets=y_raw_int,\n",
    "            node_mask=None,\n",
    "            edge_index=edge_index,\n",
    "            edge_attr=edge_attr,\n",
    "            static_node_features=static_features,\n",
    "            return_attention=True\n",
    "        )\n",
    "\n",
    "        attn_dict = extra.get('attn', {})\n",
    "        pairs = attn_dict.get(layer, [])\n",
    "        # pairs is a list over samples in the batch (because model loops over B)\n",
    "        for ei, alpha in pairs:\n",
    "            ei = ei.detach().cpu()\n",
    "            alpha = alpha.detach().cpu()\n",
    "            w = _alpha_mean_per_edge(alpha)\n",
    "            src = ei[0].to(torch.long)\n",
    "            dst = ei[1].to(torch.long)\n",
    "            for s, d, ww in zip(src.tolist(), dst.tolist(), w.tolist()):\n",
    "                key = (int(s), int(d))\n",
    "                sums[key] += float(ww)\n",
    "                counts[key] += 1\n",
    "        n_batches += 1\n",
    "        if n_batches >= max_batches:\n",
    "            break\n",
    "    rows = []\n",
    "    for (s, d), total in sums.items():\n",
    "        c = counts[(s, d)]\n",
    "        rows.append({\n",
    "            'src': s,\n",
    "            'dst': d,\n",
    "            'attn_mean': total / max(c, 1),\n",
    "            'count': c,\n",
    "            'src_name': id_to_name.get(s, str(s)),\n",
    "            'dst_name': id_to_name.get(d, str(d)),\n",
    "        })\n",
    "    df = pd.DataFrame(rows)\n",
    "    if len(df) == 0:\n",
    "        return df\n",
    "    df = df.sort_values(['attn_mean', 'count'], ascending=[False, False]).reset_index(drop=True)\n",
    "    return df\n",
    "\n",
    "@torch.no_grad()\n",
    "def collect_temporal_attention(loader, sample_indices, layer='layer2', device='cpu'):\n",
    "    \"\"\"\n",
    "    Collect attention scores for specific samples (temporal snapshots).\n",
    "\n",
    "    Args:\n",
    "        loader: DataLoader\n",
    "        sample_indices: List of sample indices to extract\n",
    "        layer: Which attention layer to extract\n",
    "        device: Device to run on\n",
    "\n",
    "    Returns:\n",
    "        List of dicts, each containing attention for one sample\n",
    "    \"\"\"\n",
    "    device = torch.device(device)\n",
    "    model.eval()\n",
    "\n",
    "    temporal_data = []\n",
    "    current_sample_idx = 0\n",
    "\n",
    "    for X_spatial, _, y_batch in loader:\n",
    "        X_batch = X_spatial.to(device)\n",
    "        y_batch = y_batch.to(device)\n",
    "        y_raw = (y_batch * SCALER_SIGMA) + SCALER_MU\n",
    "        y_raw_int = torch.round(y_raw).long()\n",
    "\n",
    "        batch_size = X_batch.shape[0]\n",
    "\n",
    "        # Pass graph data explicitly:\n",
    "        _, _, _, _, extra = model(\n",
    "            X_batch=X_batch,\n",
    "            targets=y_raw_int,\n",
    "            node_mask=None,\n",
    "            edge_index=edge_index,\n",
    "            edge_attr=edge_attr,\n",
    "            static_node_features=static_features,\n",
    "            return_attention=True\n",
    "        )\n",
    "\n",
    "        attn_dict = extra.get('attn', {})\n",
    "        pairs = attn_dict.get(layer, [])\n",
    "\n",
    "        # Process each sample in the batch\n",
    "        for batch_idx, (ei, alpha) in enumerate(pairs):\n",
    "            sample_idx = current_sample_idx + batch_idx\n",
    "\n",
    "            # Only save if this sample is in our selected indices\n",
    "            if sample_idx in sample_indices:\n",
    "                ei = ei.detach().cpu()\n",
    "                alpha = alpha.detach().cpu()\n",
    "                w = _alpha_mean_per_edge(alpha)\n",
    "\n",
    "                # Build edge dictionary for this sample\n",
    "                edges = {}\n",
    "                src = ei[0].to(torch.long)\n",
    "                dst = ei[1].to(torch.long)\n",
    "\n",
    "                for s, d, ww in zip(src.tolist(), dst.tolist(), w.tolist()):\n",
    "                    edge_key = f\"{int(s)}_{int(d)}\"\n",
    "                    edges[edge_key] = {\n",
    "                        'source': int(s),\n",
    "                        'target': int(d),\n",
    "                        'source_name': id_to_name.get(int(s), str(s)),\n",
    "                        'target_name': id_to_name.get(int(d), str(d)),\n",
    "                        'score': float(ww)\n",
    "                    }\n",
    "\n",
    "                temporal_data.append({\n",
    "                    'sample_idx': sample_idx,\n",
    "                    'edges': edges\n",
    "                })\n",
    "\n",
    "        current_sample_idx += batch_size\n",
    "\n",
    "        # Stop if we've passed all selected samples\n",
    "        if current_sample_idx > max(sample_indices):\n",
    "            break\n",
    "\n",
    "    return temporal_data\n",
    "\n",
    "def top_incoming(df: pd.DataFrame, node_idx: int, k: int = 15) -> pd.DataFrame:\n",
    "    \"\"\"Top-k incoming edges by attention into node_idx.\"\"\"\n",
    "    out = df[df['dst'] == int(node_idx)].copy()\n",
    "    return out.sort_values('attn_mean', ascending=False).head(k).reset_index(drop=True)\n",
    "\n",
    "def top_outgoing(df: pd.DataFrame, node_idx: int, k: int = 15) -> pd.DataFrame:\n",
    "    \"\"\"Top-k outgoing edges by attention from node_idx.\"\"\"\n",
    "    out = df[df['src'] == int(node_idx)].copy()\n",
    "    return out.sort_values('attn_mean', ascending=False).head(k).reset_index(drop=True)\n",
    "\n",
    "print('Ready to collect attention statistics.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collect averaged attention statistics (for static view)\n",
    "MAX_BATCHES = 25\n",
    "\n",
    "attn_l1 = collect_attention_stats(test_h, max_batches=MAX_BATCHES, layer='layer1', device=device)\n",
    "attn_l2 = collect_attention_stats(test_h, max_batches=MAX_BATCHES, layer='layer2', device=device)\n",
    "\n",
    "print('layer1 edges:', len(attn_l1), '| layer2 edges:', len(attn_l2))\n",
    "\n",
    "# Top edges globally\n",
    "display(attn_l1.head(20))\n",
    "display(attn_l2.head(20))\n",
    "\n",
    "# Pick a node to inspect (0 is fine, or change to any sensor id)\n",
    "node_idx = 0\n",
    "print('Node:', node_idx, id_to_name.get(int(node_idx), str(node_idx)))\n",
    "\n",
    "print('\\nTop incoming (layer2):')\n",
    "display(top_incoming(attn_l2, node_idx=node_idx, k=20))\n",
    "\n",
    "print('\\nTop outgoing (layer2):')\n",
    "display(top_outgoing(attn_l2, node_idx=node_idx, k=20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collect temporal attention for selected days\n",
    "# Sample every 4 timesteps (1 hour intervals if data is 15-min)\n",
    "SAMPLE_INTERVAL = 4\n",
    "\n",
    "selected_sample_indices = []\n",
    "for start, end in selected_day_ranges:\n",
    "    day_samples = list(range(start, end, SAMPLE_INTERVAL))\n",
    "    selected_sample_indices.extend(day_samples)\n",
    "\n",
    "print(f\"Collecting attention for {len(selected_sample_indices)} samples\")\n",
    "print(f\"Sample indices range: {min(selected_sample_indices)} to {max(selected_sample_indices)}\")\n",
    "\n",
    "# Collect temporal attention for both layers\n",
    "print(\"\\nCollecting Layer 1 temporal attention...\")\n",
    "temporal_l1 = collect_temporal_attention(test_h, selected_sample_indices, layer='layer1', device=device)\n",
    "print(f\"Collected {len(temporal_l1)} temporal snapshots for layer1\")\n",
    "\n",
    "print(\"\\nCollecting Layer 2 temporal attention...\")\n",
    "temporal_l2 = collect_temporal_attention(test_h, selected_sample_indices, layer='layer2', device=device)\n",
    "print(f\"Collected {len(temporal_l2)} temporal snapshots for layer2\")\n",
    "\n",
    "# Sort by sample index\n",
    "temporal_l1 = sorted(temporal_l1, key=lambda x: x['sample_idx'])\n",
    "temporal_l2 = sorted(temporal_l2, key=lambda x: x['sample_idx'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13",
   "metadata": {},
   "source": [
    "## Collect Temporal Attention Scores\n",
    "\n",
    "Collect attention scores at different time points for temporal visualization.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate model with all metrics (ZINB NLL, MSE, and Huber Loss)\n",
    "@torch.no_grad()\n",
    "def detailed_evaluation(model, data_loader, device, split_name=\"Val\"):\n",
    "    \"\"\"Evaluate model with ZINB NLL, MSE, and Huber Loss.\"\"\"\n",
    "    device = torch.device(device)\n",
    "    model.eval()\n",
    "\n",
    "    num_nodes = None\n",
    "    node_valid_counts = None\n",
    "    node_total_counts = None\n",
    "\n",
    "    total_zinb_nll = 0.0\n",
    "    total_mse = 0.0\n",
    "    total_huber = 0.0\n",
    "    num_batches = 0\n",
    "\n",
    "    all_preds = []\n",
    "    all_params = []\n",
    "\n",
    "    for X_spatial, _, y_batch in data_loader:\n",
    "        X_batch = X_spatial.to(device)\n",
    "        y_batch = y_batch.to(device)\n",
    "\n",
    "        if num_nodes is None:\n",
    "                num_nodes = y_batch.shape[2]\n",
    "                node_valid_counts = torch.zeros(num_nodes)\n",
    "                node_total_counts = torch.zeros(num_nodes)\n",
    "\n",
    "        # 4. Unnormalize the target variable\n",
    "        # y_raw = (y_batch_normalized * sigma) + mu\n",
    "        y_raw = (y_batch * SCALER_SIGMA) + SCALER_MU # Using your notebook's variable name\n",
    "\n",
    "        # 5. Round to nearest integer and cast to long\n",
    "        # This is ESSENTIAL for the ZINB loss function\n",
    "        y_raw_int = torch.round(y_raw).long()\n",
    "\n",
    "        preds, zinb_nll, mse, huber, params = model(\n",
    "            X_batch=X_batch,\n",
    "            targets=y_raw_int,\n",
    "            node_mask=None,\n",
    "            edge_index=edge_index,      # ← Add this\n",
    "            edge_attr=edge_attr,        # ← Add this\n",
    "            static_node_features=static_features,  # ← Add this\n",
    "            return_attention=True\n",
    "        )\n",
    "\n",
    "        all_preds.append(preds.cpu())\n",
    "        all_params.append(params)\n",
    "\n",
    "        if zinb_nll is not None:\n",
    "            total_zinb_nll += zinb_nll.item()\n",
    "            total_mse += mse.item()\n",
    "            total_huber += huber.item()\n",
    "            num_batches += 1\n",
    "\n",
    "            nan_mask = ~torch.isnan(y_batch)\n",
    "            node_valid_counts += nan_mask.sum(dim=(0, 1, 3)).cpu()\n",
    "            node_total_counts += torch.ones_like(node_valid_counts) * y_batch.shape[0]\n",
    "\n",
    "    if num_batches > 0:\n",
    "        avg_zinb_nll = total_zinb_nll / num_batches\n",
    "        avg_mse = total_mse / num_batches\n",
    "        avg_huber = total_huber / num_batches\n",
    "\n",
    "        print(f'\\n{split_name} Set Metrics:')\n",
    "        print(f'  ZINB NLL:   {avg_zinb_nll:.4f}')\n",
    "        print(f'  MSE:        {avg_mse:.4f}')\n",
    "        print(f'  Huber Loss: {avg_huber:.4f}')\n",
    "        print(f'  Batches:    {num_batches}')\n",
    "\n",
    "        # Per-node statistics\n",
    "        node_valid_pct = (node_valid_counts / node_total_counts * 100)\n",
    "        print(f\"\\n  Node Validity Statistics:\")\n",
    "        print(f\"    Min: {node_valid_pct.min():.1f}%\")\n",
    "        print(f\"    Max: {node_valid_pct.max():.1f}%\")\n",
    "        print(f\"    Mean: {node_valid_pct.mean():.1f}%\")\n",
    "        print(f\"    Nodes with 100% valid: {(node_valid_pct == 100).sum().item()}/{num_nodes}\")\n",
    "        print(f\"    Nodes with <50% valid: {(node_valid_pct < 50).sum().item()}/{num_nodes}\")\n",
    "\n",
    "        return all_preds, all_params\n",
    "\n",
    "# Run evaluation on all splits\n",
    "train_metrics = detailed_evaluation(model, train_h, device=device, split_name='Train')\n",
    "val_metrics = detailed_evaluation(model, val_h, device=device, split_name='Validation')\n",
    "test_metrics = detailed_evaluation(model, test_h, device=device, split_name='Test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save attention scores to JSON for visualization\n",
    "output_data = {\n",
    "    'layer1': {},\n",
    "    'layer2': {},\n",
    "    'nodes': id_to_name,\n",
    "    'temporal': {\n",
    "        'layer1': temporal_l1,\n",
    "        'layer2': temporal_l2,\n",
    "        'samples_per_day': SAMPLES_PER_DAY,\n",
    "        'sample_interval': SAMPLE_INTERVAL,\n",
    "        'selected_days': selected_days\n",
    "    }\n",
    "}\n",
    "\n",
    "# Convert layer1 attention to JSON format (averaged)\n",
    "for _, row in attn_l1.iterrows():\n",
    "    edge_key = f\"{row['src']}_{row['dst']}\"\n",
    "    output_data['layer1'][edge_key] = {\n",
    "        'source': int(row['src']),\n",
    "        'target': int(row['dst']),\n",
    "        'source_name': row['src_name'],\n",
    "        'target_name': row['dst_name'],\n",
    "        'score': float(row['attn_mean'])\n",
    "    }\n",
    "\n",
    "# Convert layer2 attention to JSON format (averaged)\n",
    "for _, row in attn_l2.iterrows():\n",
    "    edge_key = f\"{row['src']}_{row['dst']}\"\n",
    "    output_data['layer2'][edge_key] = {\n",
    "        'source': int(row['src']),\n",
    "        'target': int(row['dst']),\n",
    "        'source_name': row['src_name'],\n",
    "        'target_name': row['dst_name'],\n",
    "        'score': float(row['attn_mean'])\n",
    "    }\n",
    "\n",
    "# Save to JSON file\n",
    "with open('attention_scores.json', 'w') as f:\n",
    "    json.dump(output_data, f, indent=2)\n",
    "\n",
    "print(f'Attention scores saved to: attention_scores.json')\n",
    "print(f'Layer 1 edges (averaged): {len(output_data[\"layer1\"])}')\n",
    "print(f'Layer 2 edges (averaged): {len(output_data[\"layer2\"])}')\n",
    "print(f'Temporal snapshots layer 1: {len(temporal_l1)}')\n",
    "print(f'Temporal snapshots layer 2: {len(temporal_l2)}')\n",
    "print(f'Nodes: {len(output_data[\"nodes\"])}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize attention scores on graph\n",
    "import matplotlib.pyplot as plt\n",
    "import networkx as nx\n",
    "from matplotlib.colors import Normalize\n",
    "from matplotlib.cm import ScalarMappable\n",
    "\n",
    "def plot_attention_graph(attn_df, layer_name='Layer 2', top_k=100, figsize=(20, 16)):\n",
    "    \"\"\"\n",
    "    Plot a graph visualization with edges colored by attention scores.\n",
    "\n",
    "    Parameters:\n",
    "    - attn_df: DataFrame with columns src, dst, attn_mean, src_name, dst_name\n",
    "    - layer_name: Name for the plot title\n",
    "    - top_k: Number of top edges to display (to avoid clutter)\n",
    "    - figsize: Figure size tuple\n",
    "    \"\"\"\n",
    "    # Take top_k edges by attention score\n",
    "    df_plot = attn_df.head(top_k).copy()\n",
    "\n",
    "    # Create directed graph\n",
    "    G = nx.DiGraph()\n",
    "\n",
    "    # Add nodes with names\n",
    "    all_nodes = set(df_plot['src'].tolist() + df_plot['dst'].tolist())\n",
    "    for node_id in all_nodes:\n",
    "        node_name = id_to_name.get(int(node_id), str(node_id))\n",
    "        G.add_node(node_id, label=node_name)\n",
    "\n",
    "    # Add edges with attention weights\n",
    "    edge_weights = []\n",
    "    for _, row in df_plot.iterrows():\n",
    "        G.add_edge(row['src'], row['dst'], weight=row['attn_mean'])\n",
    "        edge_weights.append(row['attn_mean'])\n",
    "\n",
    "    # Setup figure\n",
    "    fig, ax = plt.subplots(figsize=figsize)\n",
    "\n",
    "    # Layout - using spring layout for better visualization\n",
    "    # You can try: spring_layout, kamada_kawai_layout, circular_layout\n",
    "    pos = nx.spring_layout(G, k=2, iterations=50, seed=42)\n",
    "\n",
    "    # Normalize edge weights for coloring\n",
    "    norm = Normalize(vmin=min(edge_weights), vmax=max(edge_weights))\n",
    "    cmap = plt.cm.YlOrRd  # Yellow to Red colormap\n",
    "\n",
    "    # Draw nodes\n",
    "    nx.draw_networkx_nodes(\n",
    "        G, pos,\n",
    "        node_color='lightblue',\n",
    "        node_size=800,\n",
    "        alpha=0.9,\n",
    "        ax=ax\n",
    "    )\n",
    "\n",
    "    # Draw edges with colors based on attention scores\n",
    "    edges = G.edges()\n",
    "    colors = [G[u][v]['weight'] for u, v in edges]\n",
    "\n",
    "    nx.draw_networkx_edges(\n",
    "        G, pos,\n",
    "        edgelist=edges,\n",
    "        edge_color=colors,\n",
    "        edge_cmap=cmap,\n",
    "        edge_vmin=min(edge_weights),\n",
    "        edge_vmax=max(edge_weights),\n",
    "        width=2,\n",
    "        alpha=0.6,\n",
    "        arrows=True,\n",
    "        arrowsize=15,\n",
    "        arrowstyle='->',\n",
    "        connectionstyle='arc3,rad=0.1',\n",
    "        ax=ax\n",
    "    )\n",
    "\n",
    "    # Draw labels\n",
    "    labels = nx.get_node_attributes(G, 'label')\n",
    "    nx.draw_networkx_labels(\n",
    "        G, pos,\n",
    "        labels=labels,\n",
    "        font_size=8,\n",
    "        font_weight='bold',\n",
    "        ax=ax\n",
    "    )\n",
    "\n",
    "    # Add colorbar\n",
    "    sm = ScalarMappable(cmap=cmap, norm=norm)\n",
    "    sm.set_array([])\n",
    "    cbar = plt.colorbar(sm, ax=ax, fraction=0.046, pad=0.04)\n",
    "    cbar.set_label('Attention Score', rotation=270, labelpad=20, fontsize=12)\n",
    "\n",
    "    ax.set_title(f'{layer_name} Attention Scores (Top {top_k} Edges)',\n",
    "                 fontsize=16, fontweight='bold', pad=20)\n",
    "    ax.axis('off')\n",
    "    plt.tight_layout()\n",
    "\n",
    "    return fig, ax, G\n",
    "\n",
    "# Plot both layers\n",
    "print('Plotting Layer 1 attention...')\n",
    "fig1, ax1, G1 = plot_attention_graph(attn_l1, layer_name='Layer 1', top_k=100)\n",
    "plt.savefig('attention_layer1_graph.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print('\\nPlotting Layer 2 attention...')\n",
    "fig2, ax2, G2 = plot_attention_graph(attn_l2, layer_name='Layer 2', top_k=100)\n",
    "plt.savefig('attention_layer2_graph.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(f'\\nGraphs saved as attention_layer1_graph.png and attention_layer2_graph.png')\n",
    "print(f'Layer 1: {G1.number_of_nodes()} nodes, {G1.number_of_edges()} edges')\n",
    "print(f'Layer 2: {G2.number_of_nodes()} nodes, {G2.number_of_edges()} edges')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_params(params):\n",
    "    params_cat = {\"mu\":[], \"theta\":[], \"pi\": []}\n",
    "    for batch in params:\n",
    "        for key in params_cat.keys():\n",
    "            value = batch[key]\n",
    "            params_cat[key].append(value)\n",
    "\n",
    "    for key in params_cat.keys():\n",
    "        params_cat[key] = torch.cat(params_cat[key], dim=0)\n",
    "\n",
    "    # Return as tuple for easy unpacking\n",
    "    return params_cat[\"mu\"], params_cat[\"theta\"], params_cat[\"pi\"]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
