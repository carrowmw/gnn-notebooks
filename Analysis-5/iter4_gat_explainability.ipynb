{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "\n",
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GATv2Conv\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "torch.set_printoptions(sci_mode=False)\n",
    "print('torch:', torch.__version__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paths (relative to Test-2/)\n",
    "PROCESSED_DIR = Path('../Test-5/data/training/processed/c56f869b05279744')\n",
    "CKPT_PATH = Path('../Test-5/data/models/iter4_gat.pth')\n",
    "\n",
    "assert PROCESSED_DIR.exists(), f'Missing processed dir: {PROCESSED_DIR.resolve()}'\n",
    "print('processed dir:', PROCESSED_DIR.resolve())\n",
    "print('checkpoint exists:', CKPT_PATH.exists(), '|', CKPT_PATH.resolve())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load processed tensors/loaders\n",
    "edge_index = torch.load(PROCESSED_DIR / 'edge_index.pt', weights_only=False)\n",
    "edge_attr = torch.load(PROCESSED_DIR / 'edge_attr.pt', weights_only=False)\n",
    "static_features = torch.load(PROCESSED_DIR / 'static_features.pt', weights_only=False)\n",
    "sensor_mask = torch.load(PROCESSED_DIR / 'sensor_mask.pt', weights_only=False)\n",
    "train_loader = torch.load(PROCESSED_DIR / 'train_loader.pt', weights_only=False)\n",
    "val_loader = torch.load(PROCESSED_DIR / 'val_loader.pt', weights_only=False)\n",
    "test_loader = torch.load(PROCESSED_DIR / 'test_loader.pt', weights_only=False)\n",
    "\n",
    "with open(PROCESSED_DIR / 'sensor_name_to_id_map.json', 'r') as f:\n",
    "    name_to_id = json.load(f)\n",
    "id_to_name = {int(v): k for k, v in name_to_id.items()}\n",
    "\n",
    "print('edge_index:', tuple(edge_index.shape))\n",
    "print('edge_attr :', tuple(edge_attr.shape))\n",
    "print('static_features:', tuple(static_features.shape))\n",
    "print('sensor_mask:', tuple(sensor_mask.shape), '| dtype:', sensor_mask.dtype)\n",
    "print('train batches:', len(train_loader), 'val:', len(val_loader), 'test:', len(test_loader))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The training notebook uses these scalers for unnormalizing targets before ZINB loss.\n",
    "# Keep them here so forward() can be called the same way if you want loss values.\n",
    "SCALER_MU = 14.323774337768555\n",
    "SCALER_SIGMA = 34.9963493347168\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select 3 random days from test set for temporal analysis\n",
    "# Assuming data is sampled at 15-minute intervals, 96 samples per day\n",
    "SAMPLES_PER_DAY = 96\n",
    "NUM_DAYS = 3\n",
    "BATCH_SIZE = 16\n",
    "\n",
    "# Get total samples in test set\n",
    "total_test_samples = len(test_loader) * BATCH_SIZE\n",
    "total_days = total_test_samples // SAMPLES_PER_DAY\n",
    "\n",
    "print(f\"Total test samples: {total_test_samples}\")\n",
    "print(f\"Total days in test set: {total_days}\")\n",
    "print(f\"Samples per day: {SAMPLES_PER_DAY}\")\n",
    "\n",
    "# Randomly select 3 days\n",
    "import random\n",
    "random.seed(42)  # For reproducibility\n",
    "selected_days = sorted(random.sample(range(total_days), min(NUM_DAYS, total_days)))\n",
    "selected_day_ranges = [(day * SAMPLES_PER_DAY, (day + 1) * SAMPLES_PER_DAY) for day in selected_days]\n",
    "\n",
    "print(f\"\\nSelected days: {selected_days}\")\n",
    "print(f\"Sample ranges: {selected_day_ranges}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5",
   "metadata": {},
   "source": [
    "## Sample Selection for Temporal Analysis\n",
    "\n",
    "Select a random subset of days from the test set for temporal attention analysis.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Same helper as in iter2_gat.ipynb (needed to match checkpoint state_dict structure)\n",
    "def prepare_hybrid_loader(loader, batch_size: int):\n",
    "    all_batches = [(X, y) for X, y in loader]\n",
    "\n",
    "    # Temporal component (unused by this Iter2 model, but kept for dataset structure)\n",
    "    X_temporal_list = [(X[:, :, :, -1:]) for X, _ in all_batches]\n",
    "    X_temporal = torch.cat(X_temporal_list, dim=0)\n",
    "\n",
    "    # Spatial component for GAT\n",
    "    X_agg_list = [(X[:, 0:1, :, :-1]) for X, _ in all_batches]  # 9 aggregated stats\n",
    "    X_raw_list = [(X[:, :, :, -1:].permute(0, 3, 2, 1)) for X, _ in all_batches]  # 12 raw timesteps\n",
    "    X_agg = torch.cat(X_agg_list, dim=0)\n",
    "    X_raw = torch.cat(X_raw_list, dim=0)\n",
    "    X_spatial = torch.cat([X_agg, X_raw], dim=3)  # 9 + 12 = 21\n",
    "\n",
    "    y_list = [y[:, 0:1, :, :] for _, y in all_batches]\n",
    "    y_target = torch.cat(y_list, dim=0)\n",
    "\n",
    "    dataset = torch.utils.data.TensorDataset(X_spatial, X_temporal, y_target)\n",
    "    hybrid_loader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, shuffle=False, drop_last=True)\n",
    "    return hybrid_loader\n",
    "\n",
    "train_h = prepare_hybrid_loader(train_loader, batch_size=16)\n",
    "val_h = prepare_hybrid_loader(val_loader, batch_size=16)\n",
    "test_h = prepare_hybrid_loader(test_loader, batch_size=16)\n",
    "\n",
    "X_spatial, X_temporal, y = next(iter(test_h))\n",
    "print('X_spatial:', tuple(X_spatial.shape), 'X_temporal:', tuple(X_temporal.shape), 'y:', tuple(y.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model (state_dict-compatible with Test-2/iter2_gat.ipynb)\n",
    "def _finite_stats(name, t: torch.Tensor | None) -> bool:\n",
    "    if t is None:\n",
    "        print(f'[DEBUG] {name}: None')\n",
    "        return False\n",
    "    is_finite = torch.isfinite(t)\n",
    "    if not is_finite.all():\n",
    "        n_nan = torch.isnan(t).sum().item()\n",
    "        n_inf = torch.isinf(t).sum().item()\n",
    "        print(f'[NON-FINITE] {name}: nan={n_nan}, inf={n_inf}, shape={tuple(t.shape)}')\n",
    "        return False\n",
    "    return True\n",
    "\n",
    "def _check(name, t: torch.Tensor | None):\n",
    "    _finite_stats(name, t)\n",
    "\n",
    "class DynamicNodeGATZINB(nn.Module):\n",
    "    def __init__(self, dynamic_node_dim, static_node_dim, edge_dim, n_embd, n_heads, dropout_rate):\n",
    "        super().__init__()\n",
    "\n",
    "        dynamic_input_dim = dynamic_node_dim * 2\n",
    "        gat1_input_channels = dynamic_input_dim + static_node_dim\n",
    "\n",
    "        self.gat1 = GATv2Conv(\n",
    "            in_channels=gat1_input_channels,\n",
    "            out_channels=n_embd,\n",
    "            edge_dim=edge_dim,\n",
    "            heads=n_heads,\n",
    "            concat=False,\n",
    "            dropout=dropout_rate,\n",
    "        )\n",
    "        self.gat2 = GATv2Conv(\n",
    "            in_channels=n_embd,\n",
    "            out_channels=n_embd,\n",
    "            edge_dim=edge_dim,\n",
    "            heads=n_heads,\n",
    "            concat=False,\n",
    "            dropout=dropout_rate,\n",
    "        )\n",
    "        self.norm = nn.LayerNorm(n_embd)\n",
    "\n",
    "        self.mu_head = nn.Linear(n_embd, 1)\n",
    "        self.theta_head = nn.Linear(n_embd, 1)\n",
    "        self.pi_head = nn.Linear(n_embd, 1)\n",
    "\n",
    "        self.elu = nn.ELU()\n",
    "        self.dropout = nn.Dropout(dropout_rate)\n",
    "\n",
    "        # NO register_buffer calls!\n",
    "\n",
    "    def forward(self, X_batch, targets, node_mask, edge_index, edge_attr, static_node_features, return_attention=False):\n",
    "        mu_list, theta_list, pi_list = [], [], []\n",
    "        attn = {}\n",
    "\n",
    "        missing_mask = torch.isnan(X_batch)\n",
    "        imputed_X = torch.nan_to_num(X_batch, nan=0.0)\n",
    "        mask_features = missing_mask.float()\n",
    "        combined_input = torch.cat([imputed_X, mask_features], dim=-1)\n",
    "\n",
    "        B = combined_input.shape[0]\n",
    "        Xb = combined_input[:, 0, :, :]\n",
    "\n",
    "        for b in range(B):\n",
    "            combined_features = torch.cat([Xb[b], static_node_features], dim=-1)\n",
    "            xb = self.dropout(combined_features)\n",
    "\n",
    "            if return_attention:\n",
    "                xb, (ei1, alpha1) = self.gat1(xb, edge_index, edge_attr, return_attention_weights=True)\n",
    "                attn.setdefault('layer1', []).append((ei1, alpha1))\n",
    "            else:\n",
    "                xb = self.gat1(xb, self.edge_index, self.edge_attr)\n",
    "\n",
    "            xb = self.norm(xb)\n",
    "            xb = self.elu(xb)\n",
    "            xb = self.dropout(xb)\n",
    "\n",
    "            if return_attention:\n",
    "                xb, (ei2, alpha2) = self.gat2(xb, edge_index,\n",
    "                edge_attr, return_attention_weights=True)\n",
    "                attn.setdefault('layer2', []).append((ei2, alpha2))\n",
    "            else:\n",
    "                xb = self.gat2(xb, self.edge_index, self.edge_attr)\n",
    "\n",
    "            xb = self.norm(xb)\n",
    "            xb = self.elu(xb)\n",
    "            xb = self.dropout(xb)\n",
    "\n",
    "            mu_b = F.softplus(self.mu_head(xb)) + 1e-6\n",
    "            theta_b = F.softplus(self.theta_head(xb)) + 1e-6\n",
    "            pi_b = torch.sigmoid(self.pi_head(xb))\n",
    "            pi_b = torch.clamp(pi_b, min=1e-6, max=1 - 1e-6)\n",
    "\n",
    "            mu_list.append(mu_b)\n",
    "            theta_list.append(theta_b)\n",
    "            pi_list.append(pi_b)\n",
    "\n",
    "        mu = torch.stack(mu_list, dim=0).unsqueeze(1)\n",
    "        theta = torch.stack(theta_list, dim=0).unsqueeze(1)\n",
    "        pi = torch.stack(pi_list, dim=0).unsqueeze(1)\n",
    "\n",
    "        preds = mu * (1 - pi)\n",
    "\n",
    "        if targets is None:\n",
    "            zinb_nll_loss = None\n",
    "            mse_loss = None\n",
    "            huber_loss = None\n",
    "            valid_sum = torch.tensor(0.0, device=preds.device)\n",
    "        else:\n",
    "            zinb_nll_loss, valid_sum = self.zinb_nll_loss(mu, theta, pi, targets, node_mask)\n",
    "            mse_loss, _ = self.mse_loss(preds, targets, node_mask)\n",
    "            huber_loss, _ = self.mse_loss(preds, targets, node_mask)\n",
    "\n",
    "        extra = {'mu': mu, 'theta': theta, 'pi': pi, 'valid_sum': valid_sum}\n",
    "        if return_attention:\n",
    "            extra['attn'] = attn\n",
    "\n",
    "        return preds, zinb_nll_loss, mse_loss, huber_loss, extra\n",
    "\n",
    "    def zinb_nll_loss(self, mu, theta, pi, targets, node_mask):\n",
    "        eps = 1e-8\n",
    "        nan_mask = ~torch.isnan(targets)\n",
    "        valid_mask = nan_mask & node_mask if node_mask is not None else nan_mask\n",
    "        if valid_mask.sum() == 0:\n",
    "            return torch.tensor(0.0, device=mu.device, requires_grad=True), torch.tensor(0.0, device=mu.device)\n",
    "\n",
    "        mu_valid = mu[valid_mask]\n",
    "        theta_valid = theta[valid_mask]\n",
    "        pi_valid = pi[valid_mask]\n",
    "        targets_valid = targets[valid_mask]\n",
    "\n",
    "        theta_mu = theta_valid + mu_valid\n",
    "        nb_log_prob = (\n",
    "            torch.lgamma(theta_valid + targets_valid + eps)\n",
    "            - torch.lgamma(theta_valid + eps)\n",
    "            - torch.lgamma(targets_valid + 1)\n",
    "            + theta_valid * torch.log(theta_valid + eps)\n",
    "            - theta_valid * torch.log(theta_mu + eps)\n",
    "            + targets_valid * torch.log(mu_valid + eps)\n",
    "            - targets_valid * torch.log(theta_mu + eps)\n",
    "        )\n",
    "\n",
    "        zero_mask = (targets_valid < eps).float()\n",
    "        nb_zero_prob = theta_valid * torch.log(theta_valid / (theta_mu + eps))\n",
    "        zero_log_prob = torch.log(pi_valid + (1 - pi_valid) * torch.exp(nb_zero_prob) + eps)\n",
    "        non_zero_log_prob = torch.log(1 - pi_valid + eps) + nb_log_prob\n",
    "        log_prob = zero_mask * zero_log_prob + (1 - zero_mask) * non_zero_log_prob\n",
    "        nll = -log_prob.mean()\n",
    "        return nll, valid_mask.sum()\n",
    "\n",
    "    def mse_loss(self, predictions, targets, node_mask):\n",
    "        nan_mask = ~torch.isnan(targets)\n",
    "        valid_mask = nan_mask & node_mask if node_mask is not None else nan_mask\n",
    "        if valid_mask.sum() == 0:\n",
    "            return torch.tensor(0.0, device=predictions.device, requires_grad=True), 0\n",
    "        preds_valid = predictions[valid_mask]\n",
    "        targets_valid = targets[valid_mask]\n",
    "        mse_loss = ((targets_valid - preds_valid) ** 2).mean()\n",
    "        return mse_loss, valid_mask.sum()\n",
    "\n",
    "    def huber_loss(self, predictions, targets, node_mask, delta=1.0):\n",
    "        \"\"\"\n",
    "        Huber loss (smooth L1 loss) - less sensitive to outliers than MSE.\n",
    "\n",
    "        Args:\n",
    "            predictions: Model predictions\n",
    "            targets: Ground truth values\n",
    "            node_mask: Mask for valid nodes\n",
    "            delta: Threshold at which to switch from quadratic to linear loss\n",
    "        \"\"\"\n",
    "        nan_mask = ~torch.isnan(targets)\n",
    "        valid_mask = nan_mask & node_mask if node_mask is not None else nan_mask\n",
    "        if valid_mask.sum() == 0:\n",
    "            return torch.tensor(0.0, device=predictions.device, requires_grad=True), 0\n",
    "\n",
    "        preds_valid = predictions[valid_mask]\n",
    "        targets_valid = targets[valid_mask]\n",
    "\n",
    "        # Huber loss formula\n",
    "        diff = torch.abs(targets_valid - preds_valid)\n",
    "        huber = torch.where(\n",
    "            diff < delta,\n",
    "            0.5 * diff ** 2,\n",
    "            delta * (diff - 0.5 * delta)\n",
    "        )\n",
    "        huber_loss = huber.mean()\n",
    "\n",
    "        return huber_loss, valid_mask.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Training expectations:\")\n",
    "print(\"  Dynamic features: 21\")\n",
    "print(\"  Static features: Should be 13\")\n",
    "print(f\"\\nValidation data:\")\n",
    "print(f\"  Dynamics features shape: {X_spatial.shape}\")\n",
    "print(f\"  Static features shape: {static_features.shape}\")\n",
    "print(f\"  Expected input to GAT1: {21*2 + static_features.shape[1]}\")\n",
    "print(f\"  Model GAT1 expects: 55\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate + load checkpoint\n",
    "device = torch.device('cpu')\n",
    "\n",
    "n_embd = 32\n",
    "n_heads = 4\n",
    "dropout = 0.1\n",
    "\n",
    "# Update model instantiation (remove graph data from constructor):\n",
    "model = DynamicNodeGATZINB(\n",
    "    dynamic_node_dim=21,\n",
    "    static_node_dim=static_features.shape[1],\n",
    "    edge_dim=edge_attr.shape[1],\n",
    "    n_embd=n_embd,\n",
    "    n_heads=n_heads,\n",
    "    dropout_rate=dropout,\n",
    ").to(device)\n",
    "\n",
    "# Load checkpoint - this will work if layer dimensions match\n",
    "if CKPT_PATH.exists():\n",
    "    state = torch.load(CKPT_PATH, map_location=device, weights_only=False)\n",
    "    missing, unexpected = model.load_state_dict(state, strict=False)\n",
    "    print('Loaded checkpoint:', CKPT_PATH)\n",
    "\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Attention aggregation utilities\n",
    "from collections import defaultdict\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def _alpha_mean_per_edge(alpha: torch.Tensor) -> torch.Tensor:\n",
    "    \"\"\"Return per-edge attention scalar by averaging over heads.\"\"\"\n",
    "    # Expected shapes: [E, heads] or [E] (rare)\n",
    "    if alpha.dim() == 2:\n",
    "        return alpha.mean(dim=1)\n",
    "    return alpha.view(alpha.shape[0], -1).mean(dim=1)\n",
    "\n",
    "@torch.no_grad()\n",
    "def collect_attention_stats(loader, max_batches=10, layer='layer2', device='cpu'):\n",
    "    \"\"\"Collect averaged attention statistics across batches.\"\"\"\n",
    "    device = torch.device(device)\n",
    "    model.eval()\n",
    "    sums = defaultdict(float)\n",
    "    counts = defaultdict(int)\n",
    "\n",
    "    n_batches = 0\n",
    "    for X_spatial, _, y_batch in loader:\n",
    "        X_batch = X_spatial.to(device)\n",
    "        y_batch = y_batch.to(device)\n",
    "        y_raw = (y_batch * SCALER_SIGMA) + SCALER_MU\n",
    "        y_raw_int = torch.round(y_raw).long()\n",
    "\n",
    "        # Pass graph data explicitly:\n",
    "        _, _, _, _, extra = model(\n",
    "            X_batch=X_batch,\n",
    "            targets=y_raw_int,\n",
    "            node_mask=None,\n",
    "            edge_index=edge_index,\n",
    "            edge_attr=edge_attr,\n",
    "            static_node_features=static_features,\n",
    "            return_attention=True\n",
    "        )\n",
    "\n",
    "        attn_dict = extra.get('attn', {})\n",
    "        pairs = attn_dict.get(layer, [])\n",
    "        # pairs is a list over samples in the batch (because model loops over B)\n",
    "        for ei, alpha in pairs:\n",
    "            ei = ei.detach().cpu()\n",
    "            alpha = alpha.detach().cpu()\n",
    "            w = _alpha_mean_per_edge(alpha)\n",
    "            src = ei[0].to(torch.long)\n",
    "            dst = ei[1].to(torch.long)\n",
    "            for s, d, ww in zip(src.tolist(), dst.tolist(), w.tolist()):\n",
    "                key = (int(s), int(d))\n",
    "                sums[key] += float(ww)\n",
    "                counts[key] += 1\n",
    "        n_batches += 1\n",
    "        if n_batches >= max_batches:\n",
    "            break\n",
    "    rows = []\n",
    "    for (s, d), total in sums.items():\n",
    "        c = counts[(s, d)]\n",
    "        rows.append({\n",
    "            'src': s,\n",
    "            'dst': d,\n",
    "            'attn_mean': total / max(c, 1),\n",
    "            'count': c,\n",
    "            'src_name': id_to_name.get(s, str(s)),\n",
    "            'dst_name': id_to_name.get(d, str(d)),\n",
    "        })\n",
    "    df = pd.DataFrame(rows)\n",
    "    if len(df) == 0:\n",
    "        return df\n",
    "    df = df.sort_values(['attn_mean', 'count'], ascending=[False, False]).reset_index(drop=True)\n",
    "    return df\n",
    "\n",
    "@torch.no_grad()\n",
    "def collect_temporal_attention(loader, sample_indices, layer='layer2', device='cpu'):\n",
    "    \"\"\"\n",
    "    Collect attention scores for specific samples (temporal snapshots).\n",
    "\n",
    "    Args:\n",
    "        loader: DataLoader\n",
    "        sample_indices: List of sample indices to extract\n",
    "        layer: Which attention layer to extract\n",
    "        device: Device to run on\n",
    "\n",
    "    Returns:\n",
    "        List of dicts, each containing attention for one sample\n",
    "    \"\"\"\n",
    "    device = torch.device(device)\n",
    "    model.eval()\n",
    "\n",
    "    temporal_data = []\n",
    "    current_sample_idx = 0\n",
    "\n",
    "    for X_spatial, _, y_batch in loader:\n",
    "        X_batch = X_spatial.to(device)\n",
    "        y_batch = y_batch.to(device)\n",
    "        y_raw = (y_batch * SCALER_SIGMA) + SCALER_MU\n",
    "        y_raw_int = torch.round(y_raw).long()\n",
    "\n",
    "        batch_size = X_batch.shape[0]\n",
    "\n",
    "        # Pass graph data explicitly:\n",
    "        _, _, _, _, extra = model(\n",
    "            X_batch=X_batch,\n",
    "            targets=y_raw_int,\n",
    "            node_mask=None,\n",
    "            edge_index=edge_index,\n",
    "            edge_attr=edge_attr,\n",
    "            static_node_features=static_features,\n",
    "            return_attention=True\n",
    "        )\n",
    "\n",
    "        attn_dict = extra.get('attn', {})\n",
    "        pairs = attn_dict.get(layer, [])\n",
    "\n",
    "        # Process each sample in the batch\n",
    "        for batch_idx, (ei, alpha) in enumerate(pairs):\n",
    "            sample_idx = current_sample_idx + batch_idx\n",
    "\n",
    "            # Only save if this sample is in our selected indices\n",
    "            if sample_idx in sample_indices:\n",
    "                ei = ei.detach().cpu()\n",
    "                alpha = alpha.detach().cpu()\n",
    "                w = _alpha_mean_per_edge(alpha)\n",
    "\n",
    "                # Build edge dictionary for this sample\n",
    "                edges = {}\n",
    "                src = ei[0].to(torch.long)\n",
    "                dst = ei[1].to(torch.long)\n",
    "\n",
    "                for s, d, ww in zip(src.tolist(), dst.tolist(), w.tolist()):\n",
    "                    edge_key = f\"{int(s)}_{int(d)}\"\n",
    "                    edges[edge_key] = {\n",
    "                        'source': int(s),\n",
    "                        'target': int(d),\n",
    "                        'source_name': id_to_name.get(int(s), str(s)),\n",
    "                        'target_name': id_to_name.get(int(d), str(d)),\n",
    "                        'score': float(ww)\n",
    "                    }\n",
    "\n",
    "                temporal_data.append({\n",
    "                    'sample_idx': sample_idx,\n",
    "                    'edges': edges\n",
    "                })\n",
    "\n",
    "        current_sample_idx += batch_size\n",
    "\n",
    "        # Stop if we've passed all selected samples\n",
    "        if current_sample_idx > max(sample_indices):\n",
    "            break\n",
    "\n",
    "    return temporal_data\n",
    "\n",
    "def top_incoming(df: pd.DataFrame, node_idx: int, k: int = 15) -> pd.DataFrame:\n",
    "    \"\"\"Top-k incoming edges by attention into node_idx.\"\"\"\n",
    "    out = df[df['dst'] == int(node_idx)].copy()\n",
    "    return out.sort_values('attn_mean', ascending=False).head(k).reset_index(drop=True)\n",
    "\n",
    "def top_outgoing(df: pd.DataFrame, node_idx: int, k: int = 15) -> pd.DataFrame:\n",
    "    \"\"\"Top-k outgoing edges by attention from node_idx.\"\"\"\n",
    "    out = df[df['src'] == int(node_idx)].copy()\n",
    "    return out.sort_values('attn_mean', ascending=False).head(k).reset_index(drop=True)\n",
    "\n",
    "print('Ready to collect attention statistics.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collect averaged attention statistics (for static view)\n",
    "MAX_BATCHES = 25\n",
    "\n",
    "attn_l1 = collect_attention_stats(test_h, max_batches=MAX_BATCHES, layer='layer1', device=device)\n",
    "attn_l2 = collect_attention_stats(test_h, max_batches=MAX_BATCHES, layer='layer2', device=device)\n",
    "\n",
    "print('layer1 edges:', len(attn_l1), '| layer2 edges:', len(attn_l2))\n",
    "\n",
    "# Top edges globally\n",
    "display(attn_l1.head(20))\n",
    "display(attn_l2.head(20))\n",
    "\n",
    "# Pick a node to inspect (0 is fine, or change to any sensor id)\n",
    "node_idx = 0\n",
    "print('Node:', node_idx, id_to_name.get(int(node_idx), str(node_idx)))\n",
    "\n",
    "print('\\nTop incoming (layer2):')\n",
    "display(top_incoming(attn_l2, node_idx=node_idx, k=20))\n",
    "\n",
    "print('\\nTop outgoing (layer2):')\n",
    "display(top_outgoing(attn_l2, node_idx=node_idx, k=20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collect temporal attention for selected days\n",
    "# Sample every 4 timesteps (1 hour intervals if data is 15-min)\n",
    "SAMPLE_INTERVAL = 4\n",
    "\n",
    "selected_sample_indices = []\n",
    "for start, end in selected_day_ranges:\n",
    "    day_samples = list(range(start, end, SAMPLE_INTERVAL))\n",
    "    selected_sample_indices.extend(day_samples)\n",
    "\n",
    "print(f\"Collecting attention for {len(selected_sample_indices)} samples\")\n",
    "print(f\"Sample indices range: {min(selected_sample_indices)} to {max(selected_sample_indices)}\")\n",
    "\n",
    "# Collect temporal attention for both layers\n",
    "print(\"\\nCollecting Layer 1 temporal attention...\")\n",
    "temporal_l1 = collect_temporal_attention(test_h, selected_sample_indices, layer='layer1', device=device)\n",
    "print(f\"Collected {len(temporal_l1)} temporal snapshots for layer1\")\n",
    "\n",
    "print(\"\\nCollecting Layer 2 temporal attention...\")\n",
    "temporal_l2 = collect_temporal_attention(test_h, selected_sample_indices, layer='layer2', device=device)\n",
    "print(f\"Collected {len(temporal_l2)} temporal snapshots for layer2\")\n",
    "\n",
    "# Sort by sample index\n",
    "temporal_l1 = sorted(temporal_l1, key=lambda x: x['sample_idx'])\n",
    "temporal_l2 = sorted(temporal_l2, key=lambda x: x['sample_idx'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13",
   "metadata": {},
   "source": [
    "## Collect Temporal Attention Scores\n",
    "\n",
    "Collect attention scores at different time points for temporal visualization.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate model with all metrics (ZINB NLL, MSE, and Huber Loss)\n",
    "@torch.no_grad()\n",
    "def detailed_evaluation(model, data_loader, device, split_name=\"Val\"):\n",
    "    \"\"\"Evaluate model with ZINB NLL, MSE, and Huber Loss.\"\"\"\n",
    "    device = torch.device(device)\n",
    "    model.eval()\n",
    "\n",
    "    num_nodes = None\n",
    "    node_valid_counts = None\n",
    "    node_total_counts = None\n",
    "\n",
    "    total_zinb_nll = 0.0\n",
    "    total_mse = 0.0\n",
    "    total_huber = 0.0\n",
    "    num_batches = 0\n",
    "\n",
    "    all_preds = []\n",
    "    all_params = []\n",
    "\n",
    "    for X_spatial, _, y_batch in data_loader:\n",
    "        X_batch = X_spatial.to(device)\n",
    "        y_batch = y_batch.to(device)\n",
    "\n",
    "        if num_nodes is None:\n",
    "                num_nodes = y_batch.shape[2]\n",
    "                node_valid_counts = torch.zeros(num_nodes)\n",
    "                node_total_counts = torch.zeros(num_nodes)\n",
    "\n",
    "        # 4. Unnormalize the target variable\n",
    "        # y_raw = (y_batch_normalized * sigma) + mu\n",
    "        y_raw = (y_batch * SCALER_SIGMA) + SCALER_MU # Using your notebook's variable name\n",
    "\n",
    "        # 5. Round to nearest integer and cast to long\n",
    "        # This is ESSENTIAL for the ZINB loss function\n",
    "        y_raw_int = torch.round(y_raw).long()\n",
    "\n",
    "        preds, zinb_nll, mse, huber, params = model(\n",
    "            X_batch=X_batch,\n",
    "            targets=y_raw_int,\n",
    "            node_mask=None,\n",
    "            edge_index=edge_index,      # ← Add this\n",
    "            edge_attr=edge_attr,        # ← Add this\n",
    "            static_node_features=static_features,  # ← Add this\n",
    "            return_attention=True\n",
    "        )\n",
    "\n",
    "        all_preds.append(preds.cpu())\n",
    "        all_params.append(params)\n",
    "\n",
    "        if zinb_nll is not None:\n",
    "            total_zinb_nll += zinb_nll.item()\n",
    "            total_mse += mse.item()\n",
    "            total_huber += huber.item()\n",
    "            num_batches += 1\n",
    "\n",
    "            nan_mask = ~torch.isnan(y_batch)\n",
    "            node_valid_counts += nan_mask.sum(dim=(0, 1, 3)).cpu()\n",
    "            node_total_counts += torch.ones_like(node_valid_counts) * y_batch.shape[0]\n",
    "\n",
    "    if num_batches > 0:\n",
    "        avg_zinb_nll = total_zinb_nll / num_batches\n",
    "        avg_mse = total_mse / num_batches\n",
    "        avg_huber = total_huber / num_batches\n",
    "\n",
    "        print(f'\\n{split_name} Set Metrics:')\n",
    "        print(f'  ZINB NLL:   {avg_zinb_nll:.4f}')\n",
    "        print(f'  MSE:        {avg_mse:.4f}')\n",
    "        print(f'  Huber Loss: {avg_huber:.4f}')\n",
    "        print(f'  Batches:    {num_batches}')\n",
    "\n",
    "        # Per-node statistics\n",
    "        node_valid_pct = (node_valid_counts / node_total_counts * 100)\n",
    "        print(f\"\\n  Node Validity Statistics:\")\n",
    "        print(f\"    Min: {node_valid_pct.min():.1f}%\")\n",
    "        print(f\"    Max: {node_valid_pct.max():.1f}%\")\n",
    "        print(f\"    Mean: {node_valid_pct.mean():.1f}%\")\n",
    "        print(f\"    Nodes with 100% valid: {(node_valid_pct == 100).sum().item()}/{num_nodes}\")\n",
    "        print(f\"    Nodes with <50% valid: {(node_valid_pct < 50).sum().item()}/{num_nodes}\")\n",
    "\n",
    "        return all_preds, all_params\n",
    "\n",
    "# Run evaluation on all splits\n",
    "train_metrics = detailed_evaluation(model, train_h, device=device, split_name='Train')\n",
    "val_metrics = detailed_evaluation(model, val_h, device=device, split_name='Validation')\n",
    "test_metrics = detailed_evaluation(model, test_h, device=device, split_name='Test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save attention scores to JSON for visualization\n",
    "output_data = {\n",
    "    'layer1': {},\n",
    "    'layer2': {},\n",
    "    'nodes': id_to_name,\n",
    "    'temporal': {\n",
    "        'layer1': temporal_l1,\n",
    "        'layer2': temporal_l2,\n",
    "        'samples_per_day': SAMPLES_PER_DAY,\n",
    "        'sample_interval': SAMPLE_INTERVAL,\n",
    "        'selected_days': selected_days\n",
    "    }\n",
    "}\n",
    "\n",
    "# Convert layer1 attention to JSON format (averaged)\n",
    "for _, row in attn_l1.iterrows():\n",
    "    edge_key = f\"{row['src']}_{row['dst']}\"\n",
    "    output_data['layer1'][edge_key] = {\n",
    "        'source': int(row['src']),\n",
    "        'target': int(row['dst']),\n",
    "        'source_name': row['src_name'],\n",
    "        'target_name': row['dst_name'],\n",
    "        'score': float(row['attn_mean'])\n",
    "    }\n",
    "\n",
    "# Convert layer2 attention to JSON format (averaged)\n",
    "for _, row in attn_l2.iterrows():\n",
    "    edge_key = f\"{row['src']}_{row['dst']}\"\n",
    "    output_data['layer2'][edge_key] = {\n",
    "        'source': int(row['src']),\n",
    "        'target': int(row['dst']),\n",
    "        'source_name': row['src_name'],\n",
    "        'target_name': row['dst_name'],\n",
    "        'score': float(row['attn_mean'])\n",
    "    }\n",
    "\n",
    "# Save to JSON file\n",
    "with open('attention_scores.json', 'w') as f:\n",
    "    json.dump(output_data, f, indent=2)\n",
    "\n",
    "print(f'Attention scores saved to: attention_scores.json')\n",
    "print(f'Layer 1 edges (averaged): {len(output_data[\"layer1\"])}')\n",
    "print(f'Layer 2 edges (averaged): {len(output_data[\"layer2\"])}')\n",
    "print(f'Temporal snapshots layer 1: {len(temporal_l1)}')\n",
    "print(f'Temporal snapshots layer 2: {len(temporal_l2)}')\n",
    "print(f'Nodes: {len(output_data[\"nodes\"])}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize attention scores on graph\n",
    "import matplotlib.pyplot as plt\n",
    "import networkx as nx\n",
    "from matplotlib.colors import Normalize\n",
    "from matplotlib.cm import ScalarMappable\n",
    "\n",
    "def plot_attention_graph(attn_df, layer_name='Layer 2', top_k=100, figsize=(20, 16)):\n",
    "    \"\"\"\n",
    "    Plot a graph visualization with edges colored by attention scores.\n",
    "\n",
    "    Parameters:\n",
    "    - attn_df: DataFrame with columns src, dst, attn_mean, src_name, dst_name\n",
    "    - layer_name: Name for the plot title\n",
    "    - top_k: Number of top edges to display (to avoid clutter)\n",
    "    - figsize: Figure size tuple\n",
    "    \"\"\"\n",
    "    # Take top_k edges by attention score\n",
    "    df_plot = attn_df.head(top_k).copy()\n",
    "\n",
    "    # Create directed graph\n",
    "    G = nx.DiGraph()\n",
    "\n",
    "    # Add nodes with names\n",
    "    all_nodes = set(df_plot['src'].tolist() + df_plot['dst'].tolist())\n",
    "    for node_id in all_nodes:\n",
    "        node_name = id_to_name.get(int(node_id), str(node_id))\n",
    "        G.add_node(node_id, label=node_name)\n",
    "\n",
    "    # Add edges with attention weights\n",
    "    edge_weights = []\n",
    "    for _, row in df_plot.iterrows():\n",
    "        G.add_edge(row['src'], row['dst'], weight=row['attn_mean'])\n",
    "        edge_weights.append(row['attn_mean'])\n",
    "\n",
    "    # Setup figure\n",
    "    fig, ax = plt.subplots(figsize=figsize)\n",
    "\n",
    "    # Layout - using spring layout for better visualization\n",
    "    # You can try: spring_layout, kamada_kawai_layout, circular_layout\n",
    "    pos = nx.spring_layout(G, k=2, iterations=50, seed=42)\n",
    "\n",
    "    # Normalize edge weights for coloring\n",
    "    norm = Normalize(vmin=min(edge_weights), vmax=max(edge_weights))\n",
    "    cmap = plt.cm.YlOrRd  # Yellow to Red colormap\n",
    "\n",
    "    # Draw nodes\n",
    "    nx.draw_networkx_nodes(\n",
    "        G, pos,\n",
    "        node_color='lightblue',\n",
    "        node_size=800,\n",
    "        alpha=0.9,\n",
    "        ax=ax\n",
    "    )\n",
    "\n",
    "    # Draw edges with colors based on attention scores\n",
    "    edges = G.edges()\n",
    "    colors = [G[u][v]['weight'] for u, v in edges]\n",
    "\n",
    "    nx.draw_networkx_edges(\n",
    "        G, pos,\n",
    "        edgelist=edges,\n",
    "        edge_color=colors,\n",
    "        edge_cmap=cmap,\n",
    "        edge_vmin=min(edge_weights),\n",
    "        edge_vmax=max(edge_weights),\n",
    "        width=2,\n",
    "        alpha=0.6,\n",
    "        arrows=True,\n",
    "        arrowsize=15,\n",
    "        arrowstyle='->',\n",
    "        connectionstyle='arc3,rad=0.1',\n",
    "        ax=ax\n",
    "    )\n",
    "\n",
    "    # Draw labels\n",
    "    labels = nx.get_node_attributes(G, 'label')\n",
    "    nx.draw_networkx_labels(\n",
    "        G, pos,\n",
    "        labels=labels,\n",
    "        font_size=8,\n",
    "        font_weight='bold',\n",
    "        ax=ax\n",
    "    )\n",
    "\n",
    "    # Add colorbar\n",
    "    sm = ScalarMappable(cmap=cmap, norm=norm)\n",
    "    sm.set_array([])\n",
    "    cbar = plt.colorbar(sm, ax=ax, fraction=0.046, pad=0.04)\n",
    "    cbar.set_label('Attention Score', rotation=270, labelpad=20, fontsize=12)\n",
    "\n",
    "    ax.set_title(f'{layer_name} Attention Scores (Top {top_k} Edges)',\n",
    "                 fontsize=16, fontweight='bold', pad=20)\n",
    "    ax.axis('off')\n",
    "    plt.tight_layout()\n",
    "\n",
    "    return fig, ax, G\n",
    "\n",
    "# Plot both layers\n",
    "print('Plotting Layer 1 attention...')\n",
    "fig1, ax1, G1 = plot_attention_graph(attn_l1, layer_name='Layer 1', top_k=100)\n",
    "plt.savefig('attention_layer1_graph.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print('\\nPlotting Layer 2 attention...')\n",
    "fig2, ax2, G2 = plot_attention_graph(attn_l2, layer_name='Layer 2', top_k=100)\n",
    "plt.savefig('attention_layer2_graph.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(f'\\nGraphs saved as attention_layer1_graph.png and attention_layer2_graph.png')\n",
    "print(f'Layer 1: {G1.number_of_nodes()} nodes, {G1.number_of_edges()} edges')\n",
    "print(f'Layer 2: {G2.number_of_nodes()} nodes, {G2.number_of_edges()} edges')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Completeness ↔ Attention correlation utilities (works with your DynamicNodeGATZINB(return_attention=True))\n",
    "\n",
    "import pandas as pd\n",
    "import torch\n",
    "\n",
    "def _alpha_to_edge_weight(alpha: torch.Tensor) -> torch.Tensor:\n",
    "    \"\"\"alpha: [E, heads] or [E, 1] -> w: [E]\"\"\"\n",
    "    if alpha.dim() == 2:\n",
    "        return alpha.mean(dim=1)\n",
    "    return alpha.view(alpha.shape[0], -1).mean(dim=1)\n",
    "\n",
    "def _aggregate_in_out(num_nodes: int, ei: torch.Tensor, w: torch.Tensor) -> dict[str, torch.Tensor]:\n",
    "    \"\"\"\n",
    "    Returns per-node aggregates:\n",
    "      in_sum/out_sum: sum of attention weights on incoming/outgoing edges\n",
    "      in_mean/out_mean: mean attention weight per incoming/outgoing edge\n",
    "      in_deg/out_deg: counts of incoming/outgoing edges\n",
    "    \"\"\"\n",
    "    src = ei[0].to(torch.long)\n",
    "    dst = ei[1].to(torch.long)\n",
    "    w = w.to(torch.float32)\n",
    "\n",
    "    out_sum = torch.zeros(num_nodes, dtype=torch.float32)\n",
    "    in_sum  = torch.zeros(num_nodes, dtype=torch.float32)\n",
    "    out_deg = torch.zeros(num_nodes, dtype=torch.float32)\n",
    "    in_deg  = torch.zeros(num_nodes, dtype=torch.float32)\n",
    "\n",
    "    out_sum.scatter_add_(0, src, w)\n",
    "    in_sum.scatter_add_(0, dst, w)\n",
    "\n",
    "    ones = torch.ones_like(w, dtype=torch.float32)\n",
    "    out_deg.scatter_add_(0, src, ones)\n",
    "    in_deg.scatter_add_(0, dst, ones)\n",
    "\n",
    "    out_mean = out_sum / torch.clamp(out_deg, min=1.0)\n",
    "    in_mean  = in_sum  / torch.clamp(in_deg,  min=1.0)\n",
    "\n",
    "    return {\n",
    "        \"out_sum\": out_sum, \"in_sum\": in_sum,\n",
    "        \"out_mean\": out_mean, \"in_mean\": in_mean,\n",
    "        \"out_deg\": out_deg, \"in_deg\": in_deg,\n",
    "    }\n",
    "\n",
    "def _completeness_from_temporal(\n",
    "    X_temporal: torch.Tensor,\n",
    "    *,\n",
    "    valid_def: str = \"finite_and_nonzero\",  # \"finite\", \"finite_and_nonzero\"\n",
    ") -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    X_temporal: [B, T, N, 1] (your hybrid loader)\n",
    "    Returns: completeness [B, N] in [0,1]\n",
    "    \"\"\"\n",
    "    xt = X_temporal.squeeze(-1)  # [B, T, N]\n",
    "    finite = torch.isfinite(xt)\n",
    "\n",
    "    if valid_def == \"finite\":\n",
    "        valid = finite\n",
    "    elif valid_def == \"finite_and_nonzero\":\n",
    "        valid = finite & (xt != 0)\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown valid_def={valid_def}\")\n",
    "\n",
    "    # mean over time dimension\n",
    "    return valid.float().mean(dim=1)  # [B, N]\n",
    "\n",
    "@torch.no_grad()\n",
    "def attention_completeness_dataframe(\n",
    "    model,\n",
    "    loader,                       # your hybrid loader: yields (X_spatial, X_temporal, y)\n",
    "    *,\n",
    "    edge_index: torch.Tensor,\n",
    "    edge_attr: torch.Tensor,\n",
    "    static_features: torch.Tensor,\n",
    "    layer: str = \"layer2\",        # \"layer1\" or \"layer2\"\n",
    "    max_batches: int | None = 50,\n",
    "    device: str | torch.device = \"cpu\",\n",
    "    valid_def: str = \"finite_and_nonzero\",\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Produces a long-form dataframe with rows = (sample_idx, node_idx):\n",
    "      completeness, in/out attention (sum/mean), degrees\n",
    "    \"\"\"\n",
    "    device = torch.device(device)\n",
    "    model.eval()\n",
    "\n",
    "    num_nodes = int(static_features.shape[0])\n",
    "    rows = []\n",
    "    global_sample_idx = 0\n",
    "\n",
    "    for batch_idx, (X_spatial, X_temporal, _) in enumerate(loader):\n",
    "        if (max_batches is not None) and (batch_idx >= max_batches):\n",
    "            break\n",
    "\n",
    "        X_spatial = X_spatial.to(device)\n",
    "        X_temporal = X_temporal.to(device)\n",
    "\n",
    "        # completeness per sample/node\n",
    "        comp = _completeness_from_temporal(X_temporal, valid_def=valid_def).cpu()  # [B, N]\n",
    "\n",
    "        # get per-sample attention from the model\n",
    "        _, _, _, _, extra = model(\n",
    "            X_batch=X_spatial,\n",
    "            targets=None,                # metrics not needed for correlation\n",
    "            node_mask=None,\n",
    "            edge_index=edge_index.to(device),\n",
    "            edge_attr=edge_attr.to(device),\n",
    "            static_node_features=static_features.to(device),\n",
    "            return_attention=True,\n",
    "        )\n",
    "\n",
    "        pairs = extra.get(\"attn\", {}).get(layer, [])\n",
    "        B = X_spatial.shape[0]\n",
    "        if len(pairs) != B:\n",
    "            raise RuntimeError(f\"Expected {B} attention entries for {layer}, got {len(pairs)}\")\n",
    "\n",
    "        # per-sample aggregation\n",
    "        for b in range(B):\n",
    "            ei, alpha = pairs[b]\n",
    "            ei = ei.detach().cpu()\n",
    "            alpha = alpha.detach().cpu()\n",
    "            w = _alpha_to_edge_weight(alpha)  # [E]\n",
    "\n",
    "            agg = _aggregate_in_out(num_nodes, ei, w)\n",
    "            for node in range(num_nodes):\n",
    "                rows.append({\n",
    "                    \"batch_idx\": batch_idx,\n",
    "                    \"sample_idx\": global_sample_idx + b,\n",
    "                    \"node\": node,\n",
    "                    \"completeness\": float(comp[b, node].item()),\n",
    "                    \"in_attn_sum\": float(agg[\"in_sum\"][node].item()),\n",
    "                    \"out_attn_sum\": float(agg[\"out_sum\"][node].item()),\n",
    "                    \"in_attn_mean\": float(agg[\"in_mean\"][node].item()),\n",
    "                    \"out_attn_mean\": float(agg[\"out_mean\"][node].item()),\n",
    "                    \"in_deg\": float(agg[\"in_deg\"][node].item()),\n",
    "                    \"out_deg\": float(agg[\"out_deg\"][node].item()),\n",
    "                })\n",
    "\n",
    "        global_sample_idx += B\n",
    "\n",
    "    return pd.DataFrame(rows)\n",
    "\n",
    "def summarize_attention_completeness(df: pd.DataFrame, id_to_name: dict[int, str] | None = None) -> dict[str, pd.DataFrame]:\n",
    "    \"\"\"\n",
    "    Returns:\n",
    "      - overall_corr: correlations across all (sample,node) rows\n",
    "      - per_node_corr: correlation per node across time (samples)\n",
    "    \"\"\"\n",
    "    # Overall (all rows)\n",
    "    overall = pd.DataFrame([{\n",
    "        \"pearson_comp_vs_out_sum\": df[\"completeness\"].corr(df[\"out_attn_sum\"], method=\"pearson\"),\n",
    "        \"spearman_comp_vs_out_sum\": df[\"completeness\"].corr(df[\"out_attn_sum\"], method=\"spearman\"),\n",
    "        \"pearson_comp_vs_in_sum\": df[\"completeness\"].corr(df[\"in_attn_sum\"], method=\"pearson\"),\n",
    "        \"spearman_comp_vs_in_sum\": df[\"completeness\"].corr(df[\"in_attn_sum\"], method=\"spearman\"),\n",
    "        \"pearson_comp_vs_out_mean\": df[\"completeness\"].corr(df[\"out_attn_mean\"], method=\"pearson\"),\n",
    "        \"spearman_comp_vs_out_mean\": df[\"completeness\"].corr(df[\"out_attn_mean\"], method=\"spearman\"),\n",
    "        \"pearson_comp_vs_in_mean\": df[\"completeness\"].corr(df[\"in_attn_mean\"], method=\"pearson\"),\n",
    "        \"spearman_comp_vs_in_mean\": df[\"completeness\"].corr(df[\"in_attn_mean\"], method=\"spearman\"),\n",
    "        \"n_rows\": len(df),\n",
    "    }])\n",
    "\n",
    "    # Per-node (over samples)\n",
    "    per_node = []\n",
    "    for node, g in df.groupby(\"node\"):\n",
    "        if len(g) < 3:\n",
    "            continue\n",
    "        per_node.append({\n",
    "            \"node\": node,\n",
    "            \"name\": (id_to_name.get(int(node), str(node)) if id_to_name else str(node)),\n",
    "            \"n_samples\": len(g),\n",
    "            \"spearman_comp_vs_out_sum\": g[\"completeness\"].corr(g[\"out_attn_sum\"], method=\"spearman\"),\n",
    "            \"spearman_comp_vs_in_sum\": g[\"completeness\"].corr(g[\"in_attn_sum\"], method=\"spearman\"),\n",
    "            \"spearman_comp_vs_out_mean\": g[\"completeness\"].corr(g[\"out_attn_mean\"], method=\"spearman\"),\n",
    "            \"spearman_comp_vs_in_mean\": g[\"completeness\"].corr(g[\"in_attn_mean\"], method=\"spearman\"),\n",
    "        })\n",
    "    per_node = pd.DataFrame(per_node).sort_values(\"spearman_comp_vs_out_sum\", ascending=False).reset_index(drop=True)\n",
    "\n",
    "    return {\"overall_corr\": overall, \"per_node_corr\": per_node}\n",
    "\n",
    "# --- RUN IT (recommended: layer2 on test_h) ---\n",
    "df_ac = attention_completeness_dataframe(\n",
    "    model,\n",
    "    test_h,                           # <- your hybrid loader\n",
    "    edge_index=edge_index,\n",
    "    edge_attr=edge_attr,\n",
    "    static_features=static_features,\n",
    "    layer=\"layer2\",\n",
    "    max_batches=50,\n",
    "    device=device,\n",
    "    valid_def=\"finite_and_nonzero\",    # change to \"finite\" if zeros are valid readings\n",
    ")\n",
    "\n",
    "summary = summarize_attention_completeness(df_ac, id_to_name=id_to_name)\n",
    "display(summary[\"overall_corr\"])\n",
    "display(summary[\"per_node_corr\"].head(15))\n",
    "\n",
    "# Optional quick sanity plots\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(6, 4))\n",
    "plt.scatter(df_ac[\"completeness\"], df_ac[\"out_attn_sum\"], s=6, alpha=0.25)\n",
    "plt.xlabel(\"Completeness (per node, per sample)\")\n",
    "plt.ylabel(\"Out-degree attention (sum)\")\n",
    "plt.title(\"Completeness vs Out Attention (Layer2)\")\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(6, 4))\n",
    "plt.scatter(df_ac[\"completeness\"], df_ac[\"in_attn_sum\"], s=6, alpha=0.25)\n",
    "plt.xlabel(\"Completeness (per node, per sample)\")\n",
    "plt.ylabel(\"In-degree attention (sum)\")\n",
    "plt.title(\"Completeness vs In Attention (Layer2)\")\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Replace your broken \"RUN IT\" cell with this ---\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def _incoming_entropy_and_max(num_nodes: int, ei: torch.Tensor, alpha: torch.Tensor, eps: float = 1e-12):\n",
    "    \"\"\"\n",
    "    Computes per-node incoming attention entropy and max attention.\n",
    "    alpha: [E, heads] (as returned by PyG when return_attention_weights=True)\n",
    "    Returns:\n",
    "      in_entropy_mean: [N] mean entropy over heads (higher = more spread over neighbors)\n",
    "      in_max_mean:     [N] mean of max incoming alpha over heads (higher = more concentrated)\n",
    "    \"\"\"\n",
    "    dst = ei[1].to(torch.long)                     # [E]\n",
    "    alpha = alpha.to(torch.float32)                # [E, H]\n",
    "    E, H = alpha.shape\n",
    "\n",
    "    # Entropy per head per dst:  H(p) = -sum_e p_e log p_e  over incoming edges for each dst\n",
    "    in_entropy = torch.zeros((num_nodes, H), dtype=torch.float32)\n",
    "    p_log_p = alpha * torch.log(alpha + eps)       # [E, H]\n",
    "    for h in range(H):\n",
    "        in_entropy[:, h].scatter_add_(0, dst, p_log_p[:, h])\n",
    "    in_entropy = -in_entropy                        # [N, H]\n",
    "\n",
    "    # Max incoming per head per dst (fallback loop; N is small so OK)\n",
    "    in_max = torch.zeros((num_nodes, H), dtype=torch.float32)\n",
    "    for e in range(E):\n",
    "        d = int(dst[e].item())\n",
    "        in_max[d] = torch.maximum(in_max[d], alpha[e])\n",
    "\n",
    "    return in_entropy.mean(dim=1), in_max.mean(dim=1)\n",
    "\n",
    "@torch.no_grad()\n",
    "def attention_completeness_dataframe_v2(\n",
    "    model,\n",
    "    loader,\n",
    "    *,\n",
    "    edge_index: torch.Tensor,\n",
    "    edge_attr: torch.Tensor,\n",
    "    static_features: torch.Tensor,\n",
    "    layer: str = \"layer2\",\n",
    "    max_batches: int | None = 50,\n",
    "    device: str | torch.device = \"cpu\",\n",
    "    valid_def: str = \"finite\",\n",
    ") -> pd.DataFrame:\n",
    "    device = torch.device(device)\n",
    "    model.eval()\n",
    "\n",
    "    num_nodes = int(static_features.shape[0])\n",
    "    rows = []\n",
    "    global_sample_idx = 0\n",
    "\n",
    "    for batch_idx, (X_spatial, X_temporal, _) in enumerate(loader):\n",
    "        if (max_batches is not None) and (batch_idx >= max_batches):\n",
    "            break\n",
    "\n",
    "        X_spatial = X_spatial.to(device)\n",
    "        X_temporal = X_temporal.to(device)\n",
    "\n",
    "        comp = _completeness_from_temporal(X_temporal, valid_def=valid_def).cpu()  # [B, N]\n",
    "\n",
    "        _, _, _, _, extra = model(\n",
    "            X_batch=X_spatial,\n",
    "            targets=None,\n",
    "            node_mask=None,\n",
    "            edge_index=edge_index.to(device),\n",
    "            edge_attr=edge_attr.to(device),\n",
    "            static_node_features=static_features.to(device),\n",
    "            return_attention=True,\n",
    "        )\n",
    "\n",
    "        pairs = extra.get(\"attn\", {}).get(layer, [])\n",
    "        B = X_spatial.shape[0]\n",
    "        if len(pairs) != B:\n",
    "            raise RuntimeError(f\"Expected {B} attention entries for {layer}, got {len(pairs)}\")\n",
    "\n",
    "        for b in range(B):\n",
    "            ei, alpha = pairs[b]\n",
    "            ei = ei.detach().cpu()\n",
    "            alpha = alpha.detach().cpu()\n",
    "\n",
    "            # Outgoing aggregates (these can vary meaningfully)\n",
    "            w = _alpha_to_edge_weight(alpha)  # [E] averaged over heads\n",
    "            agg = _aggregate_in_out(num_nodes, ei, w)\n",
    "\n",
    "            # Incoming distribution shape metrics (not constant like in_sum)\n",
    "            in_entropy_mean, in_max_mean = _incoming_entropy_and_max(num_nodes, ei, alpha)\n",
    "\n",
    "            for node in range(num_nodes):\n",
    "                rows.append({\n",
    "                    \"batch_idx\": batch_idx,\n",
    "                    \"sample_idx\": global_sample_idx + b,\n",
    "                    \"node\": node,\n",
    "                    \"completeness\": float(comp[b, node].item()),\n",
    "\n",
    "                    # Outgoing influence\n",
    "                    \"out_attn_sum\": float(agg[\"out_sum\"][node].item()),\n",
    "                    \"out_attn_mean\": float(agg[\"out_mean\"][node].item()),\n",
    "                    \"out_deg\": float(agg[\"out_deg\"][node].item()),\n",
    "\n",
    "                    # Incoming \"listener\" shape metrics\n",
    "                    \"in_attn_entropy\": float(in_entropy_mean[node].item()),\n",
    "                    \"in_attn_max\": float(in_max_mean[node].item()),\n",
    "\n",
    "                    # Keep for debugging (but don't expect correlation!)\n",
    "                    \"in_attn_sum\": float(agg[\"in_sum\"][node].item()),\n",
    "                    \"in_attn_mean\": float(agg[\"in_mean\"][node].item()),\n",
    "                    \"in_deg\": float(agg[\"in_deg\"][node].item()),\n",
    "                })\n",
    "\n",
    "        global_sample_idx += B\n",
    "\n",
    "    return pd.DataFrame(rows)\n",
    "\n",
    "def summarize_attention_completeness_v2(df: pd.DataFrame, id_to_name: dict[int, str] | None = None) -> dict[str, pd.DataFrame]:\n",
    "    overall = pd.DataFrame([{\n",
    "        \"spearman(comp, out_sum)\": df[\"completeness\"].corr(df[\"out_attn_sum\"], method=\"spearman\"),\n",
    "        \"spearman(comp, out_mean)\": df[\"completeness\"].corr(df[\"out_attn_mean\"], method=\"spearman\"),\n",
    "        \"spearman(comp, in_entropy)\": df[\"completeness\"].corr(df[\"in_attn_entropy\"], method=\"spearman\"),\n",
    "        \"spearman(comp, in_max)\": df[\"completeness\"].corr(df[\"in_attn_max\"], method=\"spearman\"),\n",
    "        \"note\": \"in_attn_sum is ~constant in GAT (softmax over incoming edges), so it's not a good signal.\",\n",
    "        \"n_rows\": len(df),\n",
    "    }])\n",
    "\n",
    "    per_node = []\n",
    "    for node, g in df.groupby(\"node\"):\n",
    "        # Require variability, otherwise correlations are meaningless\n",
    "        if g[\"completeness\"].std() < 1e-6:\n",
    "            continue\n",
    "        if g[\"out_attn_sum\"].std() < 1e-9:\n",
    "            continue\n",
    "\n",
    "        per_node.append({\n",
    "            \"node\": int(node),\n",
    "            \"name\": (id_to_name.get(int(node), str(node)) if id_to_name else str(node)),\n",
    "            \"n_samples\": len(g),\n",
    "            \"mean_completeness\": g[\"completeness\"].mean(),\n",
    "            \"std_completeness\": g[\"completeness\"].std(),\n",
    "            \"spearman(comp, out_sum)\": g[\"completeness\"].corr(g[\"out_attn_sum\"], method=\"spearman\"),\n",
    "            \"spearman(comp, in_entropy)\": g[\"completeness\"].corr(g[\"in_attn_entropy\"], method=\"spearman\"),\n",
    "            \"spearman(comp, in_max)\": g[\"completeness\"].corr(g[\"in_attn_max\"], method=\"spearman\"),\n",
    "        })\n",
    "\n",
    "    per_node = pd.DataFrame(per_node).sort_values(\"spearman(comp, out_sum)\", ascending=False).reset_index(drop=True)\n",
    "    return {\"overall_corr\": overall, \"per_node_corr\": per_node}\n",
    "\n",
    "# ---------------- RUN ----------------\n",
    "\n",
    "df_ac = attention_completeness_dataframe_v2(\n",
    "    model,\n",
    "    test_h,\n",
    "    edge_index=edge_index,\n",
    "    edge_attr=edge_attr,\n",
    "    static_features=static_features,\n",
    "    layer=\"layer2\",\n",
    "    max_batches=50,\n",
    "    device=device,\n",
    "    valid_def=\"finite\",   # <- you said \"no zeros\"; NaNs represent missing/unknown\n",
    ")\n",
    "\n",
    "# Identify dead/near-dead sensors (mostly NaN)\n",
    "node_quality = (\n",
    "    df_ac.groupby(\"node\")\n",
    "        .agg(mean_comp=(\"completeness\", \"mean\"),\n",
    "             std_comp=(\"completeness\", \"std\"),\n",
    "             name=(\"node\", lambda n: id_to_name.get(int(n.iloc[0]), str(int(n.iloc[0])))))\n",
    "        .reset_index()\n",
    "        .sort_values([\"mean_comp\", \"std_comp\"], ascending=True)\n",
    ")\n",
    "print(\"Lowest-completeness sensors (likely dead):\")\n",
    "display(node_quality.head(20))\n",
    "\n",
    "# Filter: drop sensors that are basically always missing OR have no variation\n",
    "MIN_MEAN_COMP = 0.05     # tune (e.g., 0.01, 0.10)\n",
    "MIN_STD_COMP  = 0.02     # tune\n",
    "good_nodes = node_quality[(node_quality[\"mean_comp\"] >= MIN_MEAN_COMP) & (node_quality[\"std_comp\"] >= MIN_STD_COMP)][\"node\"].tolist()\n",
    "df_f = df_ac[df_ac[\"node\"].isin(good_nodes)].copy()\n",
    "print(f\"Filtered rows: {len(df_f)}/{len(df_ac)} | kept nodes: {len(good_nodes)}/{df_ac['node'].nunique()}\")\n",
    "\n",
    "summary = summarize_attention_completeness_v2(df_f, id_to_name=id_to_name)\n",
    "display(summary[\"overall_corr\"])\n",
    "display(summary[\"per_node_corr\"].head(60))\n",
    "\n",
    "def add_comp_bins(df: pd.DataFrame, *, T: int = 12, col: str = \"completeness\") -> pd.DataFrame:\n",
    "    \"\"\"Quantize completeness to a 1/T grid in [0,1].\"\"\"\n",
    "    out = df.copy()\n",
    "    out[\"comp_bin\"] = (np.round(out[col].to_numpy() * T) / T).clip(0, 1)\n",
    "    return out\n",
    "\n",
    "def binned_boxplot(\n",
    "    df: pd.DataFrame,\n",
    "    ycol: str,\n",
    "    *,\n",
    "    xbin: str = \"comp_bin\",\n",
    "    title: str | None = None,\n",
    "    xlabel: str = \"Completeness (binned)\",\n",
    "    ylabel: str | None = None,\n",
    "    min_n_per_bin: int = 30,\n",
    "    show_counts: bool = True,\n",
    "    figsize=(9, 4),\n",
    "):\n",
    "    \"\"\"Boxplot of ycol per discrete completeness bin.\"\"\"\n",
    "    d = df[[xbin, ycol]].dropna().copy()\n",
    "    # enforce numeric ordering\n",
    "    bins = np.sort(d[xbin].unique())\n",
    "    data = []\n",
    "    kept_bins = []\n",
    "    counts = []\n",
    "    for b in bins:\n",
    "        y = d.loc[d[xbin] == b, ycol].to_numpy()\n",
    "        if len(y) < min_n_per_bin:\n",
    "            continue\n",
    "        data.append(y)\n",
    "        kept_bins.append(b)\n",
    "        counts.append(len(y))\n",
    "\n",
    "    if len(data) == 0:\n",
    "        raise ValueError(f\"No bins with n >= {min_n_per_bin} for {ycol}\")\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=figsize)\n",
    "    ax.boxplot(\n",
    "        data,\n",
    "        positions=np.arange(len(kept_bins)),\n",
    "        widths=0.65,\n",
    "        showfliers=False,\n",
    "        patch_artist=True,\n",
    "        boxprops=dict(facecolor=\"#8ecae6\", alpha=0.6),\n",
    "        medianprops=dict(color=\"#1f2937\", linewidth=2),\n",
    "        whiskerprops=dict(color=\"#475569\"),\n",
    "        capprops=dict(color=\"#475569\"),\n",
    "    )\n",
    "\n",
    "    ax.set_xticks(np.arange(len(kept_bins)))\n",
    "    ax.set_xticklabels([f\"{b:.2f}\" for b in kept_bins], rotation=0)\n",
    "    ax.set_xlabel(xlabel)\n",
    "    ax.set_ylabel(ylabel or ycol)\n",
    "    ax.set_title(title or f\"{ycol} vs completeness (binned boxplot)\")\n",
    "\n",
    "    if show_counts:\n",
    "        # small count annotations above each box\n",
    "        ymax = np.nanmax(np.concatenate(data))\n",
    "        yspan = np.nanmax(np.concatenate(data)) - np.nanmin(np.concatenate(data))\n",
    "        y_annot = ymax + (0.02 * (yspan if yspan > 0 else 1.0))\n",
    "        for i, n in enumerate(counts):\n",
    "            ax.text(i, y_annot, f\"n={n}\", ha=\"center\", va=\"bottom\", fontsize=8, color=\"#334155\")\n",
    "\n",
    "    ax.grid(True, axis=\"y\", alpha=0.25)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def make_centered_cols(df: pd.DataFrame, cols: list[str], group: str = \"node\") -> pd.DataFrame:\n",
    "    out = df.copy()\n",
    "    for c in cols:\n",
    "        out[c + \"_centered\"] = out[c] - out.groupby(group)[c].transform(\"mean\")\n",
    "    return out\n",
    "\n",
    "# -------------------------\n",
    "# Use with your filtered df_f\n",
    "# -------------------------\n",
    "dfp = add_comp_bins(df_f, T=12, col=\"completeness\")\n",
    "\n",
    "# Raw metrics (replace your scatter plots)\n",
    "for ycol, ttl in [\n",
    "    (\"out_attn_sum\", \"Outgoing attention (sum) vs completeness\"),\n",
    "    (\"in_attn_entropy\", \"Incoming attention entropy vs completeness\"),\n",
    "    (\"in_attn_max\", \"Max incoming attention vs completeness\"),\n",
    "]:\n",
    "    binned_boxplot(dfp, ycol, title=ttl, min_n_per_bin=30)\n",
    "\n",
    "# Centered metrics (often the most interpretable)\n",
    "dfp_c = make_centered_cols(dfp, [\"out_attn_sum\", \"in_attn_entropy\", \"in_attn_max\"], group=\"node\")\n",
    "\n",
    "for ycol, ttl in [\n",
    "    (\"out_attn_sum_centered\", \"Outgoing attention (sum, centered within node) vs completeness\"),\n",
    "    (\"in_attn_entropy_centered\", \"Incoming entropy (centered within node) vs completeness\"),\n",
    "    (\"in_attn_max_centered\", \"Max incoming attention (centered within node) vs completeness\"),\n",
    "]:\n",
    "    binned_boxplot(dfp_c, ycol, title=ttl, min_n_per_bin=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Use your filtered df_f from the v2 cell\n",
    "dfp = df_f.copy()\n",
    "\n",
    "# 1) Bin completeness into the natural 1/12 grid (or slightly coarser if you prefer)\n",
    "T = 12\n",
    "dfp[\"comp_bin\"] = (np.round(dfp[\"completeness\"] * T) / T).clip(0, 1)\n",
    "\n",
    "def _bin_summary(dfp, ycol):\n",
    "    g = dfp.groupby(\"comp_bin\")[ycol]\n",
    "    out = g.agg(\n",
    "        n=\"count\",\n",
    "        median=\"median\",\n",
    "        q25=lambda s: s.quantile(0.25),\n",
    "        q75=lambda s: s.quantile(0.75),\n",
    "        mean=\"mean\",\n",
    "        std=\"std\",\n",
    "    ).reset_index()\n",
    "    return out.sort_values(\"comp_bin\")\n",
    "\n",
    "def plot_binned(ycol, title):\n",
    "    s = _bin_summary(dfp, ycol)\n",
    "    x = s[\"comp_bin\"].to_numpy()\n",
    "    med = s[\"median\"].to_numpy()\n",
    "    q25 = s[\"q25\"].to_numpy()\n",
    "    q75 = s[\"q75\"].to_numpy()\n",
    "\n",
    "    plt.figure(figsize=(7, 4))\n",
    "    plt.plot(x, med, marker=\"o\", linewidth=2, label=\"median\")\n",
    "    plt.fill_between(x, q25, q75, alpha=0.2, label=\"IQR (25–75%)\")\n",
    "    plt.xlabel(\"Completeness (binned)\")\n",
    "    plt.ylabel(ycol)\n",
    "    plt.title(title)\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "plot_binned(\"out_attn_sum\", \"Binned: Completeness vs Out-degree Attention (sum)\")\n",
    "plot_binned(\"in_attn_entropy\", \"Binned: Completeness vs Incoming Attention Entropy\")\n",
    "plot_binned(\"in_attn_max\", \"Binned: Completeness vs Max Incoming Attention\")\n",
    "\n",
    "# 2) Remove per-node baseline (this is often the key)\n",
    "for col in [\"out_attn_sum\", \"in_attn_entropy\", \"in_attn_max\"]:\n",
    "    dfp[col + \"_centered\"] = dfp[col] - dfp.groupby(\"node\")[col].transform(\"mean\")\n",
    "\n",
    "def hexbin_plot(xcol, ycol, title):\n",
    "    plt.figure(figsize=(7, 4))\n",
    "    plt.hexbin(dfp[xcol], dfp[ycol], gridsize=40, mincnt=1)\n",
    "    plt.colorbar(label=\"count\")\n",
    "    plt.xlabel(xcol)\n",
    "    plt.ylabel(ycol)\n",
    "    plt.title(title)\n",
    "    plt.grid(True, alpha=0.2)\n",
    "    plt.show()\n",
    "\n",
    "hexbin_plot(\"completeness\", \"out_attn_sum_centered\", \"Within-node centered: Completeness vs Out-attn-sum\")\n",
    "hexbin_plot(\"completeness\", \"in_attn_entropy_centered\", \"Within-node centered: Completeness vs Incoming Entropy\")\n",
    "hexbin_plot(\"completeness\", \"in_attn_max_centered\", \"Within-node centered: Completeness vs Max Incoming\")\n",
    "\n",
    "# 3) Quick numeric check on centered relationships\n",
    "print(\"Spearman (centered, pooled across nodes):\")\n",
    "print(\"  comp vs out_attn_sum_centered:\", dfp[\"completeness\"].corr(dfp[\"out_attn_sum_centered\"], method=\"spearman\"))\n",
    "print(\"  comp vs in_attn_entropy_centered:\", dfp[\"completeness\"].corr(dfp[\"in_attn_entropy_centered\"], method=\"spearman\"))\n",
    "print(\"  comp vs in_attn_max_centered:\", dfp[\"completeness\"].corr(dfp[\"in_attn_max_centered\"], method=\"spearman\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "dfp = df_f.copy()\n",
    "\n",
    "# normalized entropy in [0,1] using per-node in_deg (constant per node in a static graph)\n",
    "k = dfp[\"in_deg\"].replace(0, np.nan)\n",
    "dfp[\"in_attn_entropy_norm\"] = dfp[\"in_attn_entropy\"] / np.log(k)\n",
    "\n",
    "# center and correlate\n",
    "dfp[\"in_attn_entropy_norm_centered\"] = dfp[\"in_attn_entropy_norm\"] - dfp.groupby(\"node\")[\"in_attn_entropy_norm\"].transform(\"mean\")\n",
    "\n",
    "print(\"Spearman (centered): comp vs in_attn_entropy_norm_centered =\",\n",
    "      dfp[\"completeness\"].corr(dfp[\"in_attn_entropy_norm_centered\"], method=\"spearman\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "dfp = df_f.copy()\n",
    "\n",
    "# center per node\n",
    "for col in [\"out_attn_sum\", \"in_attn_entropy\", \"in_attn_max\"]:\n",
    "    dfp[col + \"_centered\"] = dfp[col] - dfp.groupby(\"node\")[col].transform(\"mean\")\n",
    "\n",
    "rows = []\n",
    "for node, g in dfp.groupby(\"node\"):\n",
    "    if g[\"completeness\"].std() < 1e-6:\n",
    "        continue\n",
    "    rows.append({\n",
    "        \"node\": int(node),\n",
    "        \"n\": len(g),\n",
    "        \"rho_out_sum\": g[\"completeness\"].corr(g[\"out_attn_sum_centered\"], method=\"spearman\"),\n",
    "        \"rho_in_entropy\": g[\"completeness\"].corr(g[\"in_attn_entropy_centered\"], method=\"spearman\"),\n",
    "        \"rho_in_max\": g[\"completeness\"].corr(g[\"in_attn_max_centered\"], method=\"spearman\"),\n",
    "    })\n",
    "\n",
    "per_node_rho = pd.DataFrame(rows)\n",
    "display(per_node_rho.describe())\n",
    "\n",
    "print(\"Fraction nodes with rho_in_entropy < 0:\",\n",
    "      (per_node_rho[\"rho_in_entropy\"] < 0).mean())\n",
    "print(\"Fraction nodes with rho_in_max > 0:\",\n",
    "      (per_node_rho[\"rho_in_max\"] > 0).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "\n",
    "@torch.no_grad()\n",
    "def attention_edge_dataframe(\n",
    "    model,\n",
    "    loader,\n",
    "    *,\n",
    "    edge_index: torch.Tensor,\n",
    "    edge_attr: torch.Tensor,\n",
    "    static_features: torch.Tensor,\n",
    "    layer: str = \"layer2\",\n",
    "    max_batches: int | None = 50,\n",
    "    device: str | torch.device = \"cpu\",\n",
    "    valid_def: str = \"finite\",\n",
    "    max_edges_per_sample: int | None = None,   # set e.g. 5000 if memory is an issue\n",
    "    seed: int = 42,\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Rows are edges per sample:\n",
    "      (sample_idx, src, dst, attn_w, comp_src, comp_dst)\n",
    "    \"\"\"\n",
    "    rng = np.random.default_rng(seed)\n",
    "    device = torch.device(device)\n",
    "    model.eval()\n",
    "\n",
    "    num_nodes = int(static_features.shape[0])\n",
    "    rows = []\n",
    "    global_sample_idx = 0\n",
    "\n",
    "    for batch_idx, (X_spatial, X_temporal, _) in enumerate(loader):\n",
    "        if (max_batches is not None) and (batch_idx >= max_batches):\n",
    "            break\n",
    "\n",
    "        X_spatial = X_spatial.to(device)\n",
    "        X_temporal = X_temporal.to(device)\n",
    "\n",
    "        comp = _completeness_from_temporal(X_temporal, valid_def=valid_def).cpu()  # [B, N]\n",
    "\n",
    "        _, _, _, _, extra = model(\n",
    "            X_batch=X_spatial,\n",
    "            targets=None,\n",
    "            node_mask=None,\n",
    "            edge_index=edge_index.to(device),\n",
    "            edge_attr=edge_attr.to(device),\n",
    "            static_node_features=static_features.to(device),\n",
    "            return_attention=True,\n",
    "        )\n",
    "\n",
    "        pairs = extra.get(\"attn\", {}).get(layer, [])\n",
    "        B = X_spatial.shape[0]\n",
    "        if len(pairs) != B:\n",
    "            raise RuntimeError(f\"Expected {B} attention entries for {layer}, got {len(pairs)}\")\n",
    "\n",
    "        for b in range(B):\n",
    "            ei, alpha = pairs[b]\n",
    "            ei = ei.detach().cpu()\n",
    "            alpha = alpha.detach().cpu()\n",
    "\n",
    "            # Per-edge weight averaged over heads\n",
    "            w = _alpha_to_edge_weight(alpha).to(torch.float32)  # [E]\n",
    "            src = ei[0].to(torch.long)\n",
    "            dst = ei[1].to(torch.long)\n",
    "\n",
    "            E = int(w.numel())\n",
    "            if (max_edges_per_sample is not None) and (E > max_edges_per_sample):\n",
    "                idx = rng.choice(E, size=max_edges_per_sample, replace=False)\n",
    "                idx = torch.from_numpy(idx).to(torch.long)\n",
    "                w = w[idx]\n",
    "                src = src[idx]\n",
    "                dst = dst[idx]\n",
    "\n",
    "            comp_b = comp[b]  # [N]\n",
    "            comp_src = comp_b[src].to(torch.float32)\n",
    "            comp_dst = comp_b[dst].to(torch.float32)\n",
    "\n",
    "            sample_idx = global_sample_idx + b\n",
    "            rows.extend(\n",
    "                {\n",
    "                    \"batch_idx\": batch_idx,\n",
    "                    \"sample_idx\": sample_idx,\n",
    "                    \"src\": int(s),\n",
    "                    \"dst\": int(d),\n",
    "                    \"attn_w\": float(ww),\n",
    "                    \"comp_src\": float(cs),\n",
    "                    \"comp_dst\": float(cd),\n",
    "                }\n",
    "                for s, d, ww, cs, cd in zip(\n",
    "                    src.tolist(), dst.tolist(), w.tolist(), comp_src.tolist(), comp_dst.tolist()\n",
    "                )\n",
    "            )\n",
    "\n",
    "        global_sample_idx += B\n",
    "\n",
    "    return pd.DataFrame(rows)\n",
    "\n",
    "# --- RUN (layer2 recommended) ---\n",
    "df_e = attention_edge_dataframe(\n",
    "    model,\n",
    "    test_h,\n",
    "    edge_index=edge_index,\n",
    "    edge_attr=edge_attr,\n",
    "    static_features=static_features,\n",
    "    layer=\"layer2\",\n",
    "    max_batches=50,\n",
    "    device=device,\n",
    "    valid_def=\"finite\",\n",
    "    max_edges_per_sample=5000,  # set None if you want all edges and have RAM\n",
    ")\n",
    "\n",
    "print(\"edge rows:\", len(df_e), \"| unique samples:\", df_e[\"sample_idx\"].nunique())\n",
    "\n",
    "# 1) Naive pooled correlations (can be misleading because attention is normalized per dst)\n",
    "print(\"\\nNaive pooled Spearman:\")\n",
    "print(\"  attn_w vs comp_src:\", df_e[\"attn_w\"].corr(df_e[\"comp_src\"], method=\"spearman\"))\n",
    "print(\"  attn_w vs comp_dst:\", df_e[\"attn_w\"].corr(df_e[\"comp_dst\"], method=\"spearman\"))\n",
    "\n",
    "# 2) Correct comparison: within-(sample,dst) centered attention\n",
    "#    \"does a more complete source get higher-than-average attention among this dst's incoming neighbors?\"\n",
    "df_e[\"attn_w_centered_in_dst\"] = df_e[\"attn_w\"] - df_e.groupby([\"sample_idx\", \"dst\"])[\"attn_w\"].transform(\"mean\")\n",
    "\n",
    "print(\"\\nWithin-(sample,dst) centered Spearman:\")\n",
    "print(\"  centered_w vs comp_src:\", df_e[\"attn_w_centered_in_dst\"].corr(df_e[\"comp_src\"], method=\"spearman\"))\n",
    "print(\"  centered_w vs comp_dst:\", df_e[\"attn_w_centered_in_dst\"].corr(df_e[\"comp_dst\"], method=\"spearman\"))\n",
    "\n",
    "# 3) Per-source summary: which sources gain/lose relative attention when they are more complete?\n",
    "per_src = (\n",
    "    df_e.groupby(\"src\")\n",
    "        .apply(lambda g: pd.Series({\n",
    "            \"n_edges\": len(g),\n",
    "            \"mean_comp_src\": g[\"comp_src\"].mean(),\n",
    "            \"rho_src\": g[\"comp_src\"].corr(g[\"attn_w_centered_in_dst\"], method=\"spearman\"),\n",
    "        }))\n",
    "        .reset_index()\n",
    "        .sort_values(\"rho_src\", ascending=False)\n",
    ")\n",
    "display(per_src.head(20))\n",
    "display(per_src.tail(20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "\n",
    "# ---- 0) Fix: re-center AFTER filtering ----\n",
    "df_e2 = df_e[df_e[\"src\"].isin(good_src)].copy()\n",
    "df_e2[\"attn_w_centered_in_dst\"] = df_e2[\"attn_w\"] - df_e2.groupby([\"sample_idx\", \"dst\"])[\"attn_w\"].transform(\"mean\")\n",
    "\n",
    "print(\"Within-(sample,dst) centered Spearman (filtered, re-centered):\")\n",
    "print(\"  centered_w vs comp_src:\", df_e2[\"attn_w_centered_in_dst\"].corr(df_e2[\"comp_src\"], method=\"spearman\"))\n",
    "print(\"  centered_w vs comp_dst:\", df_e2[\"attn_w_centered_in_dst\"].corr(df_e2[\"comp_dst\"], method=\"spearman\"))\n",
    "\n",
    "# Also silence the pandas warning if you still compute per-src rhos:\n",
    "def _rho(g: pd.DataFrame) -> float:\n",
    "    if g[\"comp_src\"].std() < 1e-6 or g[\"attn_w_centered_in_dst\"].std() < 1e-12:\n",
    "        return np.nan\n",
    "    return g[\"comp_src\"].corr(g[\"attn_w_centered_in_dst\"], method=\"spearman\")\n",
    "\n",
    "rho_map = df_e2.groupby(\"src\").apply(_rho, include_groups=False).to_dict()  # pandas>=2.1\n",
    "# ---- 1) Minimal per-head centered Spearman (streaming, optional sampling) ----\n",
    "@torch.no_grad()\n",
    "def per_head_centered_spearman(\n",
    "    model,\n",
    "    loader,\n",
    "    *,\n",
    "    edge_index: torch.Tensor,\n",
    "    edge_attr: torch.Tensor,\n",
    "    static_features: torch.Tensor,\n",
    "    layer: str = \"layer2\",\n",
    "    max_batches: int = 50,\n",
    "    device: str | torch.device = \"cpu\",\n",
    "    valid_def: str = \"finite\",\n",
    "    max_edges_per_sample: int | None = 5000,\n",
    "    seed: int = 42,\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Computes Spearman corr per head for:\n",
    "      centered_alpha(head) vs comp_src\n",
    "      centered_alpha(head) vs comp_dst\n",
    "\n",
    "    Centering is within (sample,dst) using the *same* edge set being evaluated.\n",
    "    \"\"\"\n",
    "    rng = np.random.default_rng(seed)\n",
    "    device = torch.device(device)\n",
    "    model.eval()\n",
    "\n",
    "    # accumulate per head\n",
    "    xs_src, xs_dst, ys = None, None, None  # lists of np arrays per head\n",
    "    n_heads = None\n",
    "\n",
    "    for batch_idx, (X_spatial, X_temporal, _) in enumerate(loader):\n",
    "        if batch_idx >= max_batches:\n",
    "            break\n",
    "\n",
    "        X_spatial = X_spatial.to(device)\n",
    "        X_temporal = X_temporal.to(device)\n",
    "        comp = _completeness_from_temporal(X_temporal, valid_def=valid_def).cpu()  # [B, N]\n",
    "\n",
    "        _, _, _, _, extra = model(\n",
    "            X_batch=X_spatial,\n",
    "            targets=None,\n",
    "            node_mask=None,\n",
    "            edge_index=edge_index.to(device),\n",
    "            edge_attr=edge_attr.to(device),\n",
    "            static_node_features=static_features.to(device),\n",
    "            return_attention=True,\n",
    "        )\n",
    "\n",
    "        pairs = extra.get(\"attn\", {}).get(layer, [])\n",
    "        B = X_spatial.shape[0]\n",
    "        if len(pairs) != B:\n",
    "            raise RuntimeError(f\"Expected {B} attention entries for {layer}, got {len(pairs)}\")\n",
    "\n",
    "        for b in range(B):\n",
    "            ei, alpha = pairs[b]\n",
    "            ei = ei.detach().cpu()\n",
    "            alpha = alpha.detach().cpu().to(torch.float32)  # [E, H] typically\n",
    "\n",
    "            if alpha.dim() != 2:\n",
    "                alpha = alpha.view(alpha.shape[0], -1)\n",
    "\n",
    "            E, H = alpha.shape\n",
    "            if n_heads is None:\n",
    "                n_heads = H\n",
    "                xs_src = [[] for _ in range(H)]\n",
    "                xs_dst = [[] for _ in range(H)]\n",
    "                ys = [[] for _ in range(H)]\n",
    "\n",
    "            src = ei[0].to(torch.long)\n",
    "            dst = ei[1].to(torch.long)\n",
    "\n",
    "            # inside the inner loop, after src/dst/alpha are created (and after optional subsampling)\n",
    "            allowed_src = set(map(int, good_src))  # define once outside the function ideally\n",
    "            m = torch.tensor([int(s) in allowed_src for s in src.tolist()], dtype=torch.bool)\n",
    "            src = src[m]\n",
    "            dst = dst[m]\n",
    "            alpha = alpha[m]\n",
    "            E = int(alpha.shape[0])\n",
    "            if E == 0:\n",
    "                continue\n",
    "\n",
    "            # optional subsample edges to control RAM/CPU\n",
    "            if (max_edges_per_sample is not None) and (E > max_edges_per_sample):\n",
    "                idx = rng.choice(E, size=max_edges_per_sample, replace=False)\n",
    "                idx = torch.from_numpy(idx).to(torch.long)\n",
    "                src = src[idx]\n",
    "                dst = dst[idx]\n",
    "                alpha = alpha[idx]\n",
    "                E = int(alpha.shape[0])\n",
    "\n",
    "            # center within dst (for this sample)\n",
    "            num_nodes = int(static_features.shape[0])\n",
    "            deg = torch.zeros(num_nodes, dtype=torch.float32)\n",
    "            deg.scatter_add_(0, dst, torch.ones(E, dtype=torch.float32))\n",
    "\n",
    "            sum_alpha = torch.zeros((num_nodes, H), dtype=torch.float32)\n",
    "            for h in range(H):\n",
    "                sum_alpha[:, h].scatter_add_(0, dst, alpha[:, h])\n",
    "\n",
    "            mean_alpha = sum_alpha / torch.clamp(deg.unsqueeze(1), min=1.0)  # [N, H]\n",
    "            centered = alpha - mean_alpha[dst]  # [E, H]\n",
    "\n",
    "            comp_b = comp[b]\n",
    "            comp_src = comp_b[src].numpy()\n",
    "            comp_dst = comp_b[dst].numpy()\n",
    "            centered_np = centered.numpy()\n",
    "\n",
    "            for h in range(H):\n",
    "                ys[h].append(centered_np[:, h])\n",
    "                xs_src[h].append(comp_src)\n",
    "                xs_dst[h].append(comp_dst)\n",
    "\n",
    "    # compute correlations\n",
    "    rows = []\n",
    "    for h in range(n_heads or 0):\n",
    "        y = np.concatenate(ys[h])\n",
    "        xsrc = np.concatenate(xs_src[h])\n",
    "        xdst = np.concatenate(xs_dst[h])\n",
    "\n",
    "        # Spearman via pandas (handles ties reasonably)\n",
    "        rho_src = pd.Series(y).corr(pd.Series(xsrc), method=\"spearman\")\n",
    "        rho_dst = pd.Series(y).corr(pd.Series(xdst), method=\"spearman\")\n",
    "\n",
    "        rows.append({\"head\": h, \"rho(centered, comp_src)\": rho_src, \"rho(centered, comp_dst)\": rho_dst, \"n_edges\": len(y)})\n",
    "\n",
    "    return pd.DataFrame(rows).sort_values(\"head\").reset_index(drop=True)\n",
    "\n",
    "per_head = per_head_centered_spearman(\n",
    "    model,\n",
    "    test_h,\n",
    "    edge_index=edge_index,\n",
    "    edge_attr=edge_attr,\n",
    "    static_features=static_features,\n",
    "    layer=\"layer2\",\n",
    "    max_batches=50,\n",
    "    device=device,\n",
    "    valid_def=\"finite\",\n",
    "    max_edges_per_sample=5000,  # set None for full\n",
    ")\n",
    "display(per_head)\n",
    "print(\"mean rho over heads:\",\n",
    "      per_head[\"rho(centered, comp_src)\"].mean(),\n",
    "      per_head[\"rho(centered, comp_dst)\"].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- B) Node-level time-series (from df_ac produced by attention_completeness_dataframe_v2) ---\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def add_time_columns(df: pd.DataFrame, samples_per_day: int = 96) -> pd.DataFrame:\n",
    "    out = df.copy()\n",
    "    out[\"day_idx\"] = (out[\"sample_idx\"] // samples_per_day).astype(int)\n",
    "    out[\"t_in_day\"] = (out[\"sample_idx\"] % samples_per_day).astype(int)\n",
    "    out[\"hour\"] = out[\"t_in_day\"] * (24.0 / samples_per_day)\n",
    "    return out\n",
    "\n",
    "def filter_to_selected_days(df: pd.DataFrame, selected_day_ranges: list[tuple[int, int]]) -> pd.DataFrame:\n",
    "    if not selected_day_ranges:\n",
    "        return df\n",
    "    mask = np.zeros(len(df), dtype=bool)\n",
    "    sidx = df[\"sample_idx\"].to_numpy()\n",
    "    for start, end in selected_day_ranges:\n",
    "        mask |= (sidx >= start) & (sidx < end)\n",
    "    return df.loc[mask].copy()\n",
    "\n",
    "def center_within_node(df: pd.DataFrame, cols: list[str]) -> pd.DataFrame:\n",
    "    out = df.copy()\n",
    "    for c in cols:\n",
    "        out[c + \"_centered\"] = out[c] - out.groupby(\"node\")[c].transform(\"mean\")\n",
    "    return out\n",
    "\n",
    "def plot_node_timeseries(\n",
    "    df: pd.DataFrame,\n",
    "    node: int,\n",
    "    cols: list[str],\n",
    "    *,\n",
    "    title: str | None = None,\n",
    "    smooth: int | None = None,   # e.g. 12 for ~3h rolling window\n",
    "):\n",
    "    d = df[df[\"node\"] == int(node)].sort_values(\"sample_idx\").copy()\n",
    "    if len(d) == 0:\n",
    "        raise ValueError(f\"No rows for node={node}\")\n",
    "\n",
    "    x = d[\"sample_idx\"].to_numpy()\n",
    "    fig, axes = plt.subplots(len(cols), 1, figsize=(12, 2.4 * len(cols)), sharex=True)\n",
    "    if len(cols) == 1:\n",
    "        axes = [axes]\n",
    "\n",
    "    for ax, c in zip(axes, cols):\n",
    "        y = d[c].to_numpy()\n",
    "        ax.plot(x, y, linewidth=1.25, label=c)\n",
    "\n",
    "        if smooth is not None and smooth >= 2:\n",
    "            ys = pd.Series(y).rolling(window=smooth, min_periods=1, center=True).mean().to_numpy()\n",
    "            ax.plot(x, ys, linewidth=2.0, label=f\"{c} (roll{smooth})\")\n",
    "\n",
    "        ax.set_ylabel(c)\n",
    "        ax.grid(True, alpha=0.25)\n",
    "        ax.legend(loc=\"upper right\")\n",
    "\n",
    "    axes[-1].set_xlabel(\"sample_idx (15-min steps)\")\n",
    "    fig.suptitle(title or f\"Node {node}: {id_to_name.get(int(node), str(node))}\", y=1.02)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    # quick within-node Spearman table\n",
    "    rows = []\n",
    "    for c in cols:\n",
    "        rho = pd.Series(d[\"completeness\"]).corr(pd.Series(d[c]), method=\"spearman\")\n",
    "        rows.append({\"node\": int(node), \"metric\": c, \"spearman(comp, metric)\": rho, \"n_samples\": len(d)})\n",
    "    display(pd.DataFrame(rows))\n",
    "\n",
    "# ----- build node-timeseries df -----\n",
    "df_nt = add_time_columns(df_ac, samples_per_day=SAMPLES_PER_DAY)\n",
    "\n",
    "# (optional) restrict to the specific 3 selected days you used earlier\n",
    "df_nt_sel = filter_to_selected_days(df_nt, selected_day_ranges)\n",
    "\n",
    "# center metrics within node (useful for removing per-node baselines)\n",
    "metric_cols = [\"out_attn_sum\", \"in_attn_entropy\", \"in_attn_max\"]\n",
    "df_nt_sel = center_within_node(df_nt_sel, metric_cols)\n",
    "\n",
    "# ----- pick nodes -----\n",
    "# Option A: manually set\n",
    "node_to_plot = 0\n",
    "\n",
    "# Option B: auto-pick nodes with strong within-node correlation (centered out_attn_sum)\n",
    "rank = (\n",
    "    df_nt_sel.groupby(\"node\")\n",
    "             .apply(lambda g: g[\"completeness\"].corr(g[\"out_attn_sum_centered\"], method=\"spearman\"))\n",
    "             .rename(\"rho\")\n",
    "             .reset_index()\n",
    "             .sort_values(\"rho\", ascending=False)\n",
    ")\n",
    "display(rank.head(10))\n",
    "display(rank.tail(10))\n",
    "\n",
    "# Plot\n",
    "plot_node_timeseries(\n",
    "    df_nt_sel,\n",
    "    node=node_to_plot,\n",
    "    cols=[\"completeness\", \"out_attn_sum_centered\", \"in_attn_entropy_centered\", \"in_attn_max_centered\"],\n",
    "    smooth=12,\n",
    "    title=\"Node-level time-series (selected days): completeness vs attention metrics (centered)\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Static sensor characteristics -> attention characteristics ---\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# sklearn (install if needed: pip install scikit-learn)\n",
    "from sklearn.model_selection import KFold, cross_val_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import RidgeCV, LassoCV\n",
    "\n",
    "# --------------------------\n",
    "# 1) Build static feature DF\n",
    "# --------------------------\n",
    "STATIC_FEAT_NAMES =[\n",
    "    \"closeness_centrality\",\n",
    "    \"eigen_vector_centrality\",\n",
    "    \"nearest_intersection_degree\",\n",
    "    \"pct_primary_roads_in_200m\",\n",
    "    \"pct_residential_roads_in_200m\",\n",
    "    \"pct_service_roads_in_200m\",\n",
    "    \"shops_in_200m\",\n",
    "    \"offices_in_200m\",\n",
    "    \"restaurants_in_200m\",\n",
    "    \"bus_stops_in_200m\",\n",
    "    \"rail_stations_in_400m\",\n",
    "    \"schools_in_200m\",\n",
    "    \"leisure_sites_in_200m\",\n",
    "]\n",
    "\n",
    "X_static = static_features.detach().cpu().numpy()\n",
    "N, D = X_static.shape\n",
    "\n",
    "if STATIC_FEAT_NAMES is None:\n",
    "    STATIC_FEAT_NAMES = [f\"f{i}\" for i in range(D)]\n",
    "else:\n",
    "    assert len(STATIC_FEAT_NAMES) == D, \"STATIC_FEAT_NAMES must match static feature dimension\"\n",
    "\n",
    "df_static = pd.DataFrame(X_static, columns=STATIC_FEAT_NAMES)\n",
    "df_static.insert(0, \"node\", np.arange(N, dtype=int))\n",
    "df_static[\"name\"] = df_static[\"node\"].map(lambda n: id_to_name.get(int(n), str(int(n))))\n",
    "\n",
    "# --------------------------\n",
    "# 2) Node-level targets from attention + missingness sensitivity\n",
    "# --------------------------\n",
    "# Use df_ac (from attention_completeness_dataframe_v2) as the raw per-(sample,node) table.\n",
    "# If you want to restrict to your earlier \"good nodes\", use df_f instead.\n",
    "df_node_source = df_ac.copy()\n",
    "\n",
    "# Basic attention characteristics (averages across samples)\n",
    "node_means = (\n",
    "    df_node_source.groupby(\"node\")\n",
    "    .agg(\n",
    "        mean_comp=(\"completeness\", \"mean\"),\n",
    "        std_comp=(\"completeness\", \"std\"),\n",
    "        mean_out_sum=(\"out_attn_sum\", \"mean\"),\n",
    "        mean_out_mean=(\"out_attn_mean\", \"mean\"),\n",
    "        mean_in_entropy=(\"in_attn_entropy\", \"mean\"),\n",
    "        mean_in_max=(\"in_attn_max\", \"mean\"),\n",
    "    )\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "# Missingness sensitivity: within-node Spearman(comp, metric_centered_over_node)\n",
    "# If df_nt_sel exists from your time-series cell, use it (optionally restricted to selected days).\n",
    "if \"df_nt_sel\" in globals():\n",
    "    df_ts = df_nt_sel.copy()\n",
    "else:\n",
    "    # fall back: use full df_ac with centering inside this block\n",
    "    df_ts = df_ac.copy()\n",
    "    for col in [\"out_attn_sum\", \"in_attn_entropy\", \"in_attn_max\"]:\n",
    "        df_ts[col + \"_centered\"] = df_ts[col] - df_ts.groupby(\"node\")[col].transform(\"mean\")\n",
    "\n",
    "def _safe_spearman(g: pd.DataFrame, ycol: str) -> float:\n",
    "    if g[\"completeness\"].std() < 1e-6 or g[ycol].std() < 1e-12:\n",
    "        return np.nan\n",
    "    return g[\"completeness\"].corr(g[ycol], method=\"spearman\")\n",
    "\n",
    "sens = []\n",
    "for node, g in df_ts.groupby(\"node\"):\n",
    "    sens.append({\n",
    "        \"node\": int(node),\n",
    "        \"rho_comp_out_sum_centered\": _safe_spearman(g, \"out_attn_sum_centered\"),\n",
    "        \"rho_comp_in_entropy_centered\": _safe_spearman(g, \"in_attn_entropy_centered\"),\n",
    "        \"rho_comp_in_max_centered\": _safe_spearman(g, \"in_attn_max_centered\"),\n",
    "        \"n_samples\": int(len(g)),\n",
    "    })\n",
    "sens = pd.DataFrame(sens)\n",
    "\n",
    "# Merge static + targets\n",
    "df_model = (\n",
    "    df_static.merge(node_means, on=\"node\", how=\"inner\")\n",
    "             .merge(sens, on=\"node\", how=\"left\")\n",
    ")\n",
    "\n",
    "display(df_model.head())\n",
    "\n",
    "# --------------------------\n",
    "# 3) Quick correlation screen (static feature <-> each target)\n",
    "# --------------------------\n",
    "target_cols = [\n",
    "    \"mean_out_sum\", \"mean_out_mean\", \"mean_in_entropy\", \"mean_in_max\",\n",
    "    \"rho_comp_out_sum_centered\", \"rho_comp_in_entropy_centered\", \"rho_comp_in_max_centered\",\n",
    "]\n",
    "\n",
    "corr_rows = []\n",
    "for t in target_cols:\n",
    "    # skip if target is mostly nan\n",
    "    tmp = df_model[[\"node\", t] + STATIC_FEAT_NAMES].dropna()\n",
    "    if len(tmp) < 10:\n",
    "        continue\n",
    "    for f in STATIC_FEAT_NAMES:\n",
    "        corr_rows.append({\n",
    "            \"target\": t,\n",
    "            \"feature\": f,\n",
    "            \"spearman\": tmp[f].corr(tmp[t], method=\"spearman\"),\n",
    "            \"pearson\": tmp[f].corr(tmp[t], method=\"pearson\"),\n",
    "            \"n\": len(tmp),\n",
    "        })\n",
    "df_corr = pd.DataFrame(corr_rows).sort_values([\"target\", \"spearman\"], ascending=[True, False])\n",
    "display(df_corr.groupby(\"target\").head(10))\n",
    "\n",
    "# --------------------------\n",
    "# 4) Train simple interpretable linear models\n",
    "#    (separate model per target)\n",
    "# --------------------------\n",
    "def fit_linear_models_for_target(df: pd.DataFrame, target: str):\n",
    "    data = df[[\"node\", target] + STATIC_FEAT_NAMES].dropna().copy()\n",
    "    X = data[STATIC_FEAT_NAMES].to_numpy()\n",
    "    y = data[target].to_numpy()\n",
    "\n",
    "    # Ridge (stable)\n",
    "    ridge = Pipeline([\n",
    "        (\"scaler\", StandardScaler()),\n",
    "        (\"model\", RidgeCV(alphas=np.logspace(-4, 4, 40))),\n",
    "    ])\n",
    "\n",
    "    # Lasso (sparse weights, but can be less stable)\n",
    "    lasso = Pipeline([\n",
    "        (\"scaler\", StandardScaler()),\n",
    "        (\"model\", LassoCV(alphas=np.logspace(-4, 1, 40), max_iter=20000, cv=5, random_state=0)),\n",
    "    ])\n",
    "\n",
    "    cv = KFold(n_splits=5, shuffle=True, random_state=0)\n",
    "    ridge_r2 = cross_val_score(ridge, X, y, cv=cv, scoring=\"r2\").mean()\n",
    "    lasso_r2 = cross_val_score(lasso, X, y, cv=cv, scoring=\"r2\").mean()\n",
    "\n",
    "    ridge.fit(X, y)\n",
    "    lasso.fit(X, y)\n",
    "\n",
    "    ridge_coefs = ridge.named_steps[\"model\"].coef_\n",
    "    lasso_coefs = lasso.named_steps[\"model\"].coef_\n",
    "\n",
    "    df_coef = pd.DataFrame({\n",
    "        \"feature\": STATIC_FEAT_NAMES,\n",
    "        \"ridge_coef\": ridge_coefs,\n",
    "        \"lasso_coef\": lasso_coefs,\n",
    "        \"abs_ridge\": np.abs(ridge_coefs),\n",
    "        \"abs_lasso\": np.abs(lasso_coefs),\n",
    "    }).sort_values(\"abs_ridge\", ascending=False)\n",
    "\n",
    "    info = pd.DataFrame([{\n",
    "        \"target\": target,\n",
    "        \"n_nodes_used\": len(data),\n",
    "        \"ridge_cv_r2\": ridge_r2,\n",
    "        \"lasso_cv_r2\": lasso_r2,\n",
    "        \"ridge_alpha\": float(ridge.named_steps[\"model\"].alpha_),\n",
    "    }])\n",
    "\n",
    "    return info, df_coef\n",
    "\n",
    "# Pick 1–2 targets to start (recommended: mean_out_sum and rho_comp_out_sum_centered)\n",
    "for tgt in [\"mean_out_sum\", \"rho_comp_out_sum_centered\"]:\n",
    "    info, coefs = fit_linear_models_for_target(df_model, tgt)\n",
    "    display(info)\n",
    "    display(coefs.head(15))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Follow-ups: permutation sanity check + bootstrap coefficient stability ---\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import KFold, cross_val_score\n",
    "from sklearn.linear_model import RidgeCV, Ridge\n",
    "\n",
    "def _get_xy(df: pd.DataFrame, target: str, feat_names: list[str]):\n",
    "    data = df[[target] + feat_names].dropna().copy()\n",
    "    X = data[feat_names].to_numpy()\n",
    "    y = data[target].to_numpy()\n",
    "    return X, y, len(data)\n",
    "\n",
    "def permutation_cv_r2(\n",
    "    df: pd.DataFrame,\n",
    "    target: str,\n",
    "    feat_names: list[str],\n",
    "    *,\n",
    "    n_perm: int = 200,\n",
    "    seed: int = 0,\n",
    "):\n",
    "    \"\"\"\n",
    "    Permutation test: compare observed CV R^2 to distribution under shuffled y.\n",
    "    \"\"\"\n",
    "    X, y, n = _get_xy(df, target, feat_names)\n",
    "    rng = np.random.default_rng(seed)\n",
    "\n",
    "    cv = KFold(n_splits=5, shuffle=True, random_state=seed)\n",
    "\n",
    "    model = Pipeline([\n",
    "        (\"scaler\", StandardScaler()),\n",
    "        (\"model\", RidgeCV(alphas=np.logspace(-4, 4, 40))),\n",
    "    ])\n",
    "\n",
    "    observed = cross_val_score(model, X, y, cv=cv, scoring=\"r2\").mean()\n",
    "\n",
    "    perm_scores = np.empty(n_perm, dtype=float)\n",
    "    for i in range(n_perm):\n",
    "        y_perm = rng.permutation(y)\n",
    "        perm_scores[i] = cross_val_score(model, X, y_perm, cv=cv, scoring=\"r2\").mean()\n",
    "\n",
    "    # one-sided p-value: how often permuted >= observed\n",
    "    pval = (np.sum(perm_scores >= observed) + 1) / (n_perm + 1)\n",
    "\n",
    "    out = {\n",
    "        \"target\": target,\n",
    "        \"n_nodes_used\": n,\n",
    "        \"observed_cv_r2\": float(observed),\n",
    "        \"perm_mean\": float(np.mean(perm_scores)),\n",
    "        \"perm_std\": float(np.std(perm_scores)),\n",
    "        \"perm_p95\": float(np.quantile(perm_scores, 0.95)),\n",
    "        \"p_value_(perm>=obs)\": float(pval),\n",
    "    }\n",
    "    return out, perm_scores\n",
    "\n",
    "def bootstrap_ridge_coefs(\n",
    "    df: pd.DataFrame,\n",
    "    target: str,\n",
    "    feat_names: list[str],\n",
    "    *,\n",
    "    n_boot: int = 500,\n",
    "    seed: int = 0,\n",
    "):\n",
    "    \"\"\"\n",
    "    Bootstrap nodes (rows) with replacement, fit Ridge with alpha chosen on full data,\n",
    "    and report coefficient stability.\n",
    "    \"\"\"\n",
    "    X, y, n = _get_xy(df, target, feat_names)\n",
    "    rng = np.random.default_rng(seed)\n",
    "\n",
    "    # 1) pick alpha once on full data (stabilizes bootstrap interpretation)\n",
    "    ridgecv = Pipeline([\n",
    "        (\"scaler\", StandardScaler()),\n",
    "        (\"model\", RidgeCV(alphas=np.logspace(-4, 4, 40))),\n",
    "    ])\n",
    "    ridgecv.fit(X, y)\n",
    "    alpha = float(ridgecv.named_steps[\"model\"].alpha_)\n",
    "\n",
    "    # 2) bootstrap fits with fixed alpha\n",
    "    coefs = np.empty((n_boot, len(feat_names)), dtype=float)\n",
    "    for b in range(n_boot):\n",
    "        idx = rng.integers(0, n, size=n)  # resample rows\n",
    "        Xb = X[idx]\n",
    "        yb = y[idx]\n",
    "\n",
    "        m = Pipeline([\n",
    "            (\"scaler\", StandardScaler()),\n",
    "            (\"model\", Ridge(alpha=alpha)),\n",
    "        ])\n",
    "        m.fit(Xb, yb)\n",
    "        coefs[b] = m.named_steps[\"model\"].coef_\n",
    "\n",
    "    df_stab = pd.DataFrame({\n",
    "        \"feature\": feat_names,\n",
    "        \"coef_mean\": coefs.mean(axis=0),\n",
    "        \"coef_std\": coefs.std(axis=0),\n",
    "        \"coef_ci_low\": np.quantile(coefs, 0.025, axis=0),\n",
    "        \"coef_ci_high\": np.quantile(coefs, 0.975, axis=0),\n",
    "        \"sign_stability\": np.mean(np.sign(coefs) == np.sign(coefs.mean(axis=0)), axis=0),\n",
    "        \"p_gt_0\": np.mean(coefs > 0, axis=0),\n",
    "    }).sort_values(\"sign_stability\", ascending=False)\n",
    "\n",
    "    info = pd.DataFrame([{\n",
    "        \"target\": target,\n",
    "        \"n_nodes_used\": n,\n",
    "        \"n_boot\": n_boot,\n",
    "        \"ridge_alpha_fixed\": alpha,\n",
    "    }])\n",
    "\n",
    "    return info, df_stab\n",
    "\n",
    "# ---- RUN for your most interesting target ----\n",
    "tgt = \"rho_comp_out_sum_centered\"  # change if needed\n",
    "\n",
    "perm_info, perm_scores = permutation_cv_r2(\n",
    "    df_model, tgt, STATIC_FEAT_NAMES, n_perm=200, seed=0\n",
    ")\n",
    "display(pd.DataFrame([perm_info]))\n",
    "\n",
    "boot_info, boot_tbl = bootstrap_ridge_coefs(\n",
    "    df_model, tgt, STATIC_FEAT_NAMES, n_boot=500, seed=0\n",
    ")\n",
    "display(boot_info)\n",
    "display(boot_tbl.head(13))  # all features (13)\n",
    "\n",
    "# Optional: show the least stable too\n",
    "display(boot_tbl.tail(13))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Failure simulation: force node 107 inputs to NaN on TEST_H, then re-evaluate + re-plot ---\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from scipy import stats as sp_stats\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "FAIL_NODE_ID = 107  # node index in this graph\n",
    "\n",
    "num_nodes = int(static_features.shape[0])\n",
    "print(\"num_nodes:\", num_nodes)\n",
    "\n",
    "if not (0 <= int(FAIL_NODE_ID) < num_nodes):\n",
    "    raise ValueError(\n",
    "        f\"FAIL_NODE_ID={FAIL_NODE_ID} is out of range for this dataset (num_nodes={num_nodes}). \"\n",
    "        f\"Valid node indices are 0..{num_nodes-1}.\"\n",
    "    )\n",
    "\n",
    "print(f\"Simulating failure for node {FAIL_NODE_ID}: {id_to_name.get(int(FAIL_NODE_ID), str(FAIL_NODE_ID))}\")\n",
    "\n",
    "def corrupted_iter(loader, *, fail_node: int):\n",
    "    \"\"\"\n",
    "    Yields (X_spatial, X_temporal, y) like test_h, but sets one node's inputs to NaN.\n",
    "    Keeps y unchanged.\n",
    "    \"\"\"\n",
    "    for X_spatial, X_temporal, y in loader:\n",
    "        X_spatial = X_spatial.clone()\n",
    "        X_temporal = X_temporal.clone()\n",
    "\n",
    "        # X_spatial: [B, 1, N, F]\n",
    "        X_spatial[:, :, fail_node, :] = float(\"nan\")\n",
    "        # X_temporal: [B, T, N, 1] (not used by model, but corrupt for completeness)\n",
    "        X_temporal[:, :, fail_node, :] = float(\"nan\")\n",
    "\n",
    "        yield (X_spatial, X_temporal, y)\n",
    "\n",
    "def format_params_from_extras(extras_list):\n",
    "    \"\"\"\n",
    "    extras_list: list[dict] where each dict has keys 'mu','theta','pi' shaped [B,1,N,1]\n",
    "    \"\"\"\n",
    "    mu = torch.cat([p[\"mu\"].detach().cpu() for p in extras_list], dim=0)\n",
    "    theta = torch.cat([p[\"theta\"].detach().cpu() for p in extras_list], dim=0)\n",
    "    pi = torch.cat([p[\"pi\"].detach().cpu() for p in extras_list], dim=0)\n",
    "    return mu, theta, pi\n",
    "\n",
    "def format_targets_from_loader(dataloader):\n",
    "    targets = []\n",
    "    for _, _, y in dataloader:\n",
    "        y_raw = (y * SCALER_SIGMA) + SCALER_MU\n",
    "        y_raw_int = torch.round(y_raw).long()\n",
    "        targets.append(y_raw_int)\n",
    "    return torch.cat(targets, dim=0)\n",
    "\n",
    "def plot_preds_and_ground_truth(targets, mu, theta, pi, names, n_samples=500, nodes_to_plot=None):\n",
    "    \"\"\"\n",
    "    Plots:\n",
    "      - True counts\n",
    "      - Predicted mean E[y]=(1-pi)*mu\n",
    "      - 95% prediction interval from ZINB (via scipy)\n",
    "    \"\"\"\n",
    "    eps = 1e-8\n",
    "    expected_value = (1 - pi) * mu\n",
    "\n",
    "    N = targets.shape[2]\n",
    "    nodes = list(range(N)) if nodes_to_plot is None else [int(n) for n in nodes_to_plot]\n",
    "\n",
    "    for node in nodes:\n",
    "        plt.figure(figsize=(10, 4))\n",
    "\n",
    "        true_node = targets[:, 0, node, -1].cpu().numpy()\n",
    "        pred_node = expected_value[:, 0, node, -1].cpu().numpy()\n",
    "\n",
    "        try:\n",
    "            mu_node = mu[:, 0, node, -1].cpu().numpy()\n",
    "            theta_node = theta[:, 0, node, -1].cpu().numpy()\n",
    "            pi_node = pi[:, 0, node, -1].cpu().numpy()\n",
    "\n",
    "            n_scipy = np.maximum(theta_node, eps)\n",
    "            p_scipy = n_scipy / (mu_node + n_scipy + eps)\n",
    "            p_scipy = np.clip(p_scipy, eps, 1 - eps)\n",
    "\n",
    "            prob_zero = pi_node + (1 - pi_node) * sp_stats.nbinom.pmf(0, n=n_scipy, p=p_scipy)\n",
    "\n",
    "            q_lower, q_upper = 0.025, 0.975\n",
    "\n",
    "            q_lower_adj = (q_lower - pi_node) / (1 - pi_node + eps)\n",
    "            q_lower_adj = np.clip(q_lower_adj, eps, 1 - eps)\n",
    "            nb_lower = sp_stats.nbinom.ppf(q_lower_adj, n=n_scipy, p=p_scipy)\n",
    "            lower_bound = np.where(q_lower <= prob_zero, 0.0, nb_lower)\n",
    "\n",
    "            q_upper_adj = (q_upper - pi_node) / (1 - pi_node + eps)\n",
    "            q_upper_adj = np.clip(q_upper_adj, eps, 1 - eps)\n",
    "            nb_upper = sp_stats.nbinom.ppf(q_upper_adj, n=n_scipy, p=p_scipy)\n",
    "            upper_bound = np.where(q_upper <= prob_zero, 0.0, nb_upper)\n",
    "\n",
    "            plot_interval = True\n",
    "        except Exception as e:\n",
    "            print(f\"Warning: Could not compute PI for node {node}. Mean only. Error: {e}\")\n",
    "            plot_interval = False\n",
    "\n",
    "        plt.plot(true_node[:n_samples], label=\"True\", alpha=0.9, color=\"blue\")\n",
    "        plt.plot(pred_node[:n_samples], label=\"Predicted (E[y])\", alpha=0.9, color=\"orange\", linestyle=\"--\")\n",
    "\n",
    "        if plot_interval:\n",
    "            plt.fill_between(\n",
    "                range(len(true_node[:n_samples])),\n",
    "                lower_bound[:n_samples],\n",
    "                upper_bound[:n_samples],\n",
    "                color=\"orange\",\n",
    "                alpha=0.2,\n",
    "                label=\"95% P.I.\",\n",
    "            )\n",
    "\n",
    "        plt.title(f\"Node {node} {names.get(int(node), str(node))} Traffic Prediction (FAILED INPUT: node set to NaN)\")\n",
    "        plt.xlabel(\"Sample Index\")\n",
    "        plt.ylabel(\"Traffic Count\")\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "\n",
    "# 1) Evaluate under failure (use the HYBRID loader in this notebook: test_h)\n",
    "test_h_failed = corrupted_iter(test_h, fail_node=int(FAIL_NODE_ID))\n",
    "\n",
    "print(\"\\n=== Test metrics with FAILED INPUTS (node set to NaN) ===\")\n",
    "preds_failed, extras_failed = detailed_evaluation(\n",
    "    model,\n",
    "    test_h_failed,\n",
    "    device=device,\n",
    "    split_name=f\"Test (node {FAIL_NODE_ID} failed)\",\n",
    ")\n",
    "\n",
    "# 2) Build plotting tensors:\n",
    "#    - targets come from the original test_h (ground truth unchanged)\n",
    "#    - mu/theta/pi come from the failed-input run\n",
    "test_targets = format_targets_from_loader(test_h)\n",
    "test_mu_failed, test_theta_failed, test_pi_failed = format_params_from_extras(extras_failed)\n",
    "\n",
    "# 3) Plot\n",
    "print(\"\\n--- Plotting Test Set (FAILED INPUTS) ---\")\n",
    "plot_preds_and_ground_truth(\n",
    "    test_targets,\n",
    "    test_mu_failed,\n",
    "    test_theta_failed,\n",
    "    test_pi_failed,\n",
    "    id_to_name,\n",
    "    n_samples=500,\n",
    "    nodes_to_plot=[FAIL_NODE_ID],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
