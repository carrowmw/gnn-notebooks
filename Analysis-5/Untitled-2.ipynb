{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# Iter 4 - GAT-ZINB Evaluation Metrics and Visualizations\n",
    "\n",
    "This notebook extends the GAT-ZINB traffic prediction model with comprehensive evaluation metrics and visualizations to assess model performance, calibration, and interpretability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn as nn\n",
    "from torch_geometric.nn import GATv2Conv\n",
    "import torch.nn.functional as F\n",
    "from scipy import stats as sp_stats\n",
    "from scipy.special import gammaln\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "SCALER_MU = 14.323774337768555\n",
    "SCALER_SIGMA = 34.9963493347168\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "edge_index = torch.load(\"data/training/processed/c56f869b05279744/edge_index.pt\", weights_only=False)\n",
    "edge_attr_data = torch.load(\"data/training/processed/c56f869b05279744/edge_attr.pt\", weights_only=False)\n",
    "static_features = torch.load(\"data/training/processed/c56f869b05279744/static_features.pt\", weights_only=False)\n",
    "sensor_mask = torch.load(\"data/training/processed/c56f869b05279744/sensor_mask.pt\", weights_only=False)\n",
    "train_loader = torch.load(\"data/training/processed/c56f869b05279744/train_loader.pt\", weights_only=False)\n",
    "val_loader = torch.load(\"data/training/processed/c56f869b05279744/val_loader.pt\", weights_only=False)\n",
    "test_loader = torch.load(\"data/training/processed/c56f869b05279744/test_loader.pt\", weights_only=False)\n",
    "\n",
    "with open(\"data/training/processed/c56f869b05279744/sensor_name_to_id_map.json\", \"r\") as f:\n",
    "    name_to_id_map = json.load(f)\n",
    "    id_to_name_map = {v: k for k, v in name_to_id_map.items()}\n",
    "\n",
    "print(f\"Loaded {len(id_to_name_map)} sensor nodes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_hybrid_loader(loader, batch_size):\n",
    "    all_batches = [(X, y) for X, y in loader]\n",
    "\n",
    "    X_temporal_list = [(X[:, :, :, -1:]) for X, _ in all_batches]\n",
    "    X_temporal = torch.cat(X_temporal_list, dim=0)\n",
    "\n",
    "    X_agg_list = [(X[:, 0:1, :, :-1]) for X, _ in all_batches]\n",
    "    X_raw_list = [(X[:, :, :, -1:].permute(0,3,2,1)) for X, _ in all_batches]\n",
    "    X_agg = torch.cat(X_agg_list, dim=0)\n",
    "    X_raw = torch.cat(X_raw_list, dim=0)\n",
    "    X_spatial = torch.cat([X_agg, X_raw], dim=3)\n",
    "\n",
    "    y_list = [y[:, 0:1, :, :] for _, y in all_batches]\n",
    "    y_target = torch.cat(y_list, dim=0)\n",
    "\n",
    "    dataset = torch.utils.data.TensorDataset(X_spatial, X_temporal, y_target)\n",
    "    hybrid_loader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, shuffle=False, drop_last=True)\n",
    "\n",
    "    return hybrid_loader\n",
    "\n",
    "train_loader = prepare_hybrid_loader(train_loader, batch_size=16)\n",
    "val_loader = prepare_hybrid_loader(val_loader, batch_size=16)\n",
    "test_loader = prepare_hybrid_loader(test_loader, batch_size=16)\n",
    "print(f\"Train batches: {len(train_loader)}, Val batches: {len(val_loader)}, Test batches: {len(test_loader)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model definition with attention weight extraction\n",
    "class DynamicNodeGATZINB(nn.Module):\n",
    "    def __init__(self, dynamic_node_dim, static_node_dim, edge_dim, n_embd, n_heads, dropout_rate):\n",
    "        super().__init__()\n",
    "\n",
    "        dynamic_input_dim = dynamic_node_dim * 2\n",
    "        static_input_dim = static_node_dim\n",
    "        gat1_input_channels = dynamic_input_dim + static_input_dim\n",
    "\n",
    "        self.gat1 = GATv2Conv(in_channels=gat1_input_channels, out_channels=n_embd, edge_dim=edge_dim,\n",
    "                              heads=n_heads, concat=False, dropout=dropout_rate)\n",
    "        self.gat2 = GATv2Conv(in_channels=n_embd, out_channels=n_embd, edge_dim=edge_dim,\n",
    "                              heads=n_heads, concat=False, dropout=dropout_rate)\n",
    "        self.norm = nn.LayerNorm(n_embd)\n",
    "\n",
    "        self.mu_head = nn.Linear(n_embd, 1)\n",
    "        self.theta_head = nn.Linear(n_embd, 1)\n",
    "        self.pi_head = nn.Linear(n_embd, 1)\n",
    "\n",
    "        self.elu = nn.ELU()\n",
    "        self.dropout = nn.Dropout(dropout_rate)\n",
    "\n",
    "        # Store attention weights\n",
    "        self.attention_weights_1 = None\n",
    "        self.attention_weights_2 = None\n",
    "\n",
    "    def forward(self, X_batch, targets, node_mask, edge_index, edge_attr, static_node_features, return_attention=False):\n",
    "        mu_list, theta_list, pi_list = [], [], []\n",
    "        attn_weights_1_list, attn_weights_2_list = [], []\n",
    "\n",
    "        missing_mask = torch.isnan(X_batch)\n",
    "        imputed_X = torch.nan_to_num(X_batch, nan=0.0)\n",
    "        mask_features = missing_mask.float()\n",
    "        combined_input = torch.cat([imputed_X, mask_features], dim=-1)\n",
    "\n",
    "        B = combined_input.shape[0]\n",
    "        Xb = combined_input[:,0,:,:]\n",
    "\n",
    "        for b in range(B):\n",
    "            combined_features = torch.cat([Xb[b], static_node_features], dim=-1)\n",
    "            xb = self.dropout(combined_features)\n",
    "\n",
    "            # Get attention weights from first GAT layer\n",
    "            xb, attn1 = self.gat1(xb, edge_index, edge_attr, return_attention_weights=True)\n",
    "            xb = self.norm(xb)\n",
    "            xb = self.elu(xb)\n",
    "            xb = self.dropout(xb)\n",
    "\n",
    "            # Get attention weights from second GAT layer\n",
    "            xb, attn2 = self.gat2(xb, edge_index, edge_attr, return_attention_weights=True)\n",
    "            xb = self.norm(xb)\n",
    "            xb = self.elu(xb)\n",
    "            xb = self.dropout(xb)\n",
    "\n",
    "            if return_attention:\n",
    "                attn_weights_1_list.append(attn1)\n",
    "                attn_weights_2_list.append(attn2)\n",
    "\n",
    "            mu_b = torch.nn.functional.softplus(self.mu_head(xb)) + 1e-6\n",
    "            theta_b = torch.nn.functional.softplus(self.theta_head(xb)) + 1e-6\n",
    "            pi_b = torch.sigmoid(self.pi_head(xb))\n",
    "            pi_b = torch.clamp(pi_b, min=1e-6, max=1-1e-6)\n",
    "\n",
    "            mu_list.append(mu_b)\n",
    "            theta_list.append(theta_b)\n",
    "            pi_list.append(pi_b)\n",
    "\n",
    "        mu = torch.stack(mu_list, dim=0).unsqueeze(1)\n",
    "        theta = torch.stack(theta_list, dim=0).unsqueeze(1)\n",
    "        pi = torch.stack(pi_list, dim=0).unsqueeze(1)\n",
    "\n",
    "        zinb_nll_loss, valid_sum = self.zinb_nll_loss(mu, theta, pi, targets, node_mask)\n",
    "        preds = mu * (1 - pi)\n",
    "        mse_loss, _ = self.mse_loss(preds, targets, node_mask)\n",
    "\n",
    "        result = {\n",
    "            'mu': mu, 'theta': theta, 'pi': pi, 'valid_sum': valid_sum\n",
    "        }\n",
    "\n",
    "        if return_attention:\n",
    "            result['attention_1'] = attn_weights_1_list\n",
    "            result['attention_2'] = attn_weights_2_list\n",
    "\n",
    "        return preds, zinb_nll_loss, mse_loss, result\n",
    "\n",
    "    def zinb_nll_loss(self, mu, theta, pi, targets, node_mask):\n",
    "        eps = 1e-8\n",
    "        nan_mask = ~torch.isnan(targets)\n",
    "\n",
    "        if node_mask is not None:\n",
    "            valid_mask = nan_mask & node_mask\n",
    "        else:\n",
    "            valid_mask = nan_mask\n",
    "\n",
    "        if valid_mask.sum() == 0:\n",
    "            return torch.tensor(0.0, device=mu.device, requires_grad=True), torch.tensor(0.0, device=mu.device)\n",
    "\n",
    "        mu_valid = mu[valid_mask]\n",
    "        theta_valid = theta[valid_mask]\n",
    "        pi_valid = pi[valid_mask]\n",
    "        targets_valid = targets[valid_mask]\n",
    "        targets_valid = torch.round(targets_valid).clamp_min(0).to(mu_valid.dtype)\n",
    "\n",
    "        theta_mu = theta_valid + mu_valid\n",
    "\n",
    "        nb_log_prob = (\n",
    "            torch.lgamma(theta_valid + targets_valid + eps)\n",
    "            - torch.lgamma(theta_valid + eps)\n",
    "            - torch.lgamma(targets_valid + 1)\n",
    "            + theta_valid * torch.log(theta_valid + eps)\n",
    "            - theta_valid * torch.log(theta_mu + eps)\n",
    "            + targets_valid * torch.log(mu_valid + eps)\n",
    "            - targets_valid * torch.log(theta_mu + eps)\n",
    "        )\n",
    "\n",
    "        zero_mask = (targets_valid < eps).float()\n",
    "        nb_zero_prob = theta_valid * torch.log(theta_valid / (theta_mu + eps))\n",
    "        zero_log_prob = torch.log(pi_valid + (1 - pi_valid) * torch.exp(nb_zero_prob) + eps)\n",
    "        non_zero_log_prob = torch.log(1 - pi_valid + eps) + nb_log_prob\n",
    "        log_prob = zero_mask * zero_log_prob + (1 - zero_mask) * non_zero_log_prob\n",
    "\n",
    "        nll = -log_prob.mean()\n",
    "        return nll, valid_mask.sum()\n",
    "\n",
    "    def mse_loss(self, predictions, targets, node_mask):\n",
    "        nan_mask = ~torch.isnan(targets)\n",
    "        if node_mask is not None:\n",
    "            valid_mask = nan_mask & node_mask\n",
    "        else:\n",
    "            valid_mask = nan_mask\n",
    "\n",
    "        if valid_mask.sum() == 0:\n",
    "            return torch.tensor(0.0, device=predictions.device, requires_grad=True), 0\n",
    "\n",
    "        preds_valid = predictions[valid_mask]\n",
    "        targets_valid = targets[valid_mask]\n",
    "        mse_loss = ((targets_valid - preds_valid)**2).mean()\n",
    "\n",
    "        return mse_loss, valid_mask.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load trained model\n",
    "n_embd = 32\n",
    "n_heads = 4\n",
    "dropout = 0.1\n",
    "static_nodes_dim = static_features.shape[1]\n",
    "edge_attr_dim = edge_attr_data.shape[1]\n",
    "\n",
    "model = DynamicNodeGATZINB(\n",
    "    dynamic_node_dim=21,\n",
    "    static_node_dim=static_nodes_dim,\n",
    "    edge_dim=edge_attr_dim,\n",
    "    n_embd=n_embd,\n",
    "    n_heads=n_heads,\n",
    "    dropout_rate=dropout,\n",
    ").to(device)\n",
    "\n",
    "model.load_state_dict(torch.load(\"data/models/iter4_gat.pth\", map_location=device))\n",
    "model.eval()\n",
    "print(f\"Model loaded with {sum(p.numel() for p in model.parameters())/1e3:.1f}K parameters\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare graph data\n",
    "X_static_input = static_features.to(device)\n",
    "edge_index_input = edge_index.to(device)\n",
    "edge_attr_input = edge_attr_data.to(device)\n",
    "num_nodes = static_features.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract predictions and parameters from test set\n",
    "def extract_predictions(model, data_loader, device):\n",
    "    model.eval()\n",
    "\n",
    "    all_targets = []\n",
    "    all_mu = []\n",
    "    all_theta = []\n",
    "    all_pi = []\n",
    "    all_preds = []\n",
    "    all_attention_1 = []\n",
    "    all_attention_2 = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for X_spatial, _, y_batch in data_loader:\n",
    "            X_batch = X_spatial.to(device)\n",
    "            y_batch = y_batch.to(device)\n",
    "            y_raw = (y_batch * SCALER_SIGMA) + SCALER_MU\n",
    "\n",
    "            preds, _, _, params = model(\n",
    "                X_batch=X_batch,\n",
    "                targets=y_raw,\n",
    "                node_mask=None,\n",
    "                edge_index=edge_index_input,\n",
    "                edge_attr=edge_attr_input,\n",
    "                static_node_features=X_static_input,\n",
    "                return_attention=True\n",
    "            )\n",
    "\n",
    "            all_targets.append(y_raw.cpu())\n",
    "            all_preds.append(preds.cpu())\n",
    "            all_mu.append(params['mu'].cpu())\n",
    "            all_theta.append(params['theta'].cpu())\n",
    "            all_pi.append(params['pi'].cpu())\n",
    "            all_attention_1.extend(params['attention_1'])\n",
    "            all_attention_2.extend(params['attention_2'])\n",
    "\n",
    "    return {\n",
    "        'targets': torch.cat(all_targets, dim=0),\n",
    "        'preds': torch.cat(all_preds, dim=0),\n",
    "        'mu': torch.cat(all_mu, dim=0),\n",
    "        'theta': torch.cat(all_theta, dim=0),\n",
    "        'pi': torch.cat(all_pi, dim=0),\n",
    "        'attention_1': all_attention_1,\n",
    "        'attention_2': all_attention_2\n",
    "    }\n",
    "\n",
    "test_results = extract_predictions(model, test_loader, device)\n",
    "val_results = extract_predictions(model, val_loader, device)\n",
    "train_results = extract_predictions(model, train_loader, device)\n",
    "\n",
    "print(f\"Test samples: {test_results['targets'].shape[0]}\")\n",
    "print(f\"Validation samples: {val_results['targets'].shape[0]}\")\n",
    "print(f\"Training samples: {train_results['targets'].shape[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8",
   "metadata": {},
   "source": [
    "## 1. Compute Calibration Metrics for ZINB Predictions\n",
    "\n",
    "Calculate calibration metrics to assess how well the predicted ZINB distributions match observed frequencies. Compute PIT (Probability Integral Transform) histograms and reliability diagrams for the zero-inflation component."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_zinb_cdf(y, mu, theta, pi):\n",
    "    \"\"\"\n",
    "    Compute CDF of ZINB distribution at point y.\n",
    "    ZINB CDF = pi * I(y >= 0) + (1 - pi) * NB_CDF(y)\n",
    "    \"\"\"\n",
    "    eps = 1e-8\n",
    "\n",
    "    # Convert to numpy\n",
    "    y = np.asarray(y)\n",
    "    mu = np.asarray(mu)\n",
    "    theta = np.asarray(theta)\n",
    "    pi = np.asarray(pi)\n",
    "\n",
    "    # NB parameters for scipy\n",
    "    n_scipy = np.maximum(theta, eps)\n",
    "    p_scipy = n_scipy / (mu + n_scipy + eps)\n",
    "    p_scipy = np.clip(p_scipy, eps, 1-eps)\n",
    "\n",
    "    # NB CDF\n",
    "    nb_cdf = sp_stats.nbinom.cdf(y, n=n_scipy, p=p_scipy)\n",
    "\n",
    "    # ZINB CDF\n",
    "    zinb_cdf = pi + (1 - pi) * nb_cdf\n",
    "\n",
    "    return zinb_cdf\n",
    "\n",
    "def compute_pit_values(targets, mu, theta, pi):\n",
    "    \"\"\"\n",
    "    Compute Probability Integral Transform (PIT) values.\n",
    "    For a well-calibrated model, PIT values should be uniformly distributed.\n",
    "    \"\"\"\n",
    "    # Flatten all tensors\n",
    "    targets_flat = targets.numpy().flatten()\n",
    "    mu_flat = mu.numpy().flatten()\n",
    "    theta_flat = theta.numpy().flatten()\n",
    "    pi_flat = pi.numpy().flatten()\n",
    "\n",
    "    # Remove NaN values\n",
    "    valid_mask = ~np.isnan(targets_flat)\n",
    "    targets_valid = targets_flat[valid_mask]\n",
    "    mu_valid = mu_flat[valid_mask]\n",
    "    theta_valid = theta_flat[valid_mask]\n",
    "    pi_valid = pi_flat[valid_mask]\n",
    "\n",
    "    # Ensure non-negative counts\n",
    "    targets_valid = np.maximum(np.round(targets_valid), 0)\n",
    "\n",
    "    # Compute PIT values\n",
    "    pit_values = compute_zinb_cdf(targets_valid, mu_valid, theta_valid, pi_valid)\n",
    "\n",
    "    return pit_values, targets_valid, mu_valid, theta_valid, pi_valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute PIT values for test set\n",
    "pit_values, targets_valid, mu_valid, theta_valid, pi_valid = compute_pit_values(\n",
    "    test_results['targets'],\n",
    "    test_results['mu'],\n",
    "    test_results['theta'],\n",
    "    test_results['pi']\n",
    ")\n",
    "\n",
    "print(f\"Computed PIT values for {len(pit_values)} valid samples\")\n",
    "print(f\"PIT value range: [{pit_values.min():.4f}, {pit_values.max():.4f}]\")\n",
    "print(f\"PIT value mean: {pit_values.mean():.4f} (should be ~0.5 for calibrated model)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot PIT histogram\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 4))\n",
    "\n",
    "# PIT Histogram\n",
    "ax1 = axes[0]\n",
    "ax1.hist(pit_values, bins=20, density=True, alpha=0.7, color='steelblue', edgecolor='black')\n",
    "ax1.axhline(y=1.0, color='red', linestyle='--', linewidth=2, label='Uniform (ideal)')\n",
    "ax1.set_xlabel('PIT Value')\n",
    "ax1.set_ylabel('Density')\n",
    "ax1.set_title('PIT Histogram (Test Set)')\n",
    "ax1.legend()\n",
    "ax1.set_xlim(0, 1)\n",
    "\n",
    "# Kolmogorov-Smirnov test for uniformity\n",
    "ks_stat, ks_pvalue = sp_stats.kstest(pit_values, 'uniform')\n",
    "ax1.text(0.05, 0.95, f'KS stat: {ks_stat:.4f}\\np-value: {ks_pvalue:.4f}',\n",
    "         transform=ax1.transAxes, verticalalignment='top', fontsize=10,\n",
    "         bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.5))\n",
    "\n",
    "# Reliability diagram for zero-inflation\n",
    "ax2 = axes[1]\n",
    "# Bin predictions by pi value\n",
    "n_bins = 10\n",
    "pi_bins = np.linspace(0, 1, n_bins + 1)\n",
    "observed_zero_fracs = []\n",
    "predicted_zero_fracs = []\n",
    "\n",
    "for i in range(n_bins):\n",
    "    mask = (pi_valid >= pi_bins[i]) & (pi_valid < pi_bins[i+1])\n",
    "    if mask.sum() > 0:\n",
    "        observed_zero_frac = (targets_valid[mask] == 0).mean()\n",
    "        predicted_zero_frac = pi_valid[mask].mean()\n",
    "        observed_zero_fracs.append(observed_zero_frac)\n",
    "        predicted_zero_fracs.append(predicted_zero_frac)\n",
    "\n",
    "ax2.scatter(predicted_zero_fracs, observed_zero_fracs, s=100, alpha=0.7, color='steelblue')\n",
    "ax2.plot([0, 1], [0, 1], 'r--', linewidth=2, label='Perfect calibration')\n",
    "ax2.set_xlabel('Predicted Zero Probability (π)')\n",
    "ax2.set_ylabel('Observed Zero Fraction')\n",
    "ax2.set_title('Zero-Inflation Reliability Diagram')\n",
    "ax2.legend()\n",
    "ax2.set_xlim(0, 1)\n",
    "ax2.set_ylim(0, 1)\n",
    "ax2.set_aspect('equal')\n",
    "\n",
    "# Distribution of pi values\n",
    "ax3 = axes[2]\n",
    "ax3.hist(pi_valid, bins=30, density=True, alpha=0.7, color='steelblue', edgecolor='black')\n",
    "ax3.set_xlabel('Zero-Inflation Probability (π)')\n",
    "ax3.set_ylabel('Density')\n",
    "ax3.set_title('Distribution of Predicted π Values')\n",
    "ax3.axvline(x=pi_valid.mean(), color='red', linestyle='--', linewidth=2,\n",
    "            label=f'Mean: {pi_valid.mean():.3f}')\n",
    "ax3.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\nCalibration Summary:\")\n",
    "print(f\"  KS Statistic (PIT uniformity): {ks_stat:.4f}\")\n",
    "print(f\"  KS p-value: {ks_pvalue:.4f}\")\n",
    "print(f\"  Mean predicted π: {pi_valid.mean():.4f}\")\n",
    "print(f\"  Observed zero fraction: {(targets_valid == 0).mean():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Per-node calibration analysis\n",
    "def compute_per_node_calibration(targets, mu, theta, pi):\n",
    "    \"\"\"Compute calibration metrics per node.\"\"\"\n",
    "    num_nodes = targets.shape[2]\n",
    "    node_calibration = []\n",
    "\n",
    "    for node in range(num_nodes):\n",
    "        node_targets = targets[:, 0, node, -1].numpy()\n",
    "        node_mu = mu[:, 0, node, -1].numpy()\n",
    "        node_theta = theta[:, 0, node, -1].numpy()\n",
    "        node_pi = pi[:, 0, node, -1].numpy()\n",
    "\n",
    "        valid_mask = ~np.isnan(node_targets)\n",
    "        if valid_mask.sum() < 10:\n",
    "            node_calibration.append({\n",
    "                'node': node, 'ks_stat': np.nan, 'ks_pvalue': np.nan,\n",
    "                'observed_zero_frac': np.nan, 'predicted_zero_frac': np.nan\n",
    "            })\n",
    "            continue\n",
    "\n",
    "        node_targets_valid = np.maximum(np.round(node_targets[valid_mask]), 0)\n",
    "        node_mu_valid = node_mu[valid_mask]\n",
    "        node_theta_valid = node_theta[valid_mask]\n",
    "        node_pi_valid = node_pi[valid_mask]\n",
    "\n",
    "        pit = compute_zinb_cdf(node_targets_valid, node_mu_valid, node_theta_valid, node_pi_valid)\n",
    "        ks_stat, ks_pvalue = sp_stats.kstest(pit, 'uniform')\n",
    "\n",
    "        node_calibration.append({\n",
    "            'node': node,\n",
    "            'name': id_to_name_map.get(node, f'Node_{node}'),\n",
    "            'ks_stat': ks_stat,\n",
    "            'ks_pvalue': ks_pvalue,\n",
    "            'observed_zero_frac': (node_targets_valid == 0).mean(),\n",
    "            'predicted_zero_frac': node_pi_valid.mean(),\n",
    "            'n_samples': len(node_targets_valid)\n",
    "        })\n",
    "\n",
    "    return pd.DataFrame(node_calibration)\n",
    "\n",
    "node_calibration_df = compute_per_node_calibration(\n",
    "    test_results['targets'],\n",
    "    test_results['mu'],\n",
    "    test_results['theta'],\n",
    "    test_results['pi']\n",
    ")\n",
    "\n",
    "print(\"Per-Node Calibration Metrics (sorted by KS statistic):\")\n",
    "print(node_calibration_df.sort_values('ks_stat', ascending=False).head(10).to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13",
   "metadata": {},
   "source": [
    "## 2. Calculate CRPS (Continuous Ranked Probability Score)\n",
    "\n",
    "Implement CRPS scoring for the ZINB distribution to evaluate probabilistic forecast quality. Compare against baseline models using proper scoring rules."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_zinb_crps_mc(y, mu, theta, pi, n_samples=1000):\n",
    "    \"\"\"\n",
    "    Compute CRPS using Monte Carlo integration for ZINB distribution.\n",
    "    CRPS = E|Y - y| - 0.5 * E|Y - Y'|\n",
    "    where Y, Y' are independent samples from the forecast distribution.\n",
    "    \"\"\"\n",
    "    eps = 1e-8\n",
    "\n",
    "    # Ensure arrays\n",
    "    y = np.asarray(y).flatten()\n",
    "    mu = np.asarray(mu).flatten()\n",
    "    theta = np.asarray(theta).flatten()\n",
    "    pi = np.asarray(pi).flatten()\n",
    "\n",
    "    n_obs = len(y)\n",
    "\n",
    "    # NB parameters for scipy\n",
    "    n_scipy = np.maximum(theta, eps)\n",
    "    p_scipy = n_scipy / (mu + n_scipy + eps)\n",
    "    p_scipy = np.clip(p_scipy, eps, 1-eps)\n",
    "\n",
    "    crps_values = np.zeros(n_obs)\n",
    "\n",
    "    for i in range(n_obs):\n",
    "        # Generate samples from ZINB\n",
    "        # First, determine if zero-inflated\n",
    "        is_zero_inflated = np.random.random(n_samples) < pi[i]\n",
    "\n",
    "        # Sample from NB for non-zero-inflated\n",
    "        nb_samples = sp_stats.nbinom.rvs(n=n_scipy[i], p=p_scipy[i], size=n_samples)\n",
    "\n",
    "        # Apply zero-inflation\n",
    "        samples = np.where(is_zero_inflated, 0, nb_samples)\n",
    "\n",
    "        # CRPS = E|Y - y|\n",
    "        term1 = np.abs(samples - y[i]).mean()\n",
    "\n",
    "        # - 0.5 * E|Y - Y'|\n",
    "        samples2 = samples.copy()\n",
    "        np.random.shuffle(samples2)\n",
    "        term2 = 0.5 * np.abs(samples - samples2).mean()\n",
    "\n",
    "        crps_values[i] = term1 - term2\n",
    "\n",
    "    return crps_values\n",
    "\n",
    "def compute_baseline_crps(y, baseline_type='climatology'):\n",
    "    \"\"\"Compute CRPS for baseline models.\"\"\"\n",
    "    y = np.asarray(y).flatten()\n",
    "    valid_mask = ~np.isnan(y)\n",
    "    y_valid = y[valid_mask]\n",
    "\n",
    "    if baseline_type == 'climatology':\n",
    "        # Use empirical distribution as forecast\n",
    "        mean_y = y_valid.mean()\n",
    "        std_y = y_valid.std()\n",
    "\n",
    "        # Approximate CRPS for normal distribution\n",
    "        # CRPS_normal = sigma * (z * (2*Phi(z) - 1) + 2*phi(z) - 1/sqrt(pi))\n",
    "        # where z = (y - mu) / sigma\n",
    "        z = (y_valid - mean_y) / (std_y + 1e-8)\n",
    "        crps = std_y * (z * (2 * sp_stats.norm.cdf(z) - 1) +\n",
    "                        2 * sp_stats.norm.pdf(z) - 1/np.sqrt(np.pi))\n",
    "        return np.abs(crps)\n",
    "\n",
    "    elif baseline_type == 'persistence':\n",
    "        # Use previous value as forecast (assuming sequential data)\n",
    "        crps = np.abs(y_valid[1:] - y_valid[:-1])\n",
    "        return np.concatenate([[np.nan], crps])\n",
    "\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute CRPS for a subset of test data (MC is expensive)\n",
    "n_subset = min(1000, len(targets_valid))\n",
    "subset_idx = np.random.choice(len(targets_valid), n_subset, replace=False)\n",
    "\n",
    "print(f\"Computing CRPS for {n_subset} samples (Monte Carlo with 500 samples each)...\")\n",
    "\n",
    "zinb_crps = compute_zinb_crps_mc(\n",
    "    targets_valid[subset_idx],\n",
    "    mu_valid[subset_idx],\n",
    "    theta_valid[subset_idx],\n",
    "    pi_valid[subset_idx],\n",
    "    n_samples=500\n",
    ")\n",
    "\n",
    "# Baseline CRPS\n",
    "climatology_crps = compute_baseline_crps(targets_valid[subset_idx], 'climatology')\n",
    "\n",
    "print(f\"\\nCRPS Summary:\")\n",
    "print(f\"  ZINB Model CRPS (mean): {zinb_crps.mean():.4f}\")\n",
    "print(f\"  ZINB Model CRPS (std): {zinb_crps.std():.4f}\")\n",
    "print(f\"  Climatology CRPS (mean): {climatology_crps.mean():.4f}\")\n",
    "print(f\"  Climatology CRPS (std): {climatology_crps.std():.4f}\")\n",
    "print(f\"  Skill Score: {1 - zinb_crps.mean() / climatology_crps.mean():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize CRPS comparison\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 4))\n",
    "\n",
    "# CRPS distribution comparison\n",
    "ax1 = axes[0]\n",
    "ax1.hist(zinb_crps, bins=30, alpha=0.7, label='ZINB Model', density=True, color='steelblue')\n",
    "ax1.hist(climatology_crps, bins=30, alpha=0.7, label='Climatology', density=True, color='orange')\n",
    "ax1.set_xlabel('CRPS')\n",
    "ax1.set_ylabel('Density')\n",
    "ax1.set_title('CRPS Distribution Comparison')\n",
    "ax1.legend()\n",
    "\n",
    "# CRPS vs observed value\n",
    "ax2 = axes[1]\n",
    "scatter = ax2.scatter(targets_valid[subset_idx], zinb_crps, alpha=0.3, s=10, c='steelblue')\n",
    "ax2.set_xlabel('Observed Value')\n",
    "ax2.set_ylabel('CRPS')\n",
    "ax2.set_title('CRPS vs Observed Value')\n",
    "\n",
    "# Compute binned average\n",
    "bins = np.percentile(targets_valid[subset_idx], np.linspace(0, 100, 11))\n",
    "bin_centers = []\n",
    "bin_crps_means = []\n",
    "for i in range(len(bins)-1):\n",
    "    mask = (targets_valid[subset_idx] >= bins[i]) & (targets_valid[subset_idx] < bins[i+1])\n",
    "    if mask.sum() > 0:\n",
    "        bin_centers.append((bins[i] + bins[i+1]) / 2)\n",
    "        bin_crps_means.append(zinb_crps[mask].mean())\n",
    "\n",
    "ax2.plot(bin_centers, bin_crps_means, 'ro-', linewidth=2, markersize=8, label='Binned mean')\n",
    "ax2.legend()\n",
    "\n",
    "# CRPS per node (for first few nodes)\n",
    "ax3 = axes[2]\n",
    "node_crps = []\n",
    "for node in range(min(10, num_nodes)):\n",
    "    node_targets = test_results['targets'][:, 0, node, -1].numpy()\n",
    "    node_mu = test_results['mu'][:, 0, node, -1].numpy()\n",
    "    node_theta = test_results['theta'][:, 0, node, -1].numpy()\n",
    "    node_pi = test_results['pi'][:, 0, node, -1].numpy()\n",
    "\n",
    "    valid_mask = ~np.isnan(node_targets)\n",
    "    if valid_mask.sum() > 50:\n",
    "        node_targets_valid = np.maximum(np.round(node_targets[valid_mask][:100]), 0)\n",
    "        crps = compute_zinb_crps_mc(\n",
    "            node_targets_valid,\n",
    "            node_mu[valid_mask][:100],\n",
    "            node_theta[valid_mask][:100],\n",
    "            node_pi[valid_mask][:100],\n",
    "            n_samples=200\n",
    "        )\n",
    "        node_crps.append({'node': node, 'name': id_to_name_map.get(node, f'N{node}')[:15], 'crps': crps.mean()})\n",
    "\n",
    "if node_crps:\n",
    "    crps_df = pd.DataFrame(node_crps)\n",
    "    ax3.barh(range(len(crps_df)), crps_df['crps'], color='steelblue')\n",
    "    ax3.set_yticks(range(len(crps_df)))\n",
    "    ax3.set_yticklabels(crps_df['name'])\n",
    "    ax3.set_xlabel('Mean CRPS')\n",
    "    ax3.set_title('CRPS by Node (First 10)')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17",
   "metadata": {},
   "source": [
    "## 3. Analyze Prediction Intervals Coverage\n",
    "\n",
    "Compute empirical coverage rates for 50%, 80%, and 95% prediction intervals across all nodes. Identify nodes with under/over-confident predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_prediction_intervals(mu, theta, pi, coverage_levels=[0.5, 0.8, 0.95]):\n",
    "    \"\"\"\n",
    "    Compute prediction intervals for ZINB distribution.\n",
    "    Returns lower and upper bounds for each coverage level.\n",
    "    \"\"\"\n",
    "    eps = 1e-8\n",
    "\n",
    "    mu = np.asarray(mu)\n",
    "    theta = np.asarray(theta)\n",
    "    pi = np.asarray(pi)\n",
    "\n",
    "    n_scipy = np.maximum(theta, eps)\n",
    "    p_scipy = n_scipy / (mu + n_scipy + eps)\n",
    "    p_scipy = np.clip(p_scipy, eps, 1-eps)\n",
    "\n",
    "    intervals = {}\n",
    "\n",
    "    for coverage in coverage_levels:\n",
    "        alpha = 1 - coverage\n",
    "        q_lower = alpha / 2\n",
    "        q_upper = 1 - alpha / 2\n",
    "\n",
    "        # Probability of zero in ZINB\n",
    "        prob_zero = pi + (1 - pi) * sp_stats.nbinom.pmf(0, n=n_scipy, p=p_scipy)\n",
    "\n",
    "        # Lower bound\n",
    "        q_lower_adj = np.clip((q_lower - pi) / (1 - pi + eps), eps, 1-eps)\n",
    "        nb_lower = sp_stats.nbinom.ppf(q_lower_adj, n=n_scipy, p=p_scipy)\n",
    "        lower = np.where(q_lower <= prob_zero, 0.0, nb_lower)\n",
    "\n",
    "        # Upper bound\n",
    "        q_upper_adj = np.clip((q_upper - pi) / (1 - pi + eps), eps, 1-eps)\n",
    "        nb_upper = sp_stats.nbinom.ppf(q_upper_adj, n=n_scipy, p=p_scipy)\n",
    "        upper = np.where(q_upper <= prob_zero, 0.0, nb_upper)\n",
    "\n",
    "        intervals[coverage] = {'lower': lower, 'upper': upper}\n",
    "\n",
    "    return intervals\n",
    "\n",
    "def compute_coverage_rates(targets, intervals):\n",
    "    \"\"\"Compute empirical coverage rates.\"\"\"\n",
    "    coverage_rates = {}\n",
    "\n",
    "    for coverage, bounds in intervals.items():\n",
    "        lower = bounds['lower']\n",
    "        upper = bounds['upper']\n",
    "\n",
    "        in_interval = (targets >= lower) & (targets <= upper)\n",
    "        coverage_rates[coverage] = {\n",
    "            'empirical': in_interval.mean(),\n",
    "            'nominal': coverage,\n",
    "            'calibration_error': in_interval.mean() - coverage\n",
    "        }\n",
    "\n",
    "    return coverage_rates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute prediction intervals for test set\n",
    "coverage_levels = [0.5, 0.8, 0.95]\n",
    "\n",
    "intervals = compute_prediction_intervals(\n",
    "    mu_valid, theta_valid, pi_valid, coverage_levels\n",
    ")\n",
    "\n",
    "coverage_rates = compute_coverage_rates(targets_valid, intervals)\n",
    "\n",
    "print(\"Prediction Interval Coverage Analysis:\")\n",
    "print(\"-\" * 50)\n",
    "for coverage, rates in coverage_rates.items():\n",
    "    print(f\"{int(coverage*100)}% Interval:\")\n",
    "    print(f\"  Nominal coverage: {rates['nominal']:.1%}\")\n",
    "    print(f\"  Empirical coverage: {rates['empirical']:.1%}\")\n",
    "    print(f\"  Calibration error: {rates['calibration_error']:+.1%}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize coverage analysis\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 4))\n",
    "\n",
    "# Coverage comparison bar chart\n",
    "ax1 = axes[0]\n",
    "x = np.arange(len(coverage_levels))\n",
    "width = 0.35\n",
    "\n",
    "nominal = [coverage_rates[c]['nominal'] for c in coverage_levels]\n",
    "empirical = [coverage_rates[c]['empirical'] for c in coverage_levels]\n",
    "\n",
    "bars1 = ax1.bar(x - width/2, nominal, width, label='Nominal', color='steelblue', alpha=0.7)\n",
    "bars2 = ax1.bar(x + width/2, empirical, width, label='Empirical', color='orange', alpha=0.7)\n",
    "\n",
    "ax1.set_ylabel('Coverage Rate')\n",
    "ax1.set_title('Prediction Interval Coverage')\n",
    "ax1.set_xticks(x)\n",
    "ax1.set_xticklabels([f'{int(c*100)}%' for c in coverage_levels])\n",
    "ax1.legend()\n",
    "ax1.set_ylim(0, 1.1)\n",
    "\n",
    "# Add reference line at perfect calibration\n",
    "for i, c in enumerate(coverage_levels):\n",
    "    ax1.axhline(y=c, color='gray', linestyle='--', alpha=0.5)\n",
    "\n",
    "# Per-node coverage for 95% interval\n",
    "ax2 = axes[1]\n",
    "node_coverage_95 = []\n",
    "\n",
    "for node in range(num_nodes):\n",
    "    node_targets = test_results['targets'][:, 0, node, -1].numpy()\n",
    "    node_mu = test_results['mu'][:, 0, node, -1].numpy()\n",
    "    node_theta = test_results['theta'][:, 0, node, -1].numpy()\n",
    "    node_pi = test_results['pi'][:, 0, node, -1].numpy()\n",
    "\n",
    "    valid_mask = ~np.isnan(node_targets)\n",
    "    if valid_mask.sum() < 10:\n",
    "        node_coverage_95.append(np.nan)\n",
    "        continue\n",
    "\n",
    "    node_targets_valid = np.maximum(np.round(node_targets[valid_mask]), 0)\n",
    "\n",
    "    node_intervals = compute_prediction_intervals(\n",
    "        node_mu[valid_mask], node_theta[valid_mask], node_pi[valid_mask], [0.95]\n",
    "    )\n",
    "\n",
    "    in_interval = (node_targets_valid >= node_intervals[0.95]['lower']) & \\\n",
    "                  (node_targets_valid <= node_intervals[0.95]['upper'])\n",
    "    node_coverage_95.append(in_interval.mean())\n",
    "\n",
    "ax2.bar(range(num_nodes), node_coverage_95, color='steelblue', alpha=0.7)\n",
    "ax2.axhline(y=0.95, color='red', linestyle='--', linewidth=2, label='Nominal 95%')\n",
    "ax2.set_xlabel('Node Index')\n",
    "ax2.set_ylabel('Empirical Coverage')\n",
    "ax2.set_title('95% PI Coverage by Node')\n",
    "ax2.legend()\n",
    "\n",
    "# Identify over/under-confident nodes\n",
    "ax3 = axes[2]\n",
    "node_coverage_95 = np.array(node_coverage_95)\n",
    "calibration_errors = node_coverage_95 - 0.95\n",
    "\n",
    "colors = ['red' if e < -0.1 else 'green' if e > 0.1 else 'steelblue' for e in calibration_errors]\n",
    "ax3.bar(range(num_nodes), calibration_errors, color=colors, alpha=0.7)\n",
    "ax3.axhline(y=0, color='black', linewidth=1)\n",
    "ax3.axhline(y=0.1, color='green', linestyle='--', alpha=0.5, label='Over-confident threshold')\n",
    "ax3.axhline(y=-0.1, color='red', linestyle='--', alpha=0.5, label='Under-confident threshold')\n",
    "ax3.set_xlabel('Node Index')\n",
    "ax3.set_ylabel('Coverage Error (Empirical - Nominal)')\n",
    "ax3.set_title('95% PI Calibration Error by Node')\n",
    "ax3.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Print nodes with significant calibration issues\n",
    "print(\"\\nNodes with significant calibration issues (|error| > 10%):\")\n",
    "for node in range(num_nodes):\n",
    "    if not np.isnan(calibration_errors[node]) and abs(calibration_errors[node]) > 0.1:\n",
    "        status = \"UNDER-confident\" if calibration_errors[node] < 0 else \"OVER-confident\"\n",
    "        print(f\"  Node {node} ({id_to_name_map.get(node, 'Unknown')}): {calibration_errors[node]:+.1%} ({status})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21",
   "metadata": {},
   "source": [
    "## 4. Visualize Attention Weights from GAT Layers\n",
    "\n",
    "Extract and visualize attention coefficients from GATv2Conv layers to understand which node connections the model prioritizes. Create heatmaps and graph visualizations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_attention_matrix(attention_tuple, num_nodes):\n",
    "    \"\"\"\n",
    "    Convert attention weights from sparse format to dense matrix.\n",
    "    attention_tuple = (edge_index, attention_weights)\n",
    "    \"\"\"\n",
    "    edge_index, attention_weights = attention_tuple\n",
    "\n",
    "    # Move to CPU if needed\n",
    "    if isinstance(edge_index, torch.Tensor):\n",
    "        edge_index = edge_index.cpu().numpy()\n",
    "    if isinstance(attention_weights, torch.Tensor):\n",
    "        attention_weights = attention_weights.cpu().numpy()\n",
    "\n",
    "    # attention_weights shape: [num_edges, num_heads]\n",
    "    # Average across heads\n",
    "    if len(attention_weights.shape) > 1:\n",
    "        attention_weights = attention_weights.mean(axis=1)\n",
    "\n",
    "    # Create dense attention matrix\n",
    "    attn_matrix = np.zeros((num_nodes, num_nodes))\n",
    "\n",
    "    for i in range(edge_index.shape[1]):\n",
    "        src, dst = edge_index[0, i], edge_index[1, i]\n",
    "        if src < num_nodes and dst < num_nodes:\n",
    "            attn_matrix[dst, src] = attention_weights[i]\n",
    "\n",
    "    return attn_matrix\n",
    "\n",
    "def aggregate_attention_weights(attention_list, num_nodes, n_samples=50):\n",
    "    \"\"\"Aggregate attention weights across multiple samples.\"\"\"\n",
    "    aggregated = np.zeros((num_nodes, num_nodes))\n",
    "    count = 0\n",
    "\n",
    "    for attn in attention_list[:n_samples]:\n",
    "        try:\n",
    "            attn_matrix = extract_attention_matrix(attn, num_nodes)\n",
    "            aggregated += attn_matrix\n",
    "            count += 1\n",
    "        except Exception as e:\n",
    "            continue\n",
    "\n",
    "    if count > 0:\n",
    "        aggregated /= count\n",
    "\n",
    "    return aggregated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aggregate attention weights\n",
    "print(\"Aggregating attention weights from first 50 samples...\")\n",
    "attn_matrix_1 = aggregate_attention_weights(test_results['attention_1'], num_nodes, n_samples=50)\n",
    "attn_matrix_2 = aggregate_attention_weights(test_results['attention_2'], num_nodes, n_samples=50)\n",
    "\n",
    "print(f\"Attention matrix 1 shape: {attn_matrix_1.shape}\")\n",
    "print(f\"Attention matrix 2 shape: {attn_matrix_2.shape}\")\n",
    "print(f\"Non-zero entries in layer 1: {(attn_matrix_1 > 0).sum()}\")\n",
    "print(f\"Non-zero entries in layer 2: {(attn_matrix_2 > 0).sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize attention weights\n",
    "fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
    "\n",
    "# Heatmap for layer 1\n",
    "ax1 = axes[0]\n",
    "im1 = ax1.imshow(attn_matrix_1, cmap='Blues', aspect='auto')\n",
    "ax1.set_xlabel('Source Node')\n",
    "ax1.set_ylabel('Target Node')\n",
    "ax1.set_title('GAT Layer 1 Attention Weights')\n",
    "plt.colorbar(im1, ax=ax1, label='Attention Weight')\n",
    "\n",
    "# Heatmap for layer 2\n",
    "ax2 = axes[1]\n",
    "im2 = ax2.imshow(attn_matrix_2, cmap='Oranges', aspect='auto')\n",
    "ax2.set_xlabel('Source Node')\n",
    "ax2.set_ylabel('Target Node')\n",
    "ax2.set_title('GAT Layer 2 Attention Weights')\n",
    "plt.colorbar(im2, ax=ax2, label='Attention Weight')\n",
    "\n",
    "# Average attention received per node\n",
    "ax3 = axes[2]\n",
    "avg_attn_received_1 = attn_matrix_1.sum(axis=1)\n",
    "avg_attn_received_2 = attn_matrix_2.sum(axis=1)\n",
    "\n",
    "x = np.arange(num_nodes)\n",
    "width = 0.35\n",
    "ax3.bar(x - width/2, avg_attn_received_1, width, label='Layer 1', color='steelblue', alpha=0.7)\n",
    "ax3.bar(x + width/2, avg_attn_received_2, width, label='Layer 2', color='orange', alpha=0.7)\n",
    "ax3.set_xlabel('Node Index')\n",
    "ax3.set_ylabel('Total Attention Received')\n",
    "ax3.set_title('Attention Received per Node')\n",
    "ax3.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create graph visualization with attention weights\n",
    "fig, axes = plt.subplots(1, 2, figsize=(16, 7))\n",
    "\n",
    "# Create graph from edge_index\n",
    "edge_index_np = edge_index.numpy()\n",
    "G = nx.DiGraph()\n",
    "G.add_nodes_from(range(num_nodes))\n",
    "\n",
    "# Add edges with attention weights\n",
    "for i in range(edge_index_np.shape[1]):\n",
    "    src, dst = edge_index_np[0, i], edge_index_np[1, i]\n",
    "    weight = attn_matrix_1[dst, src]\n",
    "    if weight > 0:\n",
    "        G.add_edge(src, dst, weight=weight)\n",
    "\n",
    "# Get positions using spring layout\n",
    "pos = nx.spring_layout(G, seed=42, k=2)\n",
    "\n",
    "# Layer 1 attention visualization\n",
    "ax1 = axes[0]\n",
    "edges = G.edges()\n",
    "weights = [G[u][v]['weight'] * 10 for u, v in edges]  # Scale for visibility\n",
    "\n",
    "node_colors = avg_attn_received_1\n",
    "nodes = nx.draw_networkx_nodes(G, pos, node_color=node_colors,\n",
    "                                cmap=plt.cm.Blues, node_size=300, ax=ax1)\n",
    "nx.draw_networkx_edges(G, pos, edge_color='gray', alpha=0.5,\n",
    "                       width=weights, arrows=True, arrowsize=10, ax=ax1)\n",
    "\n",
    "# Add node labels\n",
    "labels = {i: id_to_name_map.get(i, str(i))[:8] for i in range(num_nodes)}\n",
    "nx.draw_networkx_labels(G, pos, labels, font_size=6, ax=ax1)\n",
    "\n",
    "ax1.set_title('Graph with Layer 1 Attention (Node color = attention received)')\n",
    "plt.colorbar(nodes, ax=ax1, label='Attention Received')\n",
    "\n",
    "# Update graph with layer 2 attention\n",
    "for i in range(edge_index_np.shape[1]):\n",
    "    src, dst = edge_index_np[0, i], edge_index_np[1, i]\n",
    "    if G.has_edge(src, dst):\n",
    "        G[src][dst]['weight'] = attn_matrix_2[dst, src]\n",
    "\n",
    "ax2 = axes[1]\n",
    "weights = [G[u][v]['weight'] * 10 for u, v in edges]\n",
    "node_colors = avg_attn_received_2\n",
    "\n",
    "nodes = nx.draw_networkx_nodes(G, pos, node_color=node_colors,\n",
    "                                cmap=plt.cm.Oranges, node_size=300, ax=ax2)\n",
    "nx.draw_networkx_edges(G, pos, edge_color='gray', alpha=0.5,\n",
    "                       width=weights, arrows=True, arrowsize=10, ax=ax2)\n",
    "nx.draw_networkx_labels(G, pos, labels, font_size=6, ax=ax2)\n",
    "\n",
    "ax2.set_title('Graph with Layer 2 Attention (Node color = attention received)')\n",
    "plt.colorbar(nodes, ax=ax2, label='Attention Received')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify most important edges by attention\n",
    "print(\"\\nTop 10 Most Important Edges (by Layer 1 attention):\")\n",
    "edge_importance = []\n",
    "for i in range(edge_index_np.shape[1]):\n",
    "    src, dst = edge_index_np[0, i], edge_index_np[1, i]\n",
    "    weight = attn_matrix_1[dst, src]\n",
    "    if weight > 0:\n",
    "        edge_importance.append({\n",
    "            'source': src,\n",
    "            'source_name': id_to_name_map.get(src, f'Node_{src}')[:20],\n",
    "            'target': dst,\n",
    "            'target_name': id_to_name_map.get(dst, f'Node_{dst}')[:20],\n",
    "            'attention': weight\n",
    "        })\n",
    "\n",
    "edge_df = pd.DataFrame(edge_importance).sort_values('attention', ascending=False)\n",
    "print(edge_df.head(10).to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27",
   "metadata": {},
   "source": [
    "## 5. Compare Node-Level Performance Metrics\n",
    "\n",
    "Calculate per-node MAE, RMSE, and NLL metrics. Create bar charts comparing performance across sensor nodes and identify systematic prediction errors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_node_metrics(targets, preds, mu, theta, pi):\n",
    "    \"\"\"Compute per-node performance metrics.\"\"\"\n",
    "    num_nodes = targets.shape[2]\n",
    "    metrics = []\n",
    "\n",
    "    for node in range(num_nodes):\n",
    "        node_targets = targets[:, 0, node, -1].numpy()\n",
    "        node_preds = preds[:, 0, node, -1].numpy()\n",
    "        node_mu = mu[:, 0, node, -1].numpy()\n",
    "        node_theta = theta[:, 0, node, -1].numpy()\n",
    "        node_pi = pi[:, 0, node, -1].numpy()\n",
    "\n",
    "        valid_mask = ~np.isnan(node_targets)\n",
    "        n_valid = valid_mask.sum()\n",
    "\n",
    "        if n_valid < 10:\n",
    "            metrics.append({\n",
    "                'node': node,\n",
    "                'name': id_to_name_map.get(node, f'Node_{node}'),\n",
    "                'mae': np.nan, 'rmse': np.nan, 'nll': np.nan,\n",
    "                'bias': np.nan, 'n_samples': n_valid\n",
    "            })\n",
    "            continue\n",
    "\n",
    "        targets_valid = node_targets[valid_mask]\n",
    "        preds_valid = node_preds[valid_mask]\n",
    "        mu_valid = node_mu[valid_mask]\n",
    "        theta_valid = node_theta[valid_mask]\n",
    "        pi_valid = node_pi[valid_mask]\n",
    "\n",
    "        # MAE\n",
    "        mae = np.abs(targets_valid - preds_valid).mean()\n",
    "\n",
    "        # RMSE\n",
    "        rmse = np.sqrt(((targets_valid - preds_valid) ** 2).mean())\n",
    "\n",
    "        # Bias (mean error)\n",
    "        bias = (preds_valid - targets_valid).mean()\n",
    "\n",
    "        # NLL (ZINB negative log-likelihood)\n",
    "        eps = 1e-8\n",
    "        targets_count = np.maximum(np.round(targets_valid), 0)\n",
    "        n_scipy = np.maximum(theta_valid, eps)\n",
    "        p_scipy = n_scipy / (mu_valid + n_scipy + eps)\n",
    "        p_scipy = np.clip(p_scipy, eps, 1-eps)\n",
    "\n",
    "        # ZINB log probability\n",
    "        nb_log_prob = sp_stats.nbinom.logpmf(targets_count.astype(int), n=n_scipy, p=p_scipy)\n",
    "\n",
    "        zero_mask = targets_count == 0\n",
    "        log_prob = np.where(\n",
    "            zero_mask,\n",
    "            np.log(pi_valid + (1 - pi_valid) * np.exp(nb_log_prob) + eps),\n",
    "            np.log(1 - pi_valid + eps) + nb_log_prob\n",
    "        )\n",
    "        nll = -log_prob.mean()\n",
    "\n",
    "        metrics.append({\n",
    "            'node': node,\n",
    "            'name': id_to_name_map.get(node, f'Node_{node}'),\n",
    "            'mae': mae,\n",
    "            'rmse': rmse,\n",
    "            'nll': nll,\n",
    "            'bias': bias,\n",
    "            'n_samples': n_valid,\n",
    "            'mean_target': targets_valid.mean(),\n",
    "            'std_target': targets_valid.std()\n",
    "        })\n",
    "\n",
    "    return pd.DataFrame(metrics)\n",
    "\n",
    "# Compute metrics for test set\n",
    "node_metrics_df = compute_node_metrics(\n",
    "    test_results['targets'],\n",
    "    test_results['preds'],\n",
    "    test_results['mu'],\n",
    "    test_results['theta'],\n",
    "    test_results['pi']\n",
    ")\n",
    "\n",
    "print(\"Node-Level Performance Metrics Summary:\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"Mean MAE: {node_metrics_df['mae'].mean():.4f}\")\n",
    "print(f\"Mean RMSE: {node_metrics_df['rmse'].mean():.4f}\")\n",
    "print(f\"Mean NLL: {node_metrics_df['nll'].mean():.4f}\")\n",
    "print(f\"Mean Bias: {node_metrics_df['bias'].mean():.4f}\")\n",
    "print()\n",
    "print(\"Top 5 Best Performing Nodes (by MAE):\")\n",
    "print(node_metrics_df.nsmallest(5, 'mae')[['node', 'name', 'mae', 'rmse', 'nll', 'bias']].to_string(index=False))\n",
    "print()\n",
    "print(\"Top 5 Worst Performing Nodes (by MAE):\")\n",
    "print(node_metrics_df.nlargest(5, 'mae')[['node', 'name', 'mae', 'rmse', 'nll', 'bias']].to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize node-level metrics\n",
    "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "\n",
    "# MAE by node\n",
    "ax1 = axes[0, 0]\n",
    "colors = plt.cm.RdYlGn_r(np.linspace(0.2, 0.8, num_nodes))\n",
    "sorted_df = node_metrics_df.sort_values('mae')\n",
    "ax1.barh(range(num_nodes), sorted_df['mae'], color=colors)\n",
    "ax1.set_yticks(range(num_nodes))\n",
    "ax1.set_yticklabels([name[:15] for name in sorted_df['name']], fontsize=8)\n",
    "ax1.set_xlabel('MAE')\n",
    "ax1.set_title('MAE by Node (sorted)')\n",
    "ax1.axvline(x=node_metrics_df['mae'].mean(), color='red', linestyle='--', label=f'Mean: {node_metrics_df[\"mae\"].mean():.2f}')\n",
    "ax1.legend()\n",
    "\n",
    "# RMSE by node\n",
    "ax2 = axes[0, 1]\n",
    "ax2.barh(range(num_nodes), sorted_df['rmse'], color=colors)\n",
    "ax2.set_yticks(range(num_nodes))\n",
    "ax2.set_yticklabels([name[:15] for name in sorted_df['name']], fontsize=8)\n",
    "ax2.set_xlabel('RMSE')\n",
    "ax2.set_title('RMSE by Node (sorted by MAE)')\n",
    "ax2.axvline(x=node_metrics_df['rmse'].mean(), color='red', linestyle='--', label=f'Mean: {node_metrics_df[\"rmse\"].mean():.2f}')\n",
    "ax2.legend()\n",
    "\n",
    "# NLL by node\n",
    "ax3 = axes[1, 0]\n",
    "nll_sorted_df = node_metrics_df.sort_values('nll')\n",
    "ax3.barh(range(num_nodes), nll_sorted_df['nll'], color='steelblue', alpha=0.7)\n",
    "ax3.set_yticks(range(num_nodes))\n",
    "ax3.set_yticklabels([name[:15] for name in nll_sorted_df['name']], fontsize=8)\n",
    "ax3.set_xlabel('Negative Log-Likelihood')\n",
    "ax3.set_title('NLL by Node (sorted)')\n",
    "ax3.axvline(x=node_metrics_df['nll'].mean(), color='red', linestyle='--', label=f'Mean: {node_metrics_df[\"nll\"].mean():.2f}')\n",
    "ax3.legend()\n",
    "\n",
    "# Bias by node\n",
    "ax4 = axes[1, 1]\n",
    "bias_sorted_df = node_metrics_df.sort_values('bias')\n",
    "colors = ['red' if b < 0 else 'green' for b in bias_sorted_df['bias']]\n",
    "ax4.barh(range(num_nodes), bias_sorted_df['bias'], color=colors, alpha=0.7)\n",
    "ax4.set_yticks(range(num_nodes))\n",
    "ax4.set_yticklabels([name[:15] for name in bias_sorted_df['name']], fontsize=8)\n",
    "ax4.set_xlabel('Bias (Prediction - Target)')\n",
    "ax4.set_title('Prediction Bias by Node')\n",
    "ax4.axvline(x=0, color='black', linewidth=1)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze relationship between node characteristics and performance\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 4))\n",
    "\n",
    "# MAE vs mean traffic volume\n",
    "ax1 = axes[0]\n",
    "ax1.scatter(node_metrics_df['mean_target'], node_metrics_df['mae'],\n",
    "            s=100, alpha=0.7, c='steelblue')\n",
    "ax1.set_xlabel('Mean Traffic Volume')\n",
    "ax1.set_ylabel('MAE')\n",
    "ax1.set_title('MAE vs Mean Traffic Volume')\n",
    "\n",
    "# Add regression line\n",
    "valid_mask = ~(node_metrics_df['mae'].isna() | node_metrics_df['mean_target'].isna())\n",
    "if valid_mask.sum() > 2:\n",
    "    z = np.polyfit(node_metrics_df.loc[valid_mask, 'mean_target'],\n",
    "                   node_metrics_df.loc[valid_mask, 'mae'], 1)\n",
    "    p = np.poly1d(z)\n",
    "    x_range = np.linspace(node_metrics_df['mean_target'].min(),\n",
    "                          node_metrics_df['mean_target'].max(), 100)\n",
    "    ax1.plot(x_range, p(x_range), 'r--', linewidth=2, label='Linear fit')\n",
    "    ax1.legend()\n",
    "\n",
    "# MAE vs traffic variability\n",
    "ax2 = axes[1]\n",
    "ax2.scatter(node_metrics_df['std_target'], node_metrics_df['mae'],\n",
    "            s=100, alpha=0.7, c='orange')\n",
    "ax2.set_xlabel('Traffic Std Dev')\n",
    "ax2.set_ylabel('MAE')\n",
    "ax2.set_title('MAE vs Traffic Variability')\n",
    "\n",
    "if valid_mask.sum() > 2:\n",
    "    valid_mask2 = ~(node_metrics_df['mae'].isna() | node_metrics_df['std_target'].isna())\n",
    "    z = np.polyfit(node_metrics_df.loc[valid_mask2, 'std_target'],\n",
    "                   node_metrics_df.loc[valid_mask2, 'mae'], 1)\n",
    "    p = np.poly1d(z)\n",
    "    x_range = np.linspace(node_metrics_df['std_target'].min(),\n",
    "                          node_metrics_df['std_target'].max(), 100)\n",
    "    ax2.plot(x_range, p(x_range), 'r--', linewidth=2, label='Linear fit')\n",
    "    ax2.legend()\n",
    "\n",
    "# Normalized MAE (MAE / mean)\n",
    "ax3 = axes[2]\n",
    "node_metrics_df['normalized_mae'] = node_metrics_df['mae'] / (node_metrics_df['mean_target'] + 1e-6)\n",
    "normalized_sorted = node_metrics_df.sort_values('normalized_mae')\n",
    "ax3.barh(range(num_nodes), normalized_sorted['normalized_mae'], color='steelblue', alpha=0.7)\n",
    "ax3.set_yticks(range(num_nodes))\n",
    "ax3.set_yticklabels([name[:15] for name in normalized_sorted['name']], fontsize=8)\n",
    "ax3.set_xlabel('Normalized MAE (MAE / Mean)')\n",
    "ax3.set_title('Normalized MAE by Node')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31",
   "metadata": {},
   "source": [
    "## 6. Generate Residual Diagnostics Plots\n",
    "\n",
    "Plot residual distributions, Q-Q plots, and autocorrelation of residuals to diagnose model fit issues. Check for heteroscedasticity and temporal patterns in errors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute residuals\n",
    "def compute_residuals(targets, preds):\n",
    "    \"\"\"Compute residuals and related statistics.\"\"\"\n",
    "    targets_flat = targets.numpy().flatten()\n",
    "    preds_flat = preds.numpy().flatten()\n",
    "\n",
    "    valid_mask = ~np.isnan(targets_flat)\n",
    "\n",
    "    residuals = preds_flat[valid_mask] - targets_flat[valid_mask]\n",
    "    targets_valid = targets_flat[valid_mask]\n",
    "    preds_valid = preds_flat[valid_mask]\n",
    "\n",
    "    # Standardized residuals\n",
    "    std_residuals = (residuals - residuals.mean()) / (residuals.std() + 1e-8)\n",
    "\n",
    "    return {\n",
    "        'residuals': residuals,\n",
    "        'std_residuals': std_residuals,\n",
    "        'targets': targets_valid,\n",
    "        'predictions': preds_valid\n",
    "    }\n",
    "\n",
    "residual_data = compute_residuals(test_results['targets'], test_results['preds'])\n",
    "\n",
    "print(f\"Residual Statistics:\")\n",
    "print(f\"  Mean: {residual_data['residuals'].mean():.4f}\")\n",
    "print(f\"  Std: {residual_data['residuals'].std():.4f}\")\n",
    "print(f\"  Min: {residual_data['residuals'].min():.4f}\")\n",
    "print(f\"  Max: {residual_data['residuals'].max():.4f}\")\n",
    "print(f\"  Skewness: {sp_stats.skew(residual_data['residuals']):.4f}\")\n",
    "print(f\"  Kurtosis: {sp_stats.kurtosis(residual_data['residuals']):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Residual distribution and Q-Q plot\n",
    "fig, axes = plt.subplots(2, 3, figsize=(15, 10))\n",
    "\n",
    "# Residual histogram\n",
    "ax1 = axes[0, 0]\n",
    "ax1.hist(residual_data['residuals'], bins=50, density=True, alpha=0.7,\n",
    "         color='steelblue', edgecolor='black')\n",
    "# Overlay normal distribution\n",
    "x = np.linspace(residual_data['residuals'].min(), residual_data['residuals'].max(), 100)\n",
    "ax1.plot(x, sp_stats.norm.pdf(x, residual_data['residuals'].mean(),\n",
    "                               residual_data['residuals'].std()),\n",
    "         'r-', linewidth=2, label='Normal fit')\n",
    "ax1.set_xlabel('Residual')\n",
    "ax1.set_ylabel('Density')\n",
    "ax1.set_title('Residual Distribution')\n",
    "ax1.legend()\n",
    "\n",
    "# Q-Q plot\n",
    "ax2 = axes[0, 1]\n",
    "sp_stats.probplot(residual_data['std_residuals'], dist=\"norm\", plot=ax2)\n",
    "ax2.set_title('Q-Q Plot (Standardized Residuals)')\n",
    "\n",
    "# Residuals vs predicted values (heteroscedasticity check)\n",
    "ax3 = axes[0, 2]\n",
    "ax3.scatter(residual_data['predictions'], residual_data['residuals'],\n",
    "            alpha=0.1, s=5, c='steelblue')\n",
    "ax3.axhline(y=0, color='red', linestyle='--', linewidth=2)\n",
    "ax3.set_xlabel('Predicted Value')\n",
    "ax3.set_ylabel('Residual')\n",
    "ax3.set_title('Residuals vs Predictions')\n",
    "\n",
    "# Add LOWESS smoothing line\n",
    "try:\n",
    "    from statsmodels.nonparametric.smoothers_lowess import lowess\n",
    "    # Subsample for performance\n",
    "    n_subsample = min(1000, len(residual_data['predictions']))\n",
    "    idx = np.random.choice(len(residual_data['predictions']), n_subsample, replace=False)\n",
    "    lowess_result = lowess(residual_data['residuals'][idx],\n",
    "                           residual_data['predictions'][idx], frac=0.3)\n",
    "    ax3.plot(lowess_result[:, 0], lowess_result[:, 1], 'orange', linewidth=2, label='LOWESS')\n",
    "    ax3.legend()\n",
    "except ImportError:\n",
    "    pass\n",
    "\n",
    "# Residuals vs actual values\n",
    "ax4 = axes[1, 0]\n",
    "ax4.scatter(residual_data['targets'], residual_data['residuals'],\n",
    "            alpha=0.1, s=5, c='steelblue')\n",
    "ax4.axhline(y=0, color='red', linestyle='--', linewidth=2)\n",
    "ax4.set_xlabel('Actual Value')\n",
    "ax4.set_ylabel('Residual')\n",
    "ax4.set_title('Residuals vs Actual Values')\n",
    "\n",
    "# Scale-location plot (sqrt of abs standardized residuals)\n",
    "ax5 = axes[1, 1]\n",
    "sqrt_std_residuals = np.sqrt(np.abs(residual_data['std_residuals']))\n",
    "ax5.scatter(residual_data['predictions'], sqrt_std_residuals,\n",
    "            alpha=0.1, s=5, c='steelblue')\n",
    "ax5.set_xlabel('Predicted Value')\n",
    "ax5.set_ylabel('√|Standardized Residual|')\n",
    "ax5.set_title('Scale-Location Plot')\n",
    "\n",
    "try:\n",
    "    n_subsample = min(1000, len(residual_data['predictions']))\n",
    "    idx = np.random.choice(len(residual_data['predictions']), n_subsample, replace=False)\n",
    "    lowess_result = lowess(sqrt_std_residuals[idx],\n",
    "                           residual_data['predictions'][idx], frac=0.3)\n",
    "    ax5.plot(lowess_result[:, 0], lowess_result[:, 1], 'red', linewidth=2)\n",
    "except:\n",
    "    pass\n",
    "\n",
    "# Autocorrelation of residuals\n",
    "ax6 = axes[1, 2]\n",
    "max_lags = min(50, len(residual_data['residuals']) // 10)\n",
    "autocorr = [1.0]  # lag 0\n",
    "for lag in range(1, max_lags + 1):\n",
    "    autocorr.append(np.corrcoef(residual_data['residuals'][:-lag],\n",
    "                                 residual_data['residuals'][lag:])[0, 1])\n",
    "\n",
    "ax6.bar(range(max_lags + 1), autocorr, color='steelblue', alpha=0.7)\n",
    "# Add significance bounds\n",
    "n = len(residual_data['residuals'])\n",
    "significance_bound = 1.96 / np.sqrt(n)\n",
    "ax6.axhline(y=significance_bound, color='red', linestyle='--', alpha=0.7)\n",
    "ax6.axhline(y=-significance_bound, color='red', linestyle='--', alpha=0.7)\n",
    "ax6.set_xlabel('Lag')\n",
    "ax6.set_ylabel('Autocorrelation')\n",
    "ax6.set_title('Residual Autocorrelation')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Per-node residual analysis\n",
    "fig, axes = plt.subplots(2, 3, figsize=(15, 10))\n",
    "\n",
    "# Select a few representative nodes for detailed analysis\n",
    "# Best, worst, and median performing nodes\n",
    "mae_values = node_metrics_df['mae'].dropna()\n",
    "if len(mae_values) > 0:\n",
    "    best_node = node_metrics_df.loc[node_metrics_df['mae'].idxmin(), 'node']\n",
    "    worst_node = node_metrics_df.loc[node_metrics_df['mae'].idxmax(), 'node']\n",
    "    median_idx = mae_values.argsort().iloc[len(mae_values)//2]\n",
    "    median_node = node_metrics_df.loc[median_idx, 'node'] if pd.notna(median_idx) else 0\n",
    "else:\n",
    "    best_node, worst_node, median_node = 0, 1, 2\n",
    "\n",
    "selected_nodes = [best_node, median_node, worst_node]\n",
    "node_labels = ['Best', 'Median', 'Worst']\n",
    "\n",
    "for i, (node, label) in enumerate(zip(selected_nodes, node_labels)):\n",
    "    node_targets = test_results['targets'][:, 0, node, -1].numpy()\n",
    "    node_preds = test_results['preds'][:, 0, node, -1].numpy()\n",
    "\n",
    "    valid_mask = ~np.isnan(node_targets)\n",
    "    residuals = node_preds[valid_mask] - node_targets[valid_mask]\n",
    "\n",
    "    # Residual histogram\n",
    "    ax1 = axes[0, i]\n",
    "    ax1.hist(residuals, bins=30, density=True, alpha=0.7,\n",
    "             color='steelblue', edgecolor='black')\n",
    "    ax1.axvline(x=0, color='red', linestyle='--', linewidth=2)\n",
    "    ax1.set_xlabel('Residual')\n",
    "    ax1.set_ylabel('Density')\n",
    "    node_name = id_to_name_map.get(node, f'Node_{node}')[:20]\n",
    "    ax1.set_title(f'{label} Node: {node_name}\\nMean={residuals.mean():.2f}, Std={residuals.std():.2f}')\n",
    "\n",
    "    # Time series of residuals\n",
    "    ax2 = axes[1, i]\n",
    "    ax2.plot(residuals[:200], alpha=0.7, color='steelblue')\n",
    "    ax2.axhline(y=0, color='red', linestyle='--', linewidth=1)\n",
    "    ax2.fill_between(range(len(residuals[:200])),\n",
    "                     -residuals.std()*2, residuals.std()*2,\n",
    "                     alpha=0.2, color='red', label='±2σ')\n",
    "    ax2.set_xlabel('Sample Index')\n",
    "    ax2.set_ylabel('Residual')\n",
    "    ax2.set_title(f'Residual Time Series (first 200 samples)')\n",
    "    ax2.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
